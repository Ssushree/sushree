{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6455e005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "C:\\Users\\Sushree.Behera\\Sushree\\GZSL_Implementation\n",
      "------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os,sys\n",
    "pwd = os.getcwd()\n",
    "parent = '/'.join(pwd.split('/')[:-1])\n",
    "sys.path.insert(0,parent)\n",
    "#os.chdir(parent)\n",
    "#%%\n",
    "print('-'*30)\n",
    "print(os.getcwd())\n",
    "print('-'*30)\n",
    "#%%\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from DAZLE import DAZLE\n",
    "from AWA2DataLoader import AWA2DataLoader\n",
    "from helper_func import eval_zs_gzsl,visualize_attention#,get_attribute_attention_stats\n",
    "import importlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25f6b752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Sushree/Jio_Institute/Dataset/\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "AWA2\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "Balance dataloader\n",
      "_____\n",
      "C:/Sushree/Jio_Institute/Dataset/data/AWA2/feature_map_ResNet_101_AWA2.hdf5\n",
      "Expert Attr\n",
      "threshold at zero attribute with negative value\n"
     ]
    }
   ],
   "source": [
    "idx_GPU = 0\n",
    "device = torch.device(\"cuda:{}\".format(idx_GPU) if torch.cuda.is_available() else \"cpu\")\n",
    "NFS_path = 'C:/Sushree/Jio_Institute/Dataset/'\n",
    "dataloader = AWA2DataLoader(NFS_path,device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ebb88b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lr(optimizer):\n",
    "    lr = []\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr.append(param_group['lr'])\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee3e85d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Configuration\n",
      "loss_type CE\n",
      "normalize V\n",
      "normalize F\n",
      "training to exclude unseen class [seen upperbound]\n",
      "Init word2vec\n",
      "Linear model\n",
      "loss_att BCEWithLogitsLoss()\n",
      "Bilinear attention module\n",
      "******************************\n",
      "Measure w2v deviation\n",
      "Compute Pruning loss Parameter containing:\n",
      "tensor(0)\n",
      "Add one smoothing\n",
      "Second layer attenion conditioned on image features\n",
      "------------------------------\n",
      "No sigmoid on attr score\n",
      "{'pmp': {'init_lambda': 0.1, 'final_lambda': 0.1, 'phase': 0.8}, 'desired_mass': {'init_lambda': -1, 'final_lambda': -1, 'phase': 0.8}}\n",
      "\t V\n",
      "\t W_1\n",
      "\t W_2\n",
      "\t W_3\n",
      "default lr ['V'] 1x lr ['W_1', 'W_2', 'W_3']\n",
      "------------------------------\n",
      "learing rate 0.0001\n",
      "trainable V True\n",
      "lambda_ 0.1\n",
      "optimized seen only\n",
      "optimizer: RMSProp with momentum = 0.0 and weight_decay = 0.0001\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sushree.Behera\\Sushree\\GZSL_Implementation\\DAZLE.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.init_w2v_att = F.normalize(torch.tensor(init_w2v_att))\n",
      "C:\\Users\\Sushree.Behera\\Sushree\\GZSL_Implementation\\DAZLE.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.att = nn.Parameter(F.normalize(torch.tensor(att)),requires_grad = False)\n"
     ]
    }
   ],
   "source": [
    "seed = 214#214\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "batch_size = 50\n",
    "nepoches = 20\n",
    "niters = dataloader.ntrain * nepoches//batch_size\n",
    "dim_f = 2048\n",
    "dim_v = 300\n",
    "init_w2v_att = dataloader.w2v_att\n",
    "att = dataloader.att #dataloader.normalize_att#\n",
    "att[att<0] = 0\n",
    "normalize_att = dataloader.normalize_att\n",
    "#assert (att.min().item() == 0 and att.max().item() == 1)\n",
    "\n",
    "trainable_w2v = True\n",
    "lambda_ = 0.1#0.1\n",
    "bias = 0\n",
    "prob_prune = 0\n",
    "uniform_att_1 = False\n",
    "uniform_att_2 = False\n",
    "\n",
    "seenclass = dataloader.seenclasses\n",
    "unseenclass = dataloader.unseenclasses\n",
    "desired_mass = 1#unseenclass.size(0)/(seenclass.size(0)+unseenclass.size(0))\n",
    "report_interval = niters//nepoches#10000//batch_size#\n",
    "\n",
    "model = DAZLE(dim_f,dim_v,init_w2v_att,att,normalize_att,\n",
    "            seenclass,unseenclass,\n",
    "            lambda_,\n",
    "            trainable_w2v,normalize_V=True,normalize_F=True,is_conservative=True,\n",
    "            uniform_att_1=uniform_att_1,uniform_att_2=uniform_att_2,\n",
    "            prob_prune=prob_prune,desired_mass=desired_mass, is_conv=False,\n",
    "            is_bias=True)\n",
    "model.to(device)\n",
    "\n",
    "setup = {'pmp':{'init_lambda':0.1,'final_lambda':0.1,'phase':0.8},\n",
    "         'desired_mass':{'init_lambda':-1,'final_lambda':-1,'phase':0.8}}\n",
    "print(setup)\n",
    "\n",
    "params_to_update = []\n",
    "params_names = []\n",
    "for name,param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        params_names.append(name)\n",
    "        print(\"\\t\",name)\n",
    "#%%\n",
    "lr = 0.0001\n",
    "weight_decay = 0.0001#0.000#0.#\n",
    "momentum = 0.#0.#\n",
    "#%%\n",
    "lr_seperator = 1\n",
    "lr_factor = 1\n",
    "print('default lr {} {}x lr {}'.format(params_names[:lr_seperator],lr_factor,params_names[lr_seperator:]))\n",
    "optimizer  = optim.RMSprop( params_to_update ,lr=lr,weight_decay=weight_decay, momentum=momentum)\n",
    "print('-'*30)\n",
    "print('learing rate {}'.format(lr))\n",
    "print('trainable V {}'.format(trainable_w2v))\n",
    "print('lambda_ {}'.format(lambda_))\n",
    "print('optimized seen only')\n",
    "print('optimizer: RMSProp with momentum = {} and weight_decay = {}'.format(momentum,weight_decay))\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8c94e63",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 0, 'loss': 3.956040143966675, 'loss_CE': 3.9095566272735596, 'loss_cal': 0.4648360013961792, 'acc_seen': 0, 'acc_novel': 0, 'H': 0, 'acc_zs': 0}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 470, 'loss': 1.3515682220458984, 'loss_CE': 1.2346607446670532, 'loss_cal': 1.1690747737884521, 'acc_seen': 0.5439391732215881, 'acc_novel': 0.605766773223877, 'H': 0.5731905254751752, 'acc_zs': 0.6462183594703674}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 940, 'loss': 0.9183818697929382, 'loss_CE': 0.7963429093360901, 'loss_cal': 1.2203896045684814, 'acc_seen': 0.7085906267166138, 'acc_novel': 0.6012459993362427, 'H': 0.6505197228518068, 'acc_zs': 0.6683871150016785}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 1410, 'loss': 0.7530431151390076, 'loss_CE': 0.6216723322868347, 'loss_cal': 1.3137075901031494, 'acc_seen': 0.7400235533714294, 'acc_novel': 0.5982651710510254, 'H': 0.6616364759863136, 'acc_zs': 0.6683979034423828}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 1880, 'loss': 0.6627249717712402, 'loss_CE': 0.5256198048591614, 'loss_cal': 1.3710519075393677, 'acc_seen': 0.7527486085891724, 'acc_novel': 0.6026891469955444, 'H': 0.6694123945470043, 'acc_zs': 0.6754605770111084}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 2350, 'loss': 0.6532846093177795, 'loss_CE': 0.5195896029472351, 'loss_cal': 1.3369499444961548, 'acc_seen': 0.7533180713653564, 'acc_novel': 0.6059094667434692, 'H': 0.6716205169655076, 'acc_zs': 0.678466796875}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 2820, 'loss': 0.6108322739601135, 'loss_CE': 0.4819560945034027, 'loss_cal': 1.288761854171753, 'acc_seen': 0.7533180713653564, 'acc_novel': 0.6059094667434692, 'H': 0.6716205169655076, 'acc_zs': 0.678466796875}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 3290, 'loss': 0.5896127223968506, 'loss_CE': 0.4508580267429352, 'loss_cal': 1.3875467777252197, 'acc_seen': 0.7628607153892517, 'acc_novel': 0.6032173037528992, 'H': 0.6737108385143088, 'acc_zs': 0.6784058213233948}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 3760, 'loss': 0.6441433429718018, 'loss_CE': 0.5111192464828491, 'loss_cal': 1.3302406072616577, 'acc_seen': 0.7628607153892517, 'acc_novel': 0.6032173037528992, 'H': 0.6737108385143088, 'acc_zs': 0.6784058213233948}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 4230, 'loss': 0.596890926361084, 'loss_CE': 0.462432324886322, 'loss_cal': 1.3445861339569092, 'acc_seen': 0.7628607153892517, 'acc_novel': 0.6032173037528992, 'H': 0.6737108385143088, 'acc_zs': 0.6784058213233948}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 4700, 'loss': 0.6408515572547913, 'loss_CE': 0.5099989771842957, 'loss_cal': 1.308525562286377, 'acc_seen': 0.7628607153892517, 'acc_novel': 0.6032173037528992, 'H': 0.6737108385143088, 'acc_zs': 0.6784058213233948}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 5170, 'loss': 0.6000597476959229, 'loss_CE': 0.46933841705322266, 'loss_cal': 1.307213544845581, 'acc_seen': 0.7628607153892517, 'acc_novel': 0.6032173037528992, 'H': 0.6737108385143088, 'acc_zs': 0.6784058213233948}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 5640, 'loss': 0.6804867386817932, 'loss_CE': 0.557007908821106, 'loss_cal': 1.234788179397583, 'acc_seen': 0.7628607153892517, 'acc_novel': 0.6032173037528992, 'H': 0.6737108385143088, 'acc_zs': 0.6784058213233948}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 6110, 'loss': 0.5829715728759766, 'loss_CE': 0.44995012879371643, 'loss_cal': 1.3302146196365356, 'acc_seen': 0.7628607153892517, 'acc_novel': 0.6032173037528992, 'H': 0.6737108385143088, 'acc_zs': 0.6784058213233948}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 6580, 'loss': 0.6801075339317322, 'loss_CE': 0.566422700881958, 'loss_cal': 1.1368485689163208, 'acc_seen': 0.7628607153892517, 'acc_novel': 0.6032173037528992, 'H': 0.6737108385143088, 'acc_zs': 0.6784058213233948}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 7050, 'loss': 0.557324230670929, 'loss_CE': 0.42887359857559204, 'loss_cal': 1.2845064401626587, 'acc_seen': 0.7628607153892517, 'acc_novel': 0.6032173037528992, 'H': 0.6737108385143088, 'acc_zs': 0.6784058213233948}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 7520, 'loss': 0.5774976015090942, 'loss_CE': 0.452181875705719, 'loss_cal': 1.2531574964523315, 'acc_seen': 0.7628607153892517, 'acc_novel': 0.6032173037528992, 'H': 0.6737108385143088, 'acc_zs': 0.6784058213233948}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 7990, 'loss': 0.6747572422027588, 'loss_CE': 0.5563398599624634, 'loss_cal': 1.1841740608215332, 'acc_seen': 0.7628607153892517, 'acc_novel': 0.6032173037528992, 'H': 0.6737108385143088, 'acc_zs': 0.6784058213233948}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 8460, 'loss': 0.5500620007514954, 'loss_CE': 0.41784220933914185, 'loss_cal': 1.3221979141235352, 'acc_seen': 0.7628607153892517, 'acc_novel': 0.6032173037528992, 'H': 0.6737108385143088, 'acc_zs': 0.6784058213233948}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 8930, 'loss': 0.6987336277961731, 'loss_CE': 0.5684798955917358, 'loss_cal': 1.3025370836257935, 'acc_seen': 0.7628607153892517, 'acc_novel': 0.6032173037528992, 'H': 0.6737108385143088, 'acc_zs': 0.6784058213233948}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 9400, 'loss': 0.6611925363540649, 'loss_CE': 0.5426926612854004, 'loss_cal': 1.1849985122680664, 'acc_seen': 0.7628607153892517, 'acc_novel': 0.6032173037528992, 'H': 0.6737108385143088, 'acc_zs': 0.6784058213233948}\n"
     ]
    }
   ],
   "source": [
    "best_performance = [0,0,0,0]\n",
    "for i in range(0,niters):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    batch_label, batch_feature, batch_att = dataloader.next_batch(batch_size)\n",
    "    out_package = model(batch_feature)\n",
    "    \n",
    "    in_package = out_package\n",
    "    in_package['batch_label'] = batch_label\n",
    "    \n",
    "    out_package=model.compute_loss(in_package)\n",
    "    loss,loss_CE,loss_cal = out_package['loss'],out_package['loss_CE'],out_package['loss_cal']\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%report_interval==0:\n",
    "        print('-'*30)\n",
    "        acc_seen, acc_novel, H, acc_zs = eval_zs_gzsl(dataloader,model,device,bias_seen=-bias,bias_unseen=bias)\n",
    "        \n",
    "        if H > best_performance[2]:\n",
    "            best_performance = [acc_seen, acc_novel, H, acc_zs]\n",
    "        stats_package = {'iter':i, 'loss':loss.item(), 'loss_CE':loss_CE.item(),\n",
    "                         'loss_cal': loss_cal.item(),\n",
    "                         'acc_seen':best_performance[0], 'acc_novel':best_performance[1], 'H':best_performance[2], 'acc_zs':best_performance[3]}\n",
    "        \n",
    "        print(stats_package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25af7106",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
