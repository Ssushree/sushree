{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7b7057dd",
   "metadata": {},
   "source": [
    "# Implementation of the paper \"Fine-grained generalized zero-shot learning via dense attribute-based attention\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c9ccf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models.resnet as models\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import pickle\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "import torch.optim as optim\n",
    "import importlib\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfac6ac9",
   "metadata": {},
   "source": [
    "# CUB dataset\n",
    "#images = 17188\n",
    "\n",
    "#classes = 200, 150 seen classes and 50 unseen classes\n",
    "\n",
    "Each class has 312 number of attributes that represent the class infromation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccb6dce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Sushree/Jio_Institute/Dataset/\n",
      "C:/Sushree/Jio_Institute/Dataset/data/xlsa17/data/CUB/res101.mat\n"
     ]
    }
   ],
   "source": [
    "img_dir = 'C:/Sushree/Jio_Institute/Dataset/'\n",
    "print(img_dir)\n",
    "\n",
    "file_paths = 'C:/Sushree/Jio_Institute/Dataset/data/xlsa17/data/CUB/res101.mat'\n",
    "print(file_paths)\n",
    "\n",
    "#resNet101.mat includes the following fields:\n",
    "#-features: columns correspond to image instances\n",
    "#-labels: label number of a class is its row number in allclasses.txt\n",
    "#-image_files: image sources  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "832d3b51",
   "metadata": {},
   "source": [
    "# Let's visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd214aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_data_distribution(file_paths):    \n",
    "    matcontent = sio.loadmat(file_paths)\n",
    "    print(matcontent)\n",
    "\n",
    "    image_files = np.squeeze(matcontent['image_files'])\n",
    "    #print(image_files)\n",
    "\n",
    "    labels = np.squeeze(matcontent['labels'])\n",
    "    print(labels)\n",
    "    print(labels.size)  # 11788 for CUB\n",
    "\n",
    "    class_names = []\n",
    "    for idx in range(len(image_files)):\n",
    "        image_file = image_files[idx][0]\n",
    "        class_name = image_file.split('/')[5:][3]\n",
    "        class_names.append(class_name)\n",
    "\n",
    "    print(len(class_names))   \n",
    "    #print(class_names)\n",
    "    \n",
    "    num_bins = 200 # # for CUB\n",
    "    \n",
    "    plt.figure(figsize=(35,6))\n",
    "    \n",
    "    plt.title(\"Data Distribution: CUB\")\n",
    "    plt.xlabel(\"Categories\")\n",
    "    plt.ylabel(\"Number of Classes\")\n",
    "    \n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.grid(color = 'red', linestyle = '--', linewidth = 0.3)\n",
    "    plt.hist(class_names, num_bins, align=\"mid\")\n",
    "\n",
    "visualize_data_distribution(file_paths)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72caa267",
   "metadata": {},
   "source": [
    "# Let's extract deep features (consider pre-trained ResNet 101 with no fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e28dc16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomedDataset(Dataset):\n",
    "    \"\"\"Face Landmarks dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, img_dir , file_paths, transform=None):\n",
    "        self.matcontent = sio.loadmat(file_paths)\n",
    "        self.image_files = np.squeeze(self.matcontent['image_files'])\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_file = self.image_files[idx][0]\n",
    "        image_file = os.path.join(self.img_dir, '/'.join(image_file.split('/')[5:]))\n",
    "        image = Image.open(image_file)\n",
    "        \n",
    "        if image.mode == 'L':\n",
    "            image=image.convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c57bc0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 224\n",
    "data_transforms = transforms.Compose([\n",
    "        transforms.Resize(input_size),\n",
    "        transforms.CenterCrop(input_size),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "    \n",
    "CUBDataset = CustomedDataset(img_dir , file_paths, data_transforms)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51604ffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sushree.Behera\\anaconda3\\envs\\tf_sushree\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Sushree.Behera\\anaconda3\\envs\\tf_sushree\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet101_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (2): ReLU(inplace=True)\n",
      "  (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (5): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (6): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (6): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (7): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (8): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (9): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (10): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (11): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (12): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (13): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (14): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (15): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (16): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (17): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (18): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (19): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (20): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (21): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (22): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (7): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 256, 28, 28]         131,072\n",
      "      BatchNorm2d-80          [-1, 256, 28, 28]             512\n",
      "             ReLU-81          [-1, 256, 28, 28]               0\n",
      "           Conv2d-82          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-83          [-1, 256, 14, 14]             512\n",
      "             ReLU-84          [-1, 256, 14, 14]               0\n",
      "           Conv2d-85         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-86         [-1, 1024, 14, 14]           2,048\n",
      "           Conv2d-87         [-1, 1024, 14, 14]         524,288\n",
      "      BatchNorm2d-88         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-89         [-1, 1024, 14, 14]               0\n",
      "       Bottleneck-90         [-1, 1024, 14, 14]               0\n",
      "           Conv2d-91          [-1, 256, 14, 14]         262,144\n",
      "      BatchNorm2d-92          [-1, 256, 14, 14]             512\n",
      "             ReLU-93          [-1, 256, 14, 14]               0\n",
      "           Conv2d-94          [-1, 256, 14, 14]         589,824\n",
      "      BatchNorm2d-95          [-1, 256, 14, 14]             512\n",
      "             ReLU-96          [-1, 256, 14, 14]               0\n",
      "           Conv2d-97         [-1, 1024, 14, 14]         262,144\n",
      "      BatchNorm2d-98         [-1, 1024, 14, 14]           2,048\n",
      "             ReLU-99         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-100         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-101          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-102          [-1, 256, 14, 14]             512\n",
      "            ReLU-103          [-1, 256, 14, 14]               0\n",
      "          Conv2d-104          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-105          [-1, 256, 14, 14]             512\n",
      "            ReLU-106          [-1, 256, 14, 14]               0\n",
      "          Conv2d-107         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-108         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-109         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-110         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-111          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-112          [-1, 256, 14, 14]             512\n",
      "            ReLU-113          [-1, 256, 14, 14]               0\n",
      "          Conv2d-114          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-115          [-1, 256, 14, 14]             512\n",
      "            ReLU-116          [-1, 256, 14, 14]               0\n",
      "          Conv2d-117         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-118         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-119         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-120         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-121          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-122          [-1, 256, 14, 14]             512\n",
      "            ReLU-123          [-1, 256, 14, 14]               0\n",
      "          Conv2d-124          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-125          [-1, 256, 14, 14]             512\n",
      "            ReLU-126          [-1, 256, 14, 14]               0\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-142          [-1, 256, 14, 14]             512\n",
      "            ReLU-143          [-1, 256, 14, 14]               0\n",
      "          Conv2d-144          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-145          [-1, 256, 14, 14]             512\n",
      "            ReLU-146          [-1, 256, 14, 14]               0\n",
      "          Conv2d-147         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-149         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-150         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-151          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-152          [-1, 256, 14, 14]             512\n",
      "            ReLU-153          [-1, 256, 14, 14]               0\n",
      "          Conv2d-154          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-155          [-1, 256, 14, 14]             512\n",
      "            ReLU-156          [-1, 256, 14, 14]               0\n",
      "          Conv2d-157         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-159         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-160         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-161          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-162          [-1, 256, 14, 14]             512\n",
      "            ReLU-163          [-1, 256, 14, 14]               0\n",
      "          Conv2d-164          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-165          [-1, 256, 14, 14]             512\n",
      "            ReLU-166          [-1, 256, 14, 14]               0\n",
      "          Conv2d-167         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-169         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-170         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-171          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-172          [-1, 256, 14, 14]             512\n",
      "            ReLU-173          [-1, 256, 14, 14]               0\n",
      "          Conv2d-174          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-175          [-1, 256, 14, 14]             512\n",
      "            ReLU-176          [-1, 256, 14, 14]               0\n",
      "          Conv2d-177         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-179         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-180         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-181          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-182          [-1, 256, 14, 14]             512\n",
      "            ReLU-183          [-1, 256, 14, 14]               0\n",
      "          Conv2d-184          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-185          [-1, 256, 14, 14]             512\n",
      "            ReLU-186          [-1, 256, 14, 14]               0\n",
      "          Conv2d-187         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-189         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-190         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-191          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-192          [-1, 256, 14, 14]             512\n",
      "            ReLU-193          [-1, 256, 14, 14]               0\n",
      "          Conv2d-194          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-195          [-1, 256, 14, 14]             512\n",
      "            ReLU-196          [-1, 256, 14, 14]               0\n",
      "          Conv2d-197         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-199         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-200         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-201          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-202          [-1, 256, 14, 14]             512\n",
      "            ReLU-203          [-1, 256, 14, 14]               0\n",
      "          Conv2d-204          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-205          [-1, 256, 14, 14]             512\n",
      "            ReLU-206          [-1, 256, 14, 14]               0\n",
      "          Conv2d-207         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-209         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-210         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-211          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-212          [-1, 256, 14, 14]             512\n",
      "            ReLU-213          [-1, 256, 14, 14]               0\n",
      "          Conv2d-214          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-215          [-1, 256, 14, 14]             512\n",
      "            ReLU-216          [-1, 256, 14, 14]               0\n",
      "          Conv2d-217         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-219         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-220         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-221          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-222          [-1, 256, 14, 14]             512\n",
      "            ReLU-223          [-1, 256, 14, 14]               0\n",
      "          Conv2d-224          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-225          [-1, 256, 14, 14]             512\n",
      "            ReLU-226          [-1, 256, 14, 14]               0\n",
      "          Conv2d-227         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-229         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-230         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-231          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-232          [-1, 256, 14, 14]             512\n",
      "            ReLU-233          [-1, 256, 14, 14]               0\n",
      "          Conv2d-234          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-235          [-1, 256, 14, 14]             512\n",
      "            ReLU-236          [-1, 256, 14, 14]               0\n",
      "          Conv2d-237         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-239         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-240         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-241          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-242          [-1, 256, 14, 14]             512\n",
      "            ReLU-243          [-1, 256, 14, 14]               0\n",
      "          Conv2d-244          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-245          [-1, 256, 14, 14]             512\n",
      "            ReLU-246          [-1, 256, 14, 14]               0\n",
      "          Conv2d-247         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-249         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-250         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-251          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-252          [-1, 256, 14, 14]             512\n",
      "            ReLU-253          [-1, 256, 14, 14]               0\n",
      "          Conv2d-254          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-255          [-1, 256, 14, 14]             512\n",
      "            ReLU-256          [-1, 256, 14, 14]               0\n",
      "          Conv2d-257         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-259         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-260         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-261          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-262          [-1, 256, 14, 14]             512\n",
      "            ReLU-263          [-1, 256, 14, 14]               0\n",
      "          Conv2d-264          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-265          [-1, 256, 14, 14]             512\n",
      "            ReLU-266          [-1, 256, 14, 14]               0\n",
      "          Conv2d-267         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-269         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-270         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-271          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-272          [-1, 256, 14, 14]             512\n",
      "            ReLU-273          [-1, 256, 14, 14]               0\n",
      "          Conv2d-274          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-275          [-1, 256, 14, 14]             512\n",
      "            ReLU-276          [-1, 256, 14, 14]               0\n",
      "          Conv2d-277         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-279         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-280         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-281          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-282          [-1, 256, 14, 14]             512\n",
      "            ReLU-283          [-1, 256, 14, 14]               0\n",
      "          Conv2d-284          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-285          [-1, 256, 14, 14]             512\n",
      "            ReLU-286          [-1, 256, 14, 14]               0\n",
      "          Conv2d-287         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-289         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-290         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-291          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-292          [-1, 256, 14, 14]             512\n",
      "            ReLU-293          [-1, 256, 14, 14]               0\n",
      "          Conv2d-294          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-295          [-1, 256, 14, 14]             512\n",
      "            ReLU-296          [-1, 256, 14, 14]               0\n",
      "          Conv2d-297         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-299         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-300         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-301          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-302          [-1, 256, 14, 14]             512\n",
      "            ReLU-303          [-1, 256, 14, 14]               0\n",
      "          Conv2d-304          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-305          [-1, 256, 14, 14]             512\n",
      "            ReLU-306          [-1, 256, 14, 14]               0\n",
      "          Conv2d-307         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-309         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-310         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-311          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-312          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-313          [-1, 512, 14, 14]               0\n",
      "          Conv2d-314            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-315            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-316            [-1, 512, 7, 7]               0\n",
      "          Conv2d-317           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-318           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-319           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-320           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-321           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-322           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-323            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-324            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-325            [-1, 512, 7, 7]               0\n",
      "          Conv2d-326            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-327            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-328            [-1, 512, 7, 7]               0\n",
      "          Conv2d-329           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-330           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-331           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-332           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-333            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-334            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-335            [-1, 512, 7, 7]               0\n",
      "          Conv2d-336            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-337            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-338            [-1, 512, 7, 7]               0\n",
      "          Conv2d-339           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-340           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-341           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-342           [-1, 2048, 7, 7]               0\n",
      "================================================================\n",
      "Total params: 42,500,160\n",
      "Trainable params: 0\n",
      "Non-trainable params: 42,500,160\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 429.71\n",
      "Params size (MB): 162.13\n",
      "Estimated Total Size (MB): 592.41\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model_name = \"resnet\"\n",
    "\n",
    "# Batch size for training (change depending on how much memory you have)\n",
    "batch_size = 32\n",
    "\n",
    "model_ref = models.resnet101(pretrained=True)\n",
    "model_ref.eval()\n",
    "\n",
    "model_f = nn.Sequential(*list(model_ref.children())[:-2])\n",
    "model_f.eval()\n",
    "\n",
    "\n",
    "for param in model_f.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "print(model_f)\n",
    "        \n",
    "from torchsummary import summary\n",
    "summary(model_f, (3, 224, 224))    \n",
    "\n",
    "dataset_loader = torch.utils.data.DataLoader(CUBDataset, batch_size=batch_size, shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "740abf7f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "[[[[0.00000000e+00 1.23344541e-01 4.21795040e-01 ... 8.83068979e-01\n",
      "    4.78987157e-01 3.40790004e-02]\n",
      "   [3.98916721e-01 8.65673423e-01 1.91944945e+00 ... 2.04522371e+00\n",
      "    9.94292498e-01 3.35752785e-01]\n",
      "   [1.62883639e+00 1.88533747e+00 2.49308968e+00 ... 2.54128289e+00\n",
      "    2.07721472e+00 1.13727379e+00]\n",
      "   ...\n",
      "   [2.21705508e+00 2.69009900e+00 2.40386891e+00 ... 3.52886152e+00\n",
      "    2.16139841e+00 1.15703058e+00]\n",
      "   [1.61826468e+00 2.66649914e+00 2.61611414e+00 ... 2.47577143e+00\n",
      "    2.30320406e+00 1.44193637e+00]\n",
      "   [1.09783983e+00 1.36646819e+00 9.82558608e-01 ... 1.12874866e+00\n",
      "    1.96719456e+00 1.98620057e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 2.04329327e-01 6.98611215e-02 ... 1.40249580e-01\n",
      "    1.42701417e-02 0.00000000e+00]\n",
      "   [3.35342288e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 7.71514326e-03]\n",
      "   ...\n",
      "   [3.59844476e-01 1.07140690e-02 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[3.75346041e+00 3.64417338e+00 2.83157635e+00 ... 1.72575533e+00\n",
      "    2.54983783e+00 3.33554864e+00]\n",
      "   [2.95257854e+00 3.07320738e+00 3.30664444e+00 ... 3.35704446e+00\n",
      "    4.14575052e+00 4.92940569e+00]\n",
      "   [2.41849494e+00 3.57774687e+00 5.48922443e+00 ... 5.79459667e+00\n",
      "    6.48801517e+00 7.70109797e+00]\n",
      "   ...\n",
      "   [1.85578632e+00 2.70677948e+00 4.66350412e+00 ... 7.30483961e+00\n",
      "    7.11566877e+00 6.29558182e+00]\n",
      "   [2.18888760e+00 2.61752439e+00 3.84370899e+00 ... 5.14817047e+00\n",
      "    7.96137714e+00 7.96865749e+00]\n",
      "   [2.18726873e+00 2.56882286e+00 2.62795329e+00 ... 4.11728954e+00\n",
      "    6.33051300e+00 5.60106468e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00000000e+00 1.01248845e-01 3.80741805e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [3.47778112e-01 5.12185335e-01 5.23400068e-01 ... 7.63493240e-01\n",
      "    9.36028361e-03 6.51458204e-02]\n",
      "   [2.37892270e-01 0.00000000e+00 6.85765207e-01 ... 4.38160121e-01\n",
      "    0.00000000e+00 3.61981660e-01]\n",
      "   ...\n",
      "   [1.57944351e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [3.96553338e-01 4.59979266e-01 1.82142556e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [4.74180400e-01 5.67082942e-01 5.54889917e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 3.43969129e-02]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 2.27627754e-02 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.51395991e-01 7.07046986e-01 1.03317130e+00 ... 7.07272291e-01\n",
      "    1.57026023e-01 0.00000000e+00]\n",
      "   [7.51218438e-01 6.15920901e-01 4.93486285e-01 ... 1.62529135e+00\n",
      "    2.50245905e+00 6.77129686e-01]\n",
      "   ...\n",
      "   [1.23136604e+00 1.05579925e+00 1.28499842e+00 ... 1.86028481e-02\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [6.55633152e-01 7.71340847e-01 7.74460673e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.30988821e-01 4.26023006e-01 2.50278533e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 4.54365686e-02 ... 1.27414525e-01\n",
      "    8.00419971e-02 1.42024666e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 7.09344000e-02 ... 5.38958132e-01\n",
      "    2.70261079e-01 2.69324750e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 1.28245860e-01 ... 0.00000000e+00\n",
      "    4.76176620e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [1.73644125e-02 6.62654281e-01 1.53448510e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 1.52076483e-02]\n",
      "   [0.00000000e+00 3.79943967e-01 1.11918986e+00 ... 7.39583313e-01\n",
      "    4.45294470e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 6.36404008e-03 ... 7.29544759e-02\n",
      "    4.66245472e-01 6.55090511e-02]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 5.55512905e-02 1.21832326e-01 ... 1.95341498e-01\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.16046622e-01 3.27587217e-01 2.82026917e-01 ... 3.87288392e-01\n",
      "    4.74050403e-01 5.70539951e-01]\n",
      "   [7.40075529e-01 6.94488764e-01 5.60813904e-01 ... 7.97301054e-01\n",
      "    1.00133324e+00 9.84840989e-01]\n",
      "   ...\n",
      "   [2.75124764e+00 3.82622290e+00 3.50927734e+00 ... 1.46784961e+00\n",
      "    1.64880013e+00 1.06901252e+00]\n",
      "   [2.41980839e+00 4.59412050e+00 4.16425467e+00 ... 8.68923128e-01\n",
      "    1.69764829e+00 1.38343191e+00]\n",
      "   [2.03918266e+00 2.59122181e+00 2.57117414e+00 ... 8.70916784e-01\n",
      "    5.02322912e-01 7.59068012e-01]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 4.46224995e-02\n",
      "    4.60248739e-02 1.42843977e-01]\n",
      "   [1.80280894e-01 1.11720011e-01 1.03530325e-02 ... 3.60177517e-01\n",
      "    5.88244319e-01 5.48055708e-01]\n",
      "   [4.33086336e-01 3.81942928e-01 1.20741442e-01 ... 1.59049749e-01\n",
      "    1.87309116e-01 9.74878371e-02]\n",
      "   ...\n",
      "   [5.34982443e-01 4.16235358e-01 6.71987653e-01 ... 7.04398870e-01\n",
      "    5.32866359e-01 3.39570865e-02]\n",
      "   [6.59395814e-01 3.78882915e-01 3.48803639e-01 ... 1.99039310e-01\n",
      "    3.29580784e-01 0.00000000e+00]\n",
      "   [6.43873140e-02 0.00000000e+00 0.00000000e+00 ... 1.74069762e-01\n",
      "    1.95846900e-01 0.00000000e+00]]\n",
      "\n",
      "  [[1.99017322e+00 2.53189659e+00 2.61554909e+00 ... 3.77395725e+00\n",
      "    3.75050974e+00 5.02650690e+00]\n",
      "   [3.33304453e+00 4.02199221e+00 3.83909297e+00 ... 4.65760612e+00\n",
      "    5.74992418e+00 5.06978512e+00]\n",
      "   [2.96229935e+00 4.36833000e+00 4.78798819e+00 ... 5.90359354e+00\n",
      "    5.61335754e+00 4.58098984e+00]\n",
      "   ...\n",
      "   [3.41839504e+00 4.30401087e+00 4.00673676e+00 ... 7.31423473e+00\n",
      "    7.49174595e+00 7.19132519e+00]\n",
      "   [2.62928772e+00 4.12013102e+00 3.56735063e+00 ... 3.08509827e+00\n",
      "    4.13509226e+00 5.06550980e+00]\n",
      "   [2.64984369e+00 3.66536713e+00 4.37577295e+00 ... 2.37959194e+00\n",
      "    1.76572180e+00 2.45953679e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 2.94071198e-01\n",
      "    8.24070036e-01 6.00410104e-01]\n",
      "   [0.00000000e+00 1.82687640e-02 4.70556855e-01 ... 1.09519899e+00\n",
      "    1.09652197e+00 5.63392401e-01]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 1.49974927e-01\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 2.65383929e-01\n",
      "    9.20065939e-02 0.00000000e+00]\n",
      "   [5.44075482e-02 0.00000000e+00 3.42497490e-02 ... 2.99070477e-01\n",
      "    1.40833706e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 1.05622113e-02 ... 9.58454013e-02\n",
      "    0.00000000e+00 6.94755986e-02]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 7.92712748e-01\n",
      "    9.95317042e-01 8.82099092e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 7.52023637e-01\n",
      "    6.30104542e-01 1.02457833e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 6.75854087e-01 ... 8.07358384e-01\n",
      "    8.99141014e-01 6.53136611e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 1.07828997e-01 ... 5.96834958e-01\n",
      "    1.05742455e+00 4.90641475e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 2.23228797e-01\n",
      "    4.34123784e-01 0.00000000e+00]]\n",
      "\n",
      "  [[1.12536728e-01 1.85717225e-01 8.84975567e-02 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.02121457e-01 3.37889880e-01 7.01524198e-01 ... 4.38047290e-01\n",
      "    3.86167347e-01 5.87922335e-01]\n",
      "   [5.94430745e-01 9.56499338e-01 1.02932954e+00 ... 1.10222089e+00\n",
      "    1.29932678e+00 1.97966933e+00]\n",
      "   ...\n",
      "   [6.55581355e-01 1.37303472e+00 1.30771661e+00 ... 1.37036180e+00\n",
      "    1.56573224e+00 2.27161312e+00]\n",
      "   [1.05480731e+00 8.93914342e-01 3.17737252e-01 ... 4.73452836e-01\n",
      "    7.65421808e-01 1.36658013e+00]\n",
      "   [1.24122918e+00 8.84173989e-01 3.55686367e-01 ... 3.87819558e-01\n",
      "    7.18837976e-01 4.32090998e-01]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 5.14609098e-01 ... 1.74660361e+00\n",
      "    1.73377085e+00 1.38192451e+00]\n",
      "   [0.00000000e+00 4.35321659e-01 1.50430894e+00 ... 2.64416122e+00\n",
      "    3.05327272e+00 1.63199258e+00]\n",
      "   [1.13033652e+00 1.79851842e+00 2.27450991e+00 ... 3.07588816e+00\n",
      "    3.09264660e+00 1.80212450e+00]\n",
      "   ...\n",
      "   [1.44788253e+00 1.94485545e+00 2.36521006e+00 ... 2.87604141e+00\n",
      "    1.36609232e+00 4.50808585e-01]\n",
      "   [1.39853799e+00 2.61941385e+00 4.42756605e+00 ... 1.83830643e+00\n",
      "    4.70707983e-01 8.25710371e-02]\n",
      "   [3.98768544e-01 1.02479243e+00 2.53090119e+00 ... 9.44443345e-01\n",
      "    1.20840728e-01 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 6.28843784e-01\n",
      "    5.08461237e-01 8.22339728e-02]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    5.62002301e-01 6.33501112e-02]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.66646630e-01 6.08619824e-02]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 2.23245710e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[3.08519363e+00 4.13730335e+00 2.11681342e+00 ... 7.74318337e-01\n",
      "    7.77671337e-01 1.45249367e+00]\n",
      "   [2.42382431e+00 3.12841010e+00 2.60485888e+00 ... 7.09272563e-01\n",
      "    9.55441654e-01 1.20019257e+00]\n",
      "   [1.69484997e+00 3.12121916e+00 4.12403107e+00 ... 1.60222304e+00\n",
      "    1.09781337e+00 1.35860634e+00]\n",
      "   ...\n",
      "   [3.53537989e+00 7.37788582e+00 8.59177113e+00 ... 5.99820042e+00\n",
      "    3.76717043e+00 2.12989330e+00]\n",
      "   [3.74528551e+00 7.33026981e+00 8.57229328e+00 ... 7.78991604e+00\n",
      "    4.49117661e+00 3.13209176e+00]\n",
      "   [3.17805910e+00 6.62985086e+00 8.59153748e+00 ... 6.25169754e+00\n",
      "    3.92545700e+00 3.09998369e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[4.07315418e-02 2.94651091e-02 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [3.50065947e-01 4.54916358e-02 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [3.56395841e-01 1.72396749e-02 7.85625428e-02 ... 0.00000000e+00\n",
      "    4.35394049e-02 5.44649661e-02]\n",
      "   ...\n",
      "   [5.13114274e-01 2.62079060e-01 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.87500894e-01 5.99996209e-01 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 2.38595814e-01]\n",
      "   [5.73775172e-02 4.70866710e-02 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 5.85133135e-02]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 1.74833763e+00\n",
      "    1.60305834e+00 1.39611930e-01]\n",
      "   [1.46919027e-01 3.40642989e-01 7.38825142e-01 ... 2.89023685e+00\n",
      "    1.15003014e+00 2.56190896e-01]\n",
      "   [1.19329464e+00 1.16351068e+00 9.75439191e-01 ... 1.74720836e+00\n",
      "    1.43983150e+00 5.07670522e-01]\n",
      "   ...\n",
      "   [8.39505672e-01 8.59709203e-01 9.58561897e-04 ... 2.08582103e-01\n",
      "    3.89855981e-01 1.02021344e-01]\n",
      "   [5.45158565e-01 0.00000000e+00 0.00000000e+00 ... 1.03454292e-02\n",
      "    5.72227538e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 2.64874250e-02 0.00000000e+00 ... 4.84409571e-01\n",
      "    7.28514254e-01 7.80541152e-02]]\n",
      "\n",
      "  [[9.29011311e-03 8.19072798e-02 1.17494231e-02 ... 1.30910110e+00\n",
      "    1.53211069e+00 9.11279798e-01]\n",
      "   [4.12151128e-01 6.20241761e-01 3.23496044e-01 ... 9.12613988e-01\n",
      "    1.38501406e+00 1.08084297e+00]\n",
      "   [7.14405894e-01 1.55567765e+00 1.31455052e+00 ... 7.01306760e-01\n",
      "    1.07731843e+00 6.14239693e-01]\n",
      "   ...\n",
      "   [2.46584579e-01 1.73007929e+00 1.49716949e+00 ... 1.71258390e+00\n",
      "    1.36866415e+00 1.72431469e-01]\n",
      "   [1.45635262e-01 1.07985544e+00 4.42533731e-01 ... 1.36447024e+00\n",
      "    1.08928144e+00 2.53813386e-01]\n",
      "   [2.18597800e-02 8.22420597e-01 8.59650493e-01 ... 8.29530716e-01\n",
      "    5.40445268e-01 2.23672539e-01]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 3.38703203e+00\n",
      "    1.76032400e+00 4.00436111e-02]\n",
      "   [0.00000000e+00 0.00000000e+00 2.93784887e-01 ... 4.79732418e+00\n",
      "    2.38045144e+00 3.27828228e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 8.62688124e-01 ... 2.67858362e+00\n",
      "    2.13050270e+00 3.51154774e-01]\n",
      "   ...\n",
      "   [1.19607612e-01 1.19773293e+00 2.91056633e+00 ... 2.45064139e+00\n",
      "    1.21959674e+00 1.73290923e-01]\n",
      "   [1.05191171e-01 8.28289151e-01 2.10831070e+00 ... 1.40767157e+00\n",
      "    2.96408832e-01 0.00000000e+00]\n",
      "   [3.70199502e-01 8.06755185e-01 5.66424072e-01 ... 2.60193292e-02\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[2.21496850e-01 0.00000000e+00 0.00000000e+00 ... 2.17734623e+00\n",
      "    1.64285445e+00 5.71742177e-01]\n",
      "   [8.56714845e-01 3.94289464e-01 0.00000000e+00 ... 3.84377861e+00\n",
      "    2.06818151e+00 9.30971682e-01]\n",
      "   [9.27684486e-01 1.30823660e+00 1.13343549e+00 ... 2.36758995e+00\n",
      "    1.99752176e+00 1.42293882e+00]\n",
      "   ...\n",
      "   [1.25069892e+00 1.59929514e+00 1.24791217e+00 ... 2.35186553e+00\n",
      "    1.30400217e+00 9.81752098e-01]\n",
      "   [8.76262128e-01 6.61035717e-01 1.76966667e+00 ... 1.96029997e+00\n",
      "    9.15546596e-01 1.04478741e+00]\n",
      "   [0.00000000e+00 2.74956971e-01 6.78531528e-01 ... 7.23664165e-01\n",
      "    6.28796101e-01 4.28803712e-01]]\n",
      "\n",
      "  [[1.18504119e+00 2.31038666e+00 3.03925371e+00 ... 2.57731915e-01\n",
      "    0.00000000e+00 6.10086203e-01]\n",
      "   [1.25441980e+00 2.10903263e+00 2.49170732e+00 ... 6.29946351e-01\n",
      "    2.11120725e-01 3.97609472e-02]\n",
      "   [1.25105953e+00 1.02361107e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    5.99486649e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [1.08315766e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.24295330e+00 1.34480810e+00]\n",
      "   [1.66198909e+00 0.00000000e+00 0.00000000e+00 ... 3.45839560e-01\n",
      "    1.18279445e+00 1.08507609e+00]\n",
      "   [1.94972599e+00 1.80321002e+00 2.03751183e+00 ... 1.30760813e+00\n",
      "    1.36173010e+00 6.86017990e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.12762094e-01 3.51024866e-01 0.00000000e+00 ... 1.24972187e-01\n",
      "    0.00000000e+00 5.95119953e-01]\n",
      "   [0.00000000e+00 4.39763725e-01 4.14060771e-01 ... 9.52929258e-01\n",
      "    3.08764875e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 7.47586191e-01 1.56700158e+00 ... 1.19419312e+00\n",
      "    6.80270791e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [4.17915493e-01 6.25357032e-01 8.40183020e-01 ... 5.74439526e-01\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [2.01757252e-01 5.64145207e-01 8.41121197e-01 ... 1.56547248e-01\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [3.12547356e-01 3.03065293e-02 3.76400858e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 2.73540050e-01 ... 8.75891447e-01\n",
      "    7.71571875e-01 3.48998189e-01]\n",
      "   [1.47167727e-01 6.21304154e-01 1.61076581e+00 ... 1.41601825e+00\n",
      "    1.22400486e+00 4.92221117e-01]\n",
      "   [3.53185296e-01 1.07992578e+00 2.17329907e+00 ... 2.08184266e+00\n",
      "    1.24917209e+00 3.29913318e-01]\n",
      "   ...\n",
      "   [1.15030444e+00 2.39922571e+00 1.47118330e+00 ... 3.24160993e-01\n",
      "    2.12125465e-01 0.00000000e+00]\n",
      "   [1.00848889e+00 1.78653860e+00 3.68232667e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [7.49280691e-01 6.36837363e-01 4.49407846e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 1.83241367e-02]\n",
      "   [3.19202185e-01 1.65868700e-01 0.00000000e+00 ... 3.53625089e-01\n",
      "    0.00000000e+00 5.93797028e-01]\n",
      "   [7.77375460e-01 7.51640975e-01 7.26850510e-01 ... 1.31712103e+00\n",
      "    7.59312928e-01 2.98873752e-01]\n",
      "   ...\n",
      "   [2.59700388e-01 7.78411269e-01 1.01604748e+00 ... 2.07247138e+00\n",
      "    1.67154956e+00 1.44249633e-01]\n",
      "   [0.00000000e+00 4.38700348e-01 1.13465834e+00 ... 9.04989958e-01\n",
      "    4.39739168e-01 1.06205702e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [9.00125027e-01 5.87229311e-01 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.85352600e+00 1.46896160e+00 1.12536120e+00 ... 3.90386611e-01\n",
      "    3.06656450e-01 1.92151457e-01]\n",
      "   ...\n",
      "   [1.61894226e+00 1.65214825e+00 2.13942099e+00 ... 6.63163126e-01\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.47468746e-02 4.44570221e-02 1.09106436e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    9.95407999e-02 8.24614614e-02]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [6.68560147e-01 5.80054700e-01 3.92742962e-01 ... 1.10411501e+00\n",
      "    9.14896786e-01 6.26444280e-01]\n",
      "   ...\n",
      "   [5.29324472e-01 3.34813595e-01 0.00000000e+00 ... 0.00000000e+00\n",
      "    2.18702018e-01 3.28336239e-01]\n",
      "   [4.30800095e-02 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[3.18110406e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 6.43730164e-05 ... 7.29410127e-02\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [3.13350767e-01 1.79054990e-01 5.62665761e-01 ... 1.29600906e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [3.26433957e-01 5.67229986e-01 1.08279634e+00 ... 1.24453735e+00\n",
      "    4.45118845e-02 0.00000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[6.26866817e-01 1.71618700e+00 3.26261282e+00 ... 2.19200754e+00\n",
      "    2.13297844e+00 1.86522269e+00]\n",
      "   [6.57636046e-01 1.92750120e+00 2.90067339e+00 ... 2.60911989e+00\n",
      "    3.41968727e+00 2.89302969e+00]\n",
      "   [1.11211240e+00 3.78539830e-01 1.34016740e+00 ... 2.56833124e+00\n",
      "    3.00477672e+00 1.86588359e+00]\n",
      "   ...\n",
      "   [2.84223747e+00 1.72774696e+00 3.17031920e-01 ... 6.41719460e-01\n",
      "    1.52587986e+00 1.69126976e+00]\n",
      "   [2.66106558e+00 2.30574703e+00 1.43773353e+00 ... 1.47520244e+00\n",
      "    1.98484433e+00 1.35650694e+00]\n",
      "   [1.74500263e+00 2.30503798e+00 9.15091932e-01 ... 2.01893854e+00\n",
      "    9.22176659e-01 7.47826278e-01]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 1.37398273e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [5.68873733e-02 1.53779447e-01 1.88760996e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 2.66777039e-01\n",
      "    3.61422956e-01 0.00000000e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.36945748e+00 1.01915574e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 2.29171664e-01\n",
      "    1.15578544e+00 6.55931354e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 1.72103927e-01 ... 2.18138561e-01\n",
      "    5.40704489e-01 2.27018416e-01]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    6.59787841e-03 1.31200448e-01]\n",
      "   [4.66722190e-01 8.90830100e-01 7.86777198e-01 ... 4.67431098e-02\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.71022868e+00 1.70205688e+00 2.70606232e+00 ... 1.44933271e+00\n",
      "    9.94663984e-02 0.00000000e+00]\n",
      "   ...\n",
      "   [1.64259005e+00 1.16157365e+00 1.52915061e+00 ... 7.15507925e-01\n",
      "    4.66894627e-01 5.16050339e-01]\n",
      "   [3.58681619e-01 4.20237154e-01 4.85955805e-01 ... 1.19052552e-01\n",
      "    3.31622094e-01 6.34687245e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    3.43105078e-01 1.80010825e-01]]]\n",
      "\n",
      "\n",
      " [[[3.75678599e-01 6.23176873e-01 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 5.13247252e-02]\n",
      "   [1.02346659e+00 8.41145158e-01 2.41493270e-01 ... 3.25752556e-01\n",
      "    3.91974390e-01 1.75023764e-01]\n",
      "   [8.19678426e-01 4.04689252e-01 2.90538549e-01 ... 1.03628528e+00\n",
      "    1.57969666e+00 1.54522491e+00]\n",
      "   ...\n",
      "   [3.68412554e-01 7.53560305e-01 4.38117355e-01 ... 1.06537747e+00\n",
      "    1.42509174e+00 1.29873717e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 2.25358531e-01\n",
      "    1.05862156e-01 1.86739132e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    3.14494371e-02 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 1.85491264e-01 5.14499009e-01 ... 4.37951386e-01\n",
      "    2.43855745e-01 1.34231299e-01]\n",
      "   ...\n",
      "   [6.05657697e-05 8.45985532e-01 9.49050844e-01 ... 1.56624603e+00\n",
      "    1.22473574e+00 7.54031301e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 1.02780473e+00\n",
      "    9.39171910e-01 1.03748822e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    6.30821809e-02 9.27882791e-02]]\n",
      "\n",
      "  [[2.14229584e+00 1.33418393e+00 3.39271665e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.97937763e+00 1.59541643e+00 1.85492903e-01 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [1.80638337e+00 1.14853513e+00 1.07631338e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   ...\n",
      "   [4.15570617e-01 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 8.20807517e-02]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    0.00000000e+00 1.90916628e-01]\n",
      "   [9.79159534e-01 1.33588016e-02 0.00000000e+00 ... 0.00000000e+00\n",
      "    3.49074781e-01 1.41029447e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.34489030e-01 5.48053645e-02 2.88178399e-02 ... 0.00000000e+00\n",
      "    0.00000000e+00 0.00000000e+00]\n",
      "   [3.58378649e-01 1.27784193e+00 1.05326462e+00 ... 6.33899927e-01\n",
      "    4.55242962e-01 0.00000000e+00]\n",
      "   [9.66873050e-01 6.17526054e-01 5.11544287e-01 ... 7.24110365e-01\n",
      "    4.79640484e-01 3.52772653e-01]\n",
      "   ...\n",
      "   [2.25502878e-01 7.37333298e-01 6.89847827e-01 ... 7.94446409e-01\n",
      "    9.48933542e-01 4.58682626e-01]\n",
      "   [1.60477296e-01 3.07252884e-01 5.77374041e-01 ... 6.07259750e-01\n",
      "    4.23939884e-01 9.38916206e-01]\n",
      "   [7.01187477e-02 3.65321904e-01 3.34585905e-01 ... 5.04749060e-01\n",
      "    1.36962843e+00 5.97665846e-01]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 0.00000000e+00\n",
      "    1.27401933e-01 2.75657296e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 1.28324485e+00\n",
      "    1.33107507e+00 1.42223716e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 9.21885431e-01 ... 1.01058507e+00\n",
      "    1.56290460e+00 1.91113734e+00]\n",
      "   ...\n",
      "   [0.00000000e+00 6.93976998e-01 1.30653024e+00 ... 8.76341343e-01\n",
      "    1.72476351e-01 6.96518064e-01]\n",
      "   [0.00000000e+00 3.03519785e-01 8.39614570e-02 ... 3.35501730e-02\n",
      "    3.65525633e-02 3.96014154e-01]\n",
      "   [0.00000000e+00 7.61310399e-01 9.50142205e-01 ... 4.29477036e-01\n",
      "    1.89235538e-01 1.28751293e-01]]\n",
      "\n",
      "  [[1.09963566e-01 0.00000000e+00 0.00000000e+00 ... 7.09319830e-01\n",
      "    6.11239016e-01 5.56220174e-01]\n",
      "   [2.26894766e-03 3.71787757e-01 5.90598583e-01 ... 1.40480638e+00\n",
      "    1.47905266e+00 7.99979210e-01]\n",
      "   [6.70535043e-02 3.18579853e-01 8.58125031e-01 ... 2.18514276e+00\n",
      "    2.20248079e+00 1.44863033e+00]\n",
      "   ...\n",
      "   [3.00460076e-03 6.75668955e-01 8.41737092e-01 ... 1.42015314e+00\n",
      "    1.55290186e+00 9.44043815e-01]\n",
      "   [2.95199156e-01 5.47617495e-01 1.12101269e+00 ... 1.96151507e+00\n",
      "    9.87273514e-01 3.96981984e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 3.35563928e-01 ... 6.27448916e-01\n",
      "    7.89714679e-02 0.00000000e+00]]]] (11788, 2048, 7, 7)\n"
     ]
    }
   ],
   "source": [
    "all_features = []\n",
    "for i_batch, imgs in enumerate(dataset_loader):\n",
    "    print(i_batch)\n",
    "    #pdb.set_trace()\n",
    "    #imgs = imgs.to(device)\n",
    "    features = model_f(imgs)\n",
    "    all_features.append(features.numpy())\n",
    "    \n",
    "all_features = np.concatenate(all_features, axis=0)\n",
    "print(all_features, all_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee639a91",
   "metadata": {},
   "source": [
    "# Let's extract semantic attributes of each category (consider pre-trained word2vec model with no fine-tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "566d27b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrain w2v model\n",
      "Done replacing OOD words\n",
      "Done preprocessing attribute des\n"
     ]
    }
   ],
   "source": [
    "print('Load pretrain w2v model')\n",
    "\n",
    "model_name = 'word2vec-google-news-300'#best model\n",
    "model = api.load(model_name)\n",
    "\n",
    "dim_w2v = 300\n",
    "\n",
    "#%%\n",
    "replace_word = [('spatulate','broad'),('upperparts','upper parts'),('grey','gray')] # for CUB\n",
    "\n",
    "\n",
    "path = 'C:/Sushree/Jio_Institute/Dataset/CUB_200_2011/CUB_200_2011/attributes/attributes.txt'\n",
    "df=pd.read_csv(path,sep=' ',header = None, names = ['idx','des'])\n",
    "des = df['des'].values\n",
    "\n",
    "#%% filter\n",
    "new_des = [' '.join(i.split('_')) for i in des]\n",
    "new_des = [' '.join(i.split('-')) for i in new_des]\n",
    "new_des = [' '.join(i.split('::')) for i in new_des]\n",
    "new_des = [i.split('(')[0] for i in new_des]\n",
    "new_des = [i[4:] for i in new_des]\n",
    "\n",
    "#%% replace out of dictionary (OOD) words\n",
    "for pair in replace_word:\n",
    "    for idx,s in enumerate(des):\n",
    "        des[idx] = s.replace(pair[0],pair[1])\n",
    "print('Done replacing OOD words')\n",
    "\n",
    "df['new_des'] = des\n",
    "df.to_csv('C:/Sushree/Jio_Institute/Dataset/CUB_200_2011/CUB_200_2011/attributes/new_des.csv')\n",
    "print('Done preprocessing attribute des')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3426bda5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bill shape curved \n",
      "bill shape dagger\n",
      "bill shape hooked\n",
      "bill shape needle\n",
      "bill shape hooked seabird\n",
      "bill shape spatulate\n",
      "\"Key 'spatulate' not present\"\n",
      "bill shape all purpose\n",
      "bill shape cone\n",
      "bill shape specialized\n",
      "wing color blue\n",
      "wing color brown\n",
      "wing color iridescent\n",
      "wing color purple\n",
      "wing color rufous\n",
      "wing color grey\n",
      "\"Key 'grey' not present\"\n",
      "wing color yellow\n",
      "wing color olive\n",
      "wing color green\n",
      "wing color pink\n",
      "wing color orange\n",
      "wing color black\n",
      "wing color white\n",
      "wing color red\n",
      "wing color buff\n",
      "upperparts color blue\n",
      "\"Key 'upperparts' not present\"\n",
      "upperparts color brown\n",
      "\"Key 'upperparts' not present\"\n",
      "upperparts color iridescent\n",
      "\"Key 'upperparts' not present\"\n",
      "upperparts color purple\n",
      "\"Key 'upperparts' not present\"\n",
      "upperparts color rufous\n",
      "\"Key 'upperparts' not present\"\n",
      "upperparts color grey\n",
      "\"Key 'upperparts' not present\"\n",
      "\"Key 'grey' not present\"\n",
      "upperparts color yellow\n",
      "\"Key 'upperparts' not present\"\n",
      "upperparts color olive\n",
      "\"Key 'upperparts' not present\"\n",
      "upperparts color green\n",
      "\"Key 'upperparts' not present\"\n",
      "upperparts color pink\n",
      "\"Key 'upperparts' not present\"\n",
      "upperparts color orange\n",
      "\"Key 'upperparts' not present\"\n",
      "upperparts color black\n",
      "\"Key 'upperparts' not present\"\n",
      "upperparts color white\n",
      "\"Key 'upperparts' not present\"\n",
      "upperparts color red\n",
      "\"Key 'upperparts' not present\"\n",
      "upperparts color buff\n",
      "\"Key 'upperparts' not present\"\n",
      "underparts color blue\n",
      "underparts color brown\n",
      "underparts color iridescent\n",
      "underparts color purple\n",
      "underparts color rufous\n",
      "underparts color grey\n",
      "\"Key 'grey' not present\"\n",
      "underparts color yellow\n",
      "underparts color olive\n",
      "underparts color green\n",
      "underparts color pink\n",
      "underparts color orange\n",
      "underparts color black\n",
      "underparts color white\n",
      "underparts color red\n",
      "underparts color buff\n",
      "breast pattern solid\n",
      "breast pattern spotted\n",
      "breast pattern striped\n",
      "breast pattern multi colored\n",
      "back color blue\n",
      "back color brown\n",
      "back color iridescent\n",
      "back color purple\n",
      "back color rufous\n",
      "back color grey\n",
      "\"Key 'grey' not present\"\n",
      "back color yellow\n",
      "back color olive\n",
      "back color green\n",
      "back color pink\n",
      "back color orange\n",
      "back color black\n",
      "back color white\n",
      "back color red\n",
      "back color buff\n",
      "tail shape forked tail\n",
      "tail shape rounded tail\n",
      "tail shape notched tail\n",
      "tail shape fan shaped tail\n",
      "tail shape pointed tail\n",
      "tail shape squared tail\n",
      "upper tail color blue\n",
      "upper tail color brown\n",
      "upper tail color iridescent\n",
      "upper tail color purple\n",
      "upper tail color rufous\n",
      "upper tail color grey\n",
      "\"Key 'grey' not present\"\n",
      "upper tail color yellow\n",
      "upper tail color olive\n",
      "upper tail color green\n",
      "upper tail color pink\n",
      "upper tail color orange\n",
      "upper tail color black\n",
      "upper tail color white\n",
      "upper tail color red\n",
      "upper tail color buff\n",
      "head pattern spotted\n",
      "head pattern malar\n",
      "head pattern crested\n",
      "head pattern masked\n",
      "head pattern unique pattern\n",
      "head pattern eyebrow\n",
      "head pattern eyering\n",
      "\"Key 'eyering' not present\"\n",
      "head pattern plain\n",
      "head pattern eyeline\n",
      "head pattern striped\n",
      "head pattern capped\n",
      "breast color blue\n",
      "breast color brown\n",
      "breast color iridescent\n",
      "breast color purple\n",
      "breast color rufous\n",
      "breast color grey\n",
      "\"Key 'grey' not present\"\n",
      "breast color yellow\n",
      "breast color olive\n",
      "breast color green\n",
      "breast color pink\n",
      "breast color orange\n",
      "breast color black\n",
      "breast color white\n",
      "breast color red\n",
      "breast color buff\n",
      "throat color blue\n",
      "throat color brown\n",
      "throat color iridescent\n",
      "throat color purple\n",
      "throat color rufous\n",
      "throat color grey\n",
      "\"Key 'grey' not present\"\n",
      "throat color yellow\n",
      "throat color olive\n",
      "throat color green\n",
      "throat color pink\n",
      "throat color orange\n",
      "throat color black\n",
      "throat color white\n",
      "throat color red\n",
      "throat color buff\n",
      "eye color blue\n",
      "eye color brown\n",
      "eye color purple\n",
      "eye color rufous\n",
      "eye color grey\n",
      "\"Key 'grey' not present\"\n",
      "eye color yellow\n",
      "eye color olive\n",
      "eye color green\n",
      "eye color pink\n",
      "eye color orange\n",
      "eye color black\n",
      "eye color white\n",
      "eye color red\n",
      "eye color buff\n",
      "bill length about the same as head\n",
      "bill length longer than head\n",
      "bill length shorter than head\n",
      "forehead color blue\n",
      "forehead color brown\n",
      "forehead color iridescent\n",
      "forehead color purple\n",
      "forehead color rufous\n",
      "forehead color grey\n",
      "\"Key 'grey' not present\"\n",
      "forehead color yellow\n",
      "forehead color olive\n",
      "forehead color green\n",
      "forehead color pink\n",
      "forehead color orange\n",
      "forehead color black\n",
      "forehead color white\n",
      "forehead color red\n",
      "forehead color buff\n",
      "under tail color blue\n",
      "under tail color brown\n",
      "under tail color iridescent\n",
      "under tail color purple\n",
      "under tail color rufous\n",
      "under tail color grey\n",
      "\"Key 'grey' not present\"\n",
      "under tail color yellow\n",
      "under tail color olive\n",
      "under tail color green\n",
      "under tail color pink\n",
      "under tail color orange\n",
      "under tail color black\n",
      "under tail color white\n",
      "under tail color red\n",
      "under tail color buff\n",
      "nape color blue\n",
      "nape color brown\n",
      "nape color iridescent\n",
      "nape color purple\n",
      "nape color rufous\n",
      "nape color grey\n",
      "\"Key 'grey' not present\"\n",
      "nape color yellow\n",
      "nape color olive\n",
      "nape color green\n",
      "nape color pink\n",
      "nape color orange\n",
      "nape color black\n",
      "nape color white\n",
      "nape color red\n",
      "nape color buff\n",
      "belly color blue\n",
      "belly color brown\n",
      "belly color iridescent\n",
      "belly color purple\n",
      "belly color rufous\n",
      "belly color grey\n",
      "\"Key 'grey' not present\"\n",
      "belly color yellow\n",
      "belly color olive\n",
      "belly color green\n",
      "belly color pink\n",
      "belly color orange\n",
      "belly color black\n",
      "belly color white\n",
      "belly color red\n",
      "belly color buff\n",
      "wing shape rounded wings\n",
      "wing shape pointed wings\n",
      "wing shape broad wings\n",
      "wing shape tapered wings\n",
      "wing shape long wings\n",
      "size large \n",
      "size small \n",
      "size very large \n",
      "size medium \n",
      "size very small \n",
      "shape upright perching water like\n",
      "shape chicken like marsh\n",
      "shape long legged like\n",
      "shape duck like\n",
      "shape owl like\n",
      "shape gull like\n",
      "shape hummingbird like\n",
      "shape pigeon like\n",
      "shape tree clinging like\n",
      "shape hawk like\n",
      "shape sandpiper like\n",
      "shape upland ground like\n",
      "shape swallow like\n",
      "shape perching like\n",
      "back pattern solid\n",
      "back pattern spotted\n",
      "back pattern striped\n",
      "back pattern multi colored\n",
      "tail pattern solid\n",
      "tail pattern spotted\n",
      "tail pattern striped\n",
      "tail pattern multi colored\n",
      "belly pattern solid\n",
      "belly pattern spotted\n",
      "belly pattern striped\n",
      "belly pattern multi colored\n",
      "primary color blue\n",
      "primary color brown\n",
      "primary color iridescent\n",
      "primary color purple\n",
      "primary color rufous\n",
      "primary color grey\n",
      "\"Key 'grey' not present\"\n",
      "primary color yellow\n",
      "primary color olive\n",
      "primary color green\n",
      "primary color pink\n",
      "primary color orange\n",
      "primary color black\n",
      "primary color white\n",
      "primary color red\n",
      "primary color buff\n",
      "leg color blue\n",
      "leg color brown\n",
      "leg color iridescent\n",
      "leg color purple\n",
      "leg color rufous\n",
      "leg color grey\n",
      "\"Key 'grey' not present\"\n",
      "leg color yellow\n",
      "leg color olive\n",
      "leg color green\n",
      "leg color pink\n",
      "leg color orange\n",
      "leg color black\n",
      "leg color white\n",
      "leg color red\n",
      "leg color buff\n",
      "bill color blue\n",
      "bill color brown\n",
      "bill color iridescent\n",
      "bill color purple\n",
      "bill color rufous\n",
      "bill color grey\n",
      "\"Key 'grey' not present\"\n",
      "bill color yellow\n",
      "bill color olive\n",
      "bill color green\n",
      "bill color pink\n",
      "bill color orange\n",
      "bill color black\n",
      "bill color white\n",
      "bill color red\n",
      "bill color buff\n",
      "crown color blue\n",
      "crown color brown\n",
      "crown color iridescent\n",
      "crown color purple\n",
      "crown color rufous\n",
      "crown color grey\n",
      "\"Key 'grey' not present\"\n",
      "crown color yellow\n",
      "crown color olive\n",
      "crown color green\n",
      "crown color pink\n",
      "crown color orange\n",
      "crown color black\n",
      "crown color white\n",
      "crown color red\n",
      "crown color buff\n",
      "wing pattern solid\n",
      "wing pattern spotted\n",
      "wing pattern striped\n",
      "wing pattern multi colored\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_w2v = []\n",
    "for s in new_des:\n",
    "    print(s)\n",
    "    words = s.split(' ')\n",
    "    if words[-1] == '':     #remove empty element\n",
    "        words = words[:-1]\n",
    "    w2v = np.zeros(dim_w2v)\n",
    "    for w in words:\n",
    "        try:\n",
    "            w2v += model[w]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "    all_w2v.append(w2v[np.newaxis,:])\n",
    "    \n",
    "#%%\n",
    "all_w2v=np.concatenate(all_w2v,axis=0)\n",
    "#pdb.set_trace()\n",
    "#%%\n",
    "\n",
    "with open('C:/Sushree/Jio_Institute/Dataset/CUB_200_2011/CUB_200_2011/w2v/CUB_attribute.pkl','wb') as f:\n",
    "    pickle.dump(all_w2v,f)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f02655a5",
   "metadata": {},
   "source": [
    "# Read the attributes and save as \"w2v_att\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9433e41e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "save w2v_att\n",
      "[[-0.171875    0.4831543  -0.16796875 ... -0.29199219  0.16931152\n",
      "  -0.11865234]\n",
      " [ 0.1484375   0.72070312  0.10888672 ... -0.30664062  0.23181152\n",
      "   0.55566406]\n",
      " [ 0.05126953  0.4831543  -0.33251953 ... -0.31347656  0.41101074\n",
      "  -0.21875   ]\n",
      " ...\n",
      " [ 0.17169189  0.44824219 -0.44018555 ... -0.40661621 -0.20285034\n",
      "   0.43066406]\n",
      " [-0.02508545  0.26171875 -0.30932617 ... -0.24353027 -0.17749023\n",
      "   0.38037109]\n",
      " [-0.02105713  0.12207031 -0.20239258 ... -0.1940918  -0.11444092\n",
      "  -0.10351562]] (312, 300)\n"
     ]
    }
   ],
   "source": [
    "attribute_path = 'C:/Sushree/Jio_Institute/Dataset/CUB_200_2011/CUB_200_2011/w2v/CUB_attribute.pkl'\n",
    "\n",
    "with open(attribute_path,'rb') as f:\n",
    "    w2v_att = pickle.load(f)\n",
    "assert w2v_att.shape == (312,300) # for AWA2\n",
    "print('save w2v_att')\n",
    "\n",
    "print(w2v_att, w2v_att.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b633a585",
   "metadata": {},
   "source": [
    "# Let's gather additional information (training, validation, and test indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5944826f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Sushree/Jio_Institute/Dataset/data/xlsa17/data/CUB/att_splits.mat\n"
     ]
    }
   ],
   "source": [
    "#%% get remaining metadata\n",
    "matcontent = CUBDataset.matcontent\n",
    "labels = matcontent['labels'].astype(int).squeeze() - 1\n",
    "\n",
    "split_path = 'C:/Sushree/Jio_Institute/Dataset/data/xlsa17/data/CUB/att_splits.mat'\n",
    "print(split_path)\n",
    "    \n",
    "#att_splits.mat includes the following fields:\n",
    "#-att: columns correpond to class attribute vectors normalized to have unit l2 norm, following the classes order in allclasses.txt \n",
    "#-original_att: the original class attribute vectors without normalization\n",
    "#-trainval_loc: instances indexes of train+val set features (for only seen classes) in resNet101.mat\n",
    "#-test_seen_loc: instances indexes of test set features for seen classes\n",
    "#-test_unseen_loc: instances indexes of test set features for unseen classes    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "03737527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'__header__': b'MATLAB 5.0 MAT-file, Platform: GLNXA64, Created on: Fri Aug 21 10:34:24 2020', '__version__': '1.0', '__globals__': [], 'allclasses_names': array([[array(['002.Laysan_Albatross'], dtype='<U20')],\n",
      "       [array(['003.Sooty_Albatross'], dtype='<U19')],\n",
      "       [array(['005.Crested_Auklet'], dtype='<U18')],\n",
      "       [array(['007.Parakeet_Auklet'], dtype='<U19')],\n",
      "       [array(['010.Red_winged_Blackbird'], dtype='<U24')],\n",
      "       [array(['011.Rusty_Blackbird'], dtype='<U19')],\n",
      "       [array(['012.Yellow_headed_Blackbird'], dtype='<U27')],\n",
      "       [array(['013.Bobolink'], dtype='<U12')],\n",
      "       [array(['015.Lazuli_Bunting'], dtype='<U18')],\n",
      "       [array(['016.Painted_Bunting'], dtype='<U19')],\n",
      "       [array(['017.Cardinal'], dtype='<U12')],\n",
      "       [array(['018.Spotted_Catbird'], dtype='<U19')],\n",
      "       [array(['019.Gray_Catbird'], dtype='<U16')],\n",
      "       [array(['020.Yellow_breasted_Chat'], dtype='<U24')],\n",
      "       [array(['021.Eastern_Towhee'], dtype='<U18')],\n",
      "       [array(['022.Chuck_will_Widow'], dtype='<U20')],\n",
      "       [array(['024.Red_faced_Cormorant'], dtype='<U23')],\n",
      "       [array(['025.Pelagic_Cormorant'], dtype='<U21')],\n",
      "       [array(['026.Bronzed_Cowbird'], dtype='<U19')],\n",
      "       [array(['027.Shiny_Cowbird'], dtype='<U17')],\n",
      "       [array(['028.Brown_Creeper'], dtype='<U17')],\n",
      "       [array(['030.Fish_Crow'], dtype='<U13')],\n",
      "       [array(['032.Mangrove_Cuckoo'], dtype='<U19')],\n",
      "       [array(['039.Least_Flycatcher'], dtype='<U20')],\n",
      "       [array(['040.Olive_sided_Flycatcher'], dtype='<U26')],\n",
      "       [array(['041.Scissor_tailed_Flycatcher'], dtype='<U29')],\n",
      "       [array(['042.Vermilion_Flycatcher'], dtype='<U24')],\n",
      "       [array(['044.Frigatebird'], dtype='<U15')],\n",
      "       [array(['045.Northern_Fulmar'], dtype='<U19')],\n",
      "       [array(['046.Gadwall'], dtype='<U11')],\n",
      "       [array(['047.American_Goldfinch'], dtype='<U22')],\n",
      "       [array(['048.European_Goldfinch'], dtype='<U22')],\n",
      "       [array(['050.Eared_Grebe'], dtype='<U15')],\n",
      "       [array(['052.Pied_billed_Grebe'], dtype='<U21')],\n",
      "       [array(['054.Blue_Grosbeak'], dtype='<U17')],\n",
      "       [array(['055.Evening_Grosbeak'], dtype='<U20')],\n",
      "       [array(['056.Pine_Grosbeak'], dtype='<U17')],\n",
      "       [array(['057.Rose_breasted_Grosbeak'], dtype='<U26')],\n",
      "       [array(['058.Pigeon_Guillemot'], dtype='<U20')],\n",
      "       [array(['059.California_Gull'], dtype='<U19')],\n",
      "       [array(['060.Glaucous_winged_Gull'], dtype='<U24')],\n",
      "       [array(['061.Heermann_Gull'], dtype='<U17')],\n",
      "       [array(['062.Herring_Gull'], dtype='<U16')],\n",
      "       [array(['063.Ivory_Gull'], dtype='<U14')],\n",
      "       [array(['064.Ring_billed_Gull'], dtype='<U20')],\n",
      "       [array(['065.Slaty_backed_Gull'], dtype='<U21')],\n",
      "       [array(['067.Anna_Hummingbird'], dtype='<U20')],\n",
      "       [array(['068.Ruby_throated_Hummingbird'], dtype='<U29')],\n",
      "       [array(['069.Rufous_Hummingbird'], dtype='<U22')],\n",
      "       [array(['070.Green_Violetear'], dtype='<U19')],\n",
      "       [array(['071.Long_tailed_Jaeger'], dtype='<U22')],\n",
      "       [array(['073.Blue_Jay'], dtype='<U12')],\n",
      "       [array(['074.Florida_Jay'], dtype='<U15')],\n",
      "       [array(['075.Green_Jay'], dtype='<U13')],\n",
      "       [array(['076.Dark_eyed_Junco'], dtype='<U19')],\n",
      "       [array(['077.Tropical_Kingbird'], dtype='<U21')],\n",
      "       [array(['078.Gray_Kingbird'], dtype='<U17')],\n",
      "       [array(['080.Green_Kingfisher'], dtype='<U20')],\n",
      "       [array(['081.Pied_Kingfisher'], dtype='<U19')],\n",
      "       [array(['082.Ringed_Kingfisher'], dtype='<U21')],\n",
      "       [array(['085.Horned_Lark'], dtype='<U15')],\n",
      "       [array(['087.Mallard'], dtype='<U11')],\n",
      "       [array(['088.Western_Meadowlark'], dtype='<U22')],\n",
      "       [array(['089.Hooded_Merganser'], dtype='<U20')],\n",
      "       [array(['090.Red_breasted_Merganser'], dtype='<U26')],\n",
      "       [array(['092.Nighthawk'], dtype='<U13')],\n",
      "       [array(['093.Clark_Nutcracker'], dtype='<U20')],\n",
      "       [array(['094.White_breasted_Nuthatch'], dtype='<U27')],\n",
      "       [array(['097.Orchard_Oriole'], dtype='<U18')],\n",
      "       [array(['099.Ovenbird'], dtype='<U12')],\n",
      "       [array(['100.Brown_Pelican'], dtype='<U17')],\n",
      "       [array(['104.American_Pipit'], dtype='<U18')],\n",
      "       [array(['105.Whip_poor_Will'], dtype='<U18')],\n",
      "       [array(['106.Horned_Puffin'], dtype='<U17')],\n",
      "       [array(['107.Common_Raven'], dtype='<U16')],\n",
      "       [array(['108.White_necked_Raven'], dtype='<U22')],\n",
      "       [array(['109.American_Redstart'], dtype='<U21')],\n",
      "       [array(['110.Geococcyx'], dtype='<U13')],\n",
      "       [array(['111.Loggerhead_Shrike'], dtype='<U21')],\n",
      "       [array(['113.Baird_Sparrow'], dtype='<U17')],\n",
      "       [array(['115.Brewer_Sparrow'], dtype='<U18')],\n",
      "       [array(['116.Chipping_Sparrow'], dtype='<U20')],\n",
      "       [array(['117.Clay_colored_Sparrow'], dtype='<U24')],\n",
      "       [array(['118.House_Sparrow'], dtype='<U17')],\n",
      "       [array(['120.Fox_Sparrow'], dtype='<U15')],\n",
      "       [array(['122.Harris_Sparrow'], dtype='<U18')],\n",
      "       [array(['123.Henslow_Sparrow'], dtype='<U19')],\n",
      "       [array(['124.Le_Conte_Sparrow'], dtype='<U20')],\n",
      "       [array(['125.Lincoln_Sparrow'], dtype='<U19')],\n",
      "       [array(['126.Nelson_Sharp_tailed_Sparrow'], dtype='<U31')],\n",
      "       [array(['127.Savannah_Sparrow'], dtype='<U20')],\n",
      "       [array(['128.Seaside_Sparrow'], dtype='<U19')],\n",
      "       [array(['129.Song_Sparrow'], dtype='<U16')],\n",
      "       [array(['131.Vesper_Sparrow'], dtype='<U18')],\n",
      "       [array(['132.White_crowned_Sparrow'], dtype='<U25')],\n",
      "       [array(['133.White_throated_Sparrow'], dtype='<U26')],\n",
      "       [array(['134.Cape_Glossy_Starling'], dtype='<U24')],\n",
      "       [array(['136.Barn_Swallow'], dtype='<U16')],\n",
      "       [array(['137.Cliff_Swallow'], dtype='<U17')],\n",
      "       [array(['139.Scarlet_Tanager'], dtype='<U19')],\n",
      "       [array(['140.Summer_Tanager'], dtype='<U18')],\n",
      "       [array(['141.Artic_Tern'], dtype='<U14')],\n",
      "       [array(['142.Black_Tern'], dtype='<U14')],\n",
      "       [array(['143.Caspian_Tern'], dtype='<U16')],\n",
      "       [array(['144.Common_Tern'], dtype='<U15')],\n",
      "       [array(['145.Elegant_Tern'], dtype='<U16')],\n",
      "       [array(['146.Forsters_Tern'], dtype='<U17')],\n",
      "       [array(['148.Green_tailed_Towhee'], dtype='<U23')],\n",
      "       [array(['149.Brown_Thrasher'], dtype='<U18')],\n",
      "       [array(['150.Sage_Thrasher'], dtype='<U17')],\n",
      "       [array(['151.Black_capped_Vireo'], dtype='<U22')],\n",
      "       [array(['152.Blue_headed_Vireo'], dtype='<U21')],\n",
      "       [array(['153.Philadelphia_Vireo'], dtype='<U22')],\n",
      "       [array(['154.Red_eyed_Vireo'], dtype='<U18')],\n",
      "       [array(['155.Warbling_Vireo'], dtype='<U18')],\n",
      "       [array(['157.Yellow_throated_Vireo'], dtype='<U25')],\n",
      "       [array(['158.Bay_breasted_Warbler'], dtype='<U24')],\n",
      "       [array(['159.Black_and_white_Warbler'], dtype='<U27')],\n",
      "       [array(['160.Black_throated_Blue_Warbler'], dtype='<U31')],\n",
      "       [array(['161.Blue_winged_Warbler'], dtype='<U23')],\n",
      "       [array(['162.Canada_Warbler'], dtype='<U18')],\n",
      "       [array(['164.Cerulean_Warbler'], dtype='<U20')],\n",
      "       [array(['167.Hooded_Warbler'], dtype='<U18')],\n",
      "       [array(['168.Kentucky_Warbler'], dtype='<U20')],\n",
      "       [array(['169.Magnolia_Warbler'], dtype='<U20')],\n",
      "       [array(['170.Mourning_Warbler'], dtype='<U20')],\n",
      "       [array(['171.Myrtle_Warbler'], dtype='<U18')],\n",
      "       [array(['172.Nashville_Warbler'], dtype='<U21')],\n",
      "       [array(['173.Orange_crowned_Warbler'], dtype='<U26')],\n",
      "       [array(['174.Palm_Warbler'], dtype='<U16')],\n",
      "       [array(['175.Pine_Warbler'], dtype='<U16')],\n",
      "       [array(['176.Prairie_Warbler'], dtype='<U19')],\n",
      "       [array(['177.Prothonotary_Warbler'], dtype='<U24')],\n",
      "       [array(['178.Swainson_Warbler'], dtype='<U20')],\n",
      "       [array(['179.Tennessee_Warbler'], dtype='<U21')],\n",
      "       [array(['181.Worm_eating_Warbler'], dtype='<U23')],\n",
      "       [array(['182.Yellow_Warbler'], dtype='<U18')],\n",
      "       [array(['184.Louisiana_Waterthrush'], dtype='<U25')],\n",
      "       [array(['188.Pileated_Woodpecker'], dtype='<U23')],\n",
      "       [array(['189.Red_bellied_Woodpecker'], dtype='<U26')],\n",
      "       [array(['190.Red_cockaded_Woodpecker'], dtype='<U27')],\n",
      "       [array(['191.Red_headed_Woodpecker'], dtype='<U25')],\n",
      "       [array(['192.Downy_Woodpecker'], dtype='<U20')],\n",
      "       [array(['193.Bewick_Wren'], dtype='<U15')],\n",
      "       [array(['194.Cactus_Wren'], dtype='<U15')],\n",
      "       [array(['195.Carolina_Wren'], dtype='<U17')],\n",
      "       [array(['196.House_Wren'], dtype='<U14')],\n",
      "       [array(['198.Rock_Wren'], dtype='<U13')],\n",
      "       [array(['199.Winter_Wren'], dtype='<U15')],\n",
      "       [array(['200.Common_Yellowthroat'], dtype='<U23')],\n",
      "       [array(['001.Black_footed_Albatross'], dtype='<U26')],\n",
      "       [array(['004.Groove_billed_Ani'], dtype='<U21')],\n",
      "       [array(['006.Least_Auklet'], dtype='<U16')],\n",
      "       [array(['008.Rhinoceros_Auklet'], dtype='<U21')],\n",
      "       [array(['009.Brewer_Blackbird'], dtype='<U20')],\n",
      "       [array(['014.Indigo_Bunting'], dtype='<U18')],\n",
      "       [array(['023.Brandt_Cormorant'], dtype='<U20')],\n",
      "       [array(['029.American_Crow'], dtype='<U17')],\n",
      "       [array(['031.Black_billed_Cuckoo'], dtype='<U23')],\n",
      "       [array(['033.Yellow_billed_Cuckoo'], dtype='<U24')],\n",
      "       [array(['034.Gray_crowned_Rosy_Finch'], dtype='<U27')],\n",
      "       [array(['035.Purple_Finch'], dtype='<U16')],\n",
      "       [array(['036.Northern_Flicker'], dtype='<U20')],\n",
      "       [array(['037.Acadian_Flycatcher'], dtype='<U22')],\n",
      "       [array(['038.Great_Crested_Flycatcher'], dtype='<U28')],\n",
      "       [array(['043.Yellow_bellied_Flycatcher'], dtype='<U29')],\n",
      "       [array(['049.Boat_tailed_Grackle'], dtype='<U23')],\n",
      "       [array(['051.Horned_Grebe'], dtype='<U16')],\n",
      "       [array(['053.Western_Grebe'], dtype='<U17')],\n",
      "       [array(['066.Western_Gull'], dtype='<U16')],\n",
      "       [array(['072.Pomarine_Jaeger'], dtype='<U19')],\n",
      "       [array(['079.Belted_Kingfisher'], dtype='<U21')],\n",
      "       [array(['083.White_breasted_Kingfisher'], dtype='<U29')],\n",
      "       [array(['084.Red_legged_Kittiwake'], dtype='<U24')],\n",
      "       [array(['086.Pacific_Loon'], dtype='<U16')],\n",
      "       [array(['091.Mockingbird'], dtype='<U15')],\n",
      "       [array(['095.Baltimore_Oriole'], dtype='<U20')],\n",
      "       [array(['096.Hooded_Oriole'], dtype='<U17')],\n",
      "       [array(['098.Scott_Oriole'], dtype='<U16')],\n",
      "       [array(['101.White_Pelican'], dtype='<U17')],\n",
      "       [array(['102.Western_Wood_Pewee'], dtype='<U22')],\n",
      "       [array(['103.Sayornis'], dtype='<U12')],\n",
      "       [array(['112.Great_Grey_Shrike'], dtype='<U21')],\n",
      "       [array(['114.Black_throated_Sparrow'], dtype='<U26')],\n",
      "       [array(['119.Field_Sparrow'], dtype='<U17')],\n",
      "       [array(['121.Grasshopper_Sparrow'], dtype='<U23')],\n",
      "       [array(['130.Tree_Sparrow'], dtype='<U16')],\n",
      "       [array(['135.Bank_Swallow'], dtype='<U16')],\n",
      "       [array(['138.Tree_Swallow'], dtype='<U16')],\n",
      "       [array(['147.Least_Tern'], dtype='<U14')],\n",
      "       [array(['156.White_eyed_Vireo'], dtype='<U20')],\n",
      "       [array(['163.Cape_May_Warbler'], dtype='<U20')],\n",
      "       [array(['165.Chestnut_sided_Warbler'], dtype='<U26')],\n",
      "       [array(['166.Golden_winged_Warbler'], dtype='<U25')],\n",
      "       [array(['180.Wilson_Warbler'], dtype='<U18')],\n",
      "       [array(['183.Northern_Waterthrush'], dtype='<U24')],\n",
      "       [array(['185.Bohemian_Waxwing'], dtype='<U20')],\n",
      "       [array(['186.Cedar_Waxwing'], dtype='<U17')],\n",
      "       [array(['187.American_Three_toed_Woodpecker'], dtype='<U34')],\n",
      "       [array(['197.Marsh_Wren'], dtype='<U14')]], dtype=object), 'att': array([[0.0106384 , 0.        , 0.        , ..., 0.        , 0.        ,\n",
      "        0.04378019],\n",
      "       [0.0106384 , 0.01133243, 0.        , ..., 0.00334966, 0.11184146,\n",
      "        0.02814441],\n",
      "       [0.00709227, 0.00944369, 0.00742474, ..., 0.        , 0.        ,\n",
      "        0.        ],\n",
      "       ...,\n",
      "       [0.00918617, 0.00266542, 0.        , ..., 0.00556558, 0.08207164,\n",
      "        0.06022509],\n",
      "       [0.02526198, 0.02132333, 0.00885258, ..., 0.        , 0.05836206,\n",
      "        0.07695428],\n",
      "       [0.02066889, 0.05863916, 0.01770516, ..., 0.15027069, 0.01823814,\n",
      "        0.06189801]]), 'original_att': array([[ 4.41176471,  0.        ,  0.        , ...,  0.        ,\n",
      "         0.        , 18.30065359],\n",
      "       [ 4.41176471,  3.97350993,  0.        , ...,  1.38888889,\n",
      "        51.96850394, 11.76470588],\n",
      "       [ 2.94117647,  3.31125828,  3.22580645, ...,  0.        ,\n",
      "         0.        ,  0.        ],\n",
      "       ...,\n",
      "       [ 3.80952381,  0.93457944,  0.        , ...,  2.30769231,\n",
      "        38.13559322, 25.17482517],\n",
      "       [10.47619048,  7.47663551,  3.84615385, ...,  0.        ,\n",
      "        27.11864407, 32.16783217],\n",
      "       [ 8.57142857, 20.56074766,  7.69230769, ..., 62.30769231,\n",
      "         8.47457627, 25.87412587]]), 'test_seen_loc': array([[ 8972],\n",
      "       [ 8571],\n",
      "       [ 1474],\n",
      "       ...,\n",
      "       [10613],\n",
      "       [ 7665],\n",
      "       [ 5896]], dtype=uint16), 'test_unseen_loc': array([[  179],\n",
      "       [  180],\n",
      "       [  181],\n",
      "       ...,\n",
      "       [11786],\n",
      "       [11787],\n",
      "       [11788]], dtype=uint16), 'train_loc': array([[10877],\n",
      "       [10921],\n",
      "       [ 2653],\n",
      "       ...,\n",
      "       [ 5227],\n",
      "       [11508],\n",
      "       [ 1643]], dtype=uint16), 'trainval_loc': array([[10877],\n",
      "       [10921],\n",
      "       [ 2653],\n",
      "       ...,\n",
      "       [ 5227],\n",
      "       [11508],\n",
      "       [ 1643]], dtype=uint16), 'val_loc': array([[2739],\n",
      "       [2893],\n",
      "       [2890],\n",
      "       ...,\n",
      "       [3402],\n",
      "       [6331],\n",
      "       [8252]], dtype=uint16)}\n",
      "[10876 10920  2652 ...  5226 11507  1642] 7057\n",
      "[ 8971  8570  1473 ... 10612  7664  5895] 1764\n",
      "[  178   179   180 ... 11785 11786 11787] 2967\n",
      "[[0.0106384  0.0106384  0.00709227 ... 0.00918617 0.02526198 0.02066889]\n",
      " [0.         0.01133243 0.00944369 ... 0.00266542 0.02132333 0.05863916]\n",
      " [0.         0.         0.00742474 ... 0.         0.00885258 0.01770516]\n",
      " ...\n",
      " [0.         0.00334966 0.         ... 0.00556558 0.         0.15027069]\n",
      " [0.         0.11184146 0.         ... 0.08207164 0.05836206 0.01823814]\n",
      " [0.04378019 0.02814441 0.         ... 0.06022509 0.07695428 0.06189801]] (200, 312)\n",
      "[[ 4.41176471  4.41176471  2.94117647 ...  3.80952381 10.47619048\n",
      "   8.57142857]\n",
      " [ 0.          3.97350993  3.31125828 ...  0.93457944  7.47663551\n",
      "  20.56074766]\n",
      " [ 0.          0.          3.22580645 ...  0.          3.84615385\n",
      "   7.69230769]\n",
      " ...\n",
      " [ 0.          1.38888889  0.         ...  2.30769231  0.\n",
      "  62.30769231]\n",
      " [ 0.         51.96850394  0.         ... 38.13559322 27.11864407\n",
      "   8.47457627]\n",
      " [18.30065359 11.76470588  0.         ... 25.17482517 32.16783217\n",
      "  25.87412587]] (200, 312)\n"
     ]
    }
   ],
   "source": [
    "def get_index_details(split_path):\n",
    "    matcontent = sio.loadmat(split_path)\n",
    "    print(matcontent)\n",
    "    \n",
    "    trainval_loc = matcontent['trainval_loc'].squeeze() - 1\n",
    "    print(trainval_loc, len(trainval_loc))\n",
    "\n",
    "    test_seen_loc = matcontent['test_seen_loc'].squeeze() - 1\n",
    "    print(test_seen_loc, len(test_seen_loc))\n",
    "\n",
    "    test_unseen_loc = matcontent['test_unseen_loc'].squeeze() - 1\n",
    "    print(test_unseen_loc, len(test_unseen_loc))\n",
    "    \n",
    "    att = matcontent['att'].T\n",
    "    print(att, att.shape)\n",
    "    \n",
    "    original_att = matcontent['original_att'].T\n",
    "    print(original_att, original_att.shape)\n",
    "    return trainval_loc, test_seen_loc, test_unseen_loc, att, original_att\n",
    "    \n",
    "trainval_loc, test_seen_loc, test_unseen_loc, att, original_att = get_index_details(split_path)    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea517643",
   "metadata": {},
   "source": [
    "# Save the feature map that includes ResNet50 features, labels, training and test (seen and unseen) data indexes, semantic attributes, and "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a540d786",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "save_path = 'C:/Sushree/Jio_Institute/Dataset/CUB_200_2011/CUB_200_2011/feature_map_ResNet_101_CUB.hdf5'\n",
    "\n",
    "f = h5py.File(save_path, \"w\")\n",
    "f.create_dataset('feature_map', data=all_features,compression=\"gzip\")\n",
    "f.create_dataset('labels', data=labels,compression=\"gzip\")\n",
    "f.create_dataset('trainval_loc', data=trainval_loc,compression=\"gzip\")\n",
    "#    f.create_dataset('train_loc', data=train_loc,compression=\"gzip\")\n",
    "#    f.create_dataset('val_unseen_loc', data=val_unseen_loc,compression=\"gzip\")\n",
    "f.create_dataset('test_seen_loc', data=test_seen_loc,compression=\"gzip\")\n",
    "f.create_dataset('test_unseen_loc', data=test_unseen_loc,compression=\"gzip\")\n",
    "f.create_dataset('att', data=att,compression=\"gzip\")\n",
    "f.create_dataset('original_att', data=original_att,compression=\"gzip\")\n",
    "f.create_dataset('w2v_att', data=w2v_att,compression=\"gzip\")\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0827b084",
   "metadata": {},
   "outputs": [],
   "source": [
    "hf = h5py.File('C:/Sushree/Jio_Institute/Dataset/Animals_with_Attributes2/feature_map_ResNet_101_AWA2.hdf5', 'r')\n",
    "features = np.array(hf.get('feature_map'))\n",
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb52765",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6373e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "att = np.array(hf.get('att'))\n",
    "print(att)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647068b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f86e6b3",
   "metadata": {},
   "source": [
    "# Train the DAZLE model for AWA2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "046aff50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.models.resnet as models\n",
    "from PIL import Image\n",
    "import h5py\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import pickle\n",
    "import pdb\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "import torch.optim as optim\n",
    "import importlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae3b3f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from DAZLE import DAZLE\n",
    "from CUBDataLoader import CUBDataLoader\n",
    "from helper_func import eval_zs_gzsl,visualize_attention#,get_attribute_attention_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b657e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:/Sushree/Jio_Institute/Dataset/\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "CUB\n",
      "$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$\n",
      "Balance dataloader\n",
      "_____\n",
      "C:/Sushree/Jio_Institute/Dataset/CUB_200_2011/CUB_200_2011/feature_map_ResNet_101_CUB.hdf5\n",
      "Expert Attr\n"
     ]
    }
   ],
   "source": [
    "data_path = 'C:/Sushree/Jio_Institute/Dataset/'\n",
    "feature_path = 'C:/Sushree/Jio_Institute/Dataset/CUB_200_2011/CUB_200_2011/'\n",
    "dataloader = CUBDataLoader(data_path, feature_path, device = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "485c300f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader.augment_img_path()\n",
    "\n",
    "def get_lr(optimizer):\n",
    "    lr = []\n",
    "    for param_group in optimizer.param_groups:\n",
    "        lr.append(param_group['lr'])\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d81d8efe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "Configuration\n",
      "loss_type CE\n",
      "no constraint V\n",
      "normalize F\n",
      "training to exclude unseen class [seen upperbound]\n",
      "Init word2vec\n",
      "Linear model\n",
      "loss_att BCEWithLogitsLoss()\n",
      "Bilinear attention module\n",
      "******************************\n",
      "Measure w2v deviation\n",
      "Compute Pruning loss Parameter containing:\n",
      "tensor(0)\n",
      "Add one smoothing\n",
      "Second layer attenion conditioned on image features\n",
      "------------------------------\n",
      "No sigmoid on attr score\n",
      "{'pmp': {'init_lambda': 0.1, 'final_lambda': 0.1, 'phase': 0.8}, 'desired_mass': {'init_lambda': -1, 'final_lambda': -1, 'phase': 0.8}}\n",
      "\t V\n",
      "\t W_1\n",
      "\t W_2\n",
      "\t W_3\n",
      "default lr ['V'] 1x lr ['W_1', 'W_2', 'W_3']\n",
      "------------------------------\n",
      "learing rate 0.0001\n",
      "trainable V True\n",
      "lambda_ 0.1\n",
      "optimized seen only\n",
      "optimizer: RMSProp with momentum = 0.9 and weight_decay = 0.0001\n",
      "------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sushree.Behera\\Sushree\\GZSL_Implementation\\DAZLE.py:51: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.init_w2v_att = F.normalize(torch.tensor(init_w2v_att))\n",
      "C:\\Users\\Sushree.Behera\\Sushree\\GZSL_Implementation\\DAZLE.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  self.att = nn.Parameter(F.normalize(torch.tensor(att)),requires_grad = False)\n"
     ]
    }
   ],
   "source": [
    "seed = 214\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "batch_size = 32\n",
    "nepoches = 100\n",
    "niters = dataloader.ntrain * nepoches//batch_size\n",
    "dim_f = 2048\n",
    "dim_v = 300\n",
    "init_w2v_att = dataloader.w2v_att # load the attribute features\n",
    "att = dataloader.att\n",
    "normalize_att = dataloader.normalize_att\n",
    "\n",
    "\n",
    "trainable_w2v = True\n",
    "lambda_ = 0.1\n",
    "bias = 0\n",
    "prob_prune = 0\n",
    "uniform_att_1 = False\n",
    "uniform_att_2 = False\n",
    "\n",
    "seenclass = dataloader.seenclasses #load seen and unseen data\n",
    "unseenclass = dataloader.unseenclasses\n",
    "desired_mass = 1\n",
    "report_interval = niters//nepoches\n",
    "\n",
    "device = None\n",
    "\n",
    "model = DAZLE(dim_f,dim_v,init_w2v_att,att,normalize_att,\n",
    "            seenclass,unseenclass,\n",
    "            lambda_,\n",
    "            trainable_w2v,normalize_V=False,normalize_F=True,is_conservative=True,\n",
    "            uniform_att_1=uniform_att_1,uniform_att_2=uniform_att_2,\n",
    "            prob_prune=prob_prune,desired_mass=desired_mass, is_conv=False,\n",
    "            is_bias=True)\n",
    "model.to(device)\n",
    "\n",
    "setup = {'pmp':{'init_lambda':0.1,'final_lambda':0.1,'phase':0.8},\n",
    "         'desired_mass':{'init_lambda':-1,'final_lambda':-1,'phase':0.8}}\n",
    "print(setup)\n",
    "\n",
    "params_to_update = []\n",
    "params_names = []\n",
    "for name,param in model.named_parameters():\n",
    "    if param.requires_grad == True:\n",
    "        params_to_update.append(param)\n",
    "        params_names.append(name)\n",
    "        print(\"\\t\",name)\n",
    "#%%\n",
    "lr = 0.0001\n",
    "weight_decay = 0.0001\n",
    "momentum = 0.9\n",
    "#%%\n",
    "lr_seperator = 1\n",
    "lr_factor = 1\n",
    "print('default lr {} {}x lr {}'.format(params_names[:lr_seperator],lr_factor,params_names[lr_seperator:]))\n",
    "optimizer  = optim.RMSprop( params_to_update ,lr=lr,weight_decay=weight_decay, momentum=momentum)\n",
    "print('-'*30)\n",
    "print('learing rate {}'.format(lr))\n",
    "print('trainable V {}'.format(trainable_w2v))\n",
    "print('lambda_ {}'.format(lambda_))\n",
    "print('optimized seen only')\n",
    "print('optimizer: RMSProp with momentum = {} and weight_decay = {}'.format(momentum,weight_decay))\n",
    "print('-'*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef247f48",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 0, 'loss': 5.437799453735352, 'loss_CE': 5.403890132904053, 'loss_cal': 0.3390955328941345, 'acc_seen': 0, 'acc_novel': 0, 'H': 0, 'acc_zs': 0}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 220, 'loss': 1.7292962074279785, 'loss_CE': 1.6393898725509644, 'loss_cal': 0.8990627527236938, 'acc_seen': 0.3866586685180664, 'acc_novel': 0.49620482325553894, 'H': 0.43463547436261807, 'acc_zs': 0.5499619245529175}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 440, 'loss': 1.318319320678711, 'loss_CE': 1.2152273654937744, 'loss_cal': 1.0309193134307861, 'acc_seen': 0.48445358872413635, 'acc_novel': 0.5386620759963989, 'H': 0.5101217483505728, 'acc_zs': 0.6094498634338379}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 660, 'loss': 1.0087454319000244, 'loss_CE': 0.8710147738456726, 'loss_cal': 1.377306342124939, 'acc_seen': 0.5309994220733643, 'acc_novel': 0.5282782912254333, 'H': 0.5296353615541095, 'acc_zs': 0.6259000301361084}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 880, 'loss': 0.9912068843841553, 'loss_CE': 0.8648595213890076, 'loss_cal': 1.2634737491607666, 'acc_seen': 0.548377275466919, 'acc_novel': 0.536051332950592, 'H': 0.5421442540193118, 'acc_zs': 0.6293941736221313}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 1100, 'loss': 0.664949357509613, 'loss_CE': 0.5299398303031921, 'loss_cal': 1.3500953912734985, 'acc_seen': 0.5615504384040833, 'acc_novel': 0.5600890517234802, 'H': 0.5608187930417421, 'acc_zs': 0.6501537561416626}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 1320, 'loss': 1.173215627670288, 'loss_CE': 1.039271593093872, 'loss_cal': 1.3394404649734497, 'acc_seen': 0.5920212268829346, 'acc_novel': 0.5461652874946594, 'H': 0.5681695214255372, 'acc_zs': 0.6476685404777527}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 1540, 'loss': 0.8881754875183105, 'loss_CE': 0.7283750176429749, 'loss_cal': 1.598004698753357, 'acc_seen': 0.5908331274986267, 'acc_novel': 0.5552297830581665, 'H': 0.5724784323493455, 'acc_zs': 0.6474389433860779}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 1760, 'loss': 0.9883075952529907, 'loss_CE': 0.8698638081550598, 'loss_cal': 1.1844381093978882, 'acc_seen': 0.5908331274986267, 'acc_novel': 0.5552297830581665, 'H': 0.5724784323493455, 'acc_zs': 0.6474389433860779}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 1980, 'loss': 0.9363863468170166, 'loss_CE': 0.7991777062416077, 'loss_cal': 1.3720866441726685, 'acc_seen': 0.5908331274986267, 'acc_novel': 0.5552297830581665, 'H': 0.5724784323493455, 'acc_zs': 0.6474389433860779}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 2200, 'loss': 0.8392817378044128, 'loss_CE': 0.6954424977302551, 'loss_cal': 1.438392162322998, 'acc_seen': 0.5812991261482239, 'acc_novel': 0.5725515484809875, 'H': 0.5768921787280022, 'acc_zs': 0.6564985513687134}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 2420, 'loss': 0.8383352160453796, 'loss_CE': 0.7094029188156128, 'loss_cal': 1.2893227338790894, 'acc_seen': 0.5812991261482239, 'acc_novel': 0.5725515484809875, 'H': 0.5768921787280022, 'acc_zs': 0.6564985513687134}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 2640, 'loss': 0.965938925743103, 'loss_CE': 0.8370150923728943, 'loss_cal': 1.2892385721206665, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 2860, 'loss': 0.7532148957252502, 'loss_CE': 0.6358360648155212, 'loss_cal': 1.1737881898880005, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 3080, 'loss': 0.6092746257781982, 'loss_CE': 0.43917956948280334, 'loss_cal': 1.700950264930725, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 3300, 'loss': 0.7814957499504089, 'loss_CE': 0.642296552658081, 'loss_cal': 1.3919918537139893, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 3520, 'loss': 0.6944969892501831, 'loss_CE': 0.5650331974029541, 'loss_cal': 1.2946375608444214, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 3740, 'loss': 0.6676619052886963, 'loss_CE': 0.5258102416992188, 'loss_cal': 1.4185162782669067, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 3960, 'loss': 0.8870308995246887, 'loss_CE': 0.739080548286438, 'loss_cal': 1.4795032739639282, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 4180, 'loss': 0.8195191621780396, 'loss_CE': 0.6856690049171448, 'loss_cal': 1.3385014533996582, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 4400, 'loss': 0.5659919381141663, 'loss_CE': 0.4330406188964844, 'loss_cal': 1.3295129537582397, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 4620, 'loss': 0.6060718894004822, 'loss_CE': 0.4597322344779968, 'loss_cal': 1.4633963108062744, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 4840, 'loss': 0.7169322967529297, 'loss_CE': 0.5909768342971802, 'loss_cal': 1.2595547437667847, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 5060, 'loss': 0.7117663621902466, 'loss_CE': 0.5622707009315491, 'loss_cal': 1.4949568510055542, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 5280, 'loss': 0.5701568126678467, 'loss_CE': 0.4229535460472107, 'loss_cal': 1.472032904624939, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 5500, 'loss': 0.49492764472961426, 'loss_CE': 0.3220083713531494, 'loss_cal': 1.7291926145553589, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 5720, 'loss': 0.6277987957000732, 'loss_CE': 0.5102306008338928, 'loss_cal': 1.1756818294525146, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 5940, 'loss': 0.7536410093307495, 'loss_CE': 0.6085526347160339, 'loss_cal': 1.4508838653564453, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 6160, 'loss': 0.42712751030921936, 'loss_CE': 0.2688402831554413, 'loss_cal': 1.5828722715377808, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 6380, 'loss': 0.35028713941574097, 'loss_CE': 0.20244699716567993, 'loss_cal': 1.4784013032913208, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 6600, 'loss': 0.5836837291717529, 'loss_CE': 0.4318195879459381, 'loss_cal': 1.5186411142349243, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 6820, 'loss': 0.4956952929496765, 'loss_CE': 0.3623758852481842, 'loss_cal': 1.3331938982009888, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 7040, 'loss': 0.4279676675796509, 'loss_CE': 0.2710740566253662, 'loss_cal': 1.5689358711242676, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 7260, 'loss': 0.5017527341842651, 'loss_CE': 0.36248403787612915, 'loss_cal': 1.3926866054534912, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 7480, 'loss': 0.483140766620636, 'loss_CE': 0.35810586810112, 'loss_cal': 1.2503490447998047, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 7700, 'loss': 0.43338894844055176, 'loss_CE': 0.2880767583847046, 'loss_cal': 1.4531216621398926, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 7920, 'loss': 0.5197030305862427, 'loss_CE': 0.37870892882347107, 'loss_cal': 1.4099410772323608, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 8140, 'loss': 0.4080032408237457, 'loss_CE': 0.250250905752182, 'loss_cal': 1.5775233507156372, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 8360, 'loss': 0.556092381477356, 'loss_CE': 0.4294814169406891, 'loss_cal': 1.266109824180603, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 8580, 'loss': 0.5387507677078247, 'loss_CE': 0.40869957208633423, 'loss_cal': 1.3005115985870361, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 8800, 'loss': 0.46050143241882324, 'loss_CE': 0.31149959564208984, 'loss_cal': 1.4900181293487549, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 9020, 'loss': 0.5321795344352722, 'loss_CE': 0.3588768541812897, 'loss_cal': 1.7330269813537598, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 9240, 'loss': 0.4382888078689575, 'loss_CE': 0.28337162733078003, 'loss_cal': 1.5491716861724854, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 9460, 'loss': 0.44365230202674866, 'loss_CE': 0.2925269901752472, 'loss_cal': 1.5112531185150146, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 9680, 'loss': 0.4820716381072998, 'loss_CE': 0.3337365686893463, 'loss_cal': 1.4833508729934692, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 9900, 'loss': 0.43913722038269043, 'loss_CE': 0.2994554340839386, 'loss_cal': 1.3968180418014526, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 10120, 'loss': 0.3274678885936737, 'loss_CE': 0.1840507835149765, 'loss_cal': 1.4341709613800049, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 10340, 'loss': 0.40870511531829834, 'loss_CE': 0.23845556378364563, 'loss_cal': 1.7024956941604614, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 10560, 'loss': 0.4821874499320984, 'loss_CE': 0.3381361961364746, 'loss_cal': 1.4405122995376587, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 10780, 'loss': 0.46939197182655334, 'loss_CE': 0.3270910978317261, 'loss_cal': 1.423008680343628, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 11000, 'loss': 0.37840574979782104, 'loss_CE': 0.227858304977417, 'loss_cal': 1.505474328994751, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 11220, 'loss': 0.4096240699291229, 'loss_CE': 0.2549731731414795, 'loss_cal': 1.5465089082717896, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 11440, 'loss': 0.36427372694015503, 'loss_CE': 0.2299996316432953, 'loss_cal': 1.3427411317825317, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 11660, 'loss': 0.35881954431533813, 'loss_CE': 0.19009120762348175, 'loss_cal': 1.6872835159301758, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 11880, 'loss': 0.3465472459793091, 'loss_CE': 0.1840939074754715, 'loss_cal': 1.6245335340499878, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 12100, 'loss': 0.32663288712501526, 'loss_CE': 0.1698838323354721, 'loss_cal': 1.5674904584884644, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 12320, 'loss': 0.39949190616607666, 'loss_CE': 0.22088272869586945, 'loss_cal': 1.7860918045043945, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 12540, 'loss': 0.3232358992099762, 'loss_CE': 0.15449677407741547, 'loss_cal': 1.6873912811279297, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 12760, 'loss': 0.306355357170105, 'loss_CE': 0.13481169939041138, 'loss_cal': 1.7154364585876465, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 12980, 'loss': 0.4912301003932953, 'loss_CE': 0.3429970145225525, 'loss_cal': 1.4823307991027832, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 13200, 'loss': 0.3446468114852905, 'loss_CE': 0.18699601292610168, 'loss_cal': 1.5765081644058228, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 13420, 'loss': 0.3499443531036377, 'loss_CE': 0.12199143320322037, 'loss_cal': 2.279529094696045, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 13640, 'loss': 0.31113436818122864, 'loss_CE': 0.1510077565908432, 'loss_cal': 1.6012660264968872, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 13860, 'loss': 0.4209708571434021, 'loss_CE': 0.2634226381778717, 'loss_cal': 1.5754822492599487, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 14080, 'loss': 0.3428061008453369, 'loss_CE': 0.1876390278339386, 'loss_cal': 1.5516705513000488, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 14300, 'loss': 0.36159878969192505, 'loss_CE': 0.19163019955158234, 'loss_cal': 1.69968581199646, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 14520, 'loss': 0.3392941653728485, 'loss_CE': 0.19830119609832764, 'loss_cal': 1.409929633140564, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 14740, 'loss': 0.3322650194168091, 'loss_CE': 0.15478691458702087, 'loss_cal': 1.7747812271118164, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 14960, 'loss': 0.348571240901947, 'loss_CE': 0.18390518426895142, 'loss_cal': 1.646660566329956, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 15180, 'loss': 0.3906227946281433, 'loss_CE': 0.23261526226997375, 'loss_cal': 1.5800752639770508, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 15400, 'loss': 0.31084030866622925, 'loss_CE': 0.1328505575656891, 'loss_cal': 1.7798973321914673, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 15620, 'loss': 0.3634073734283447, 'loss_CE': 0.20749375224113464, 'loss_cal': 1.5591360330581665, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 15840, 'loss': 0.4006774127483368, 'loss_CE': 0.24229559302330017, 'loss_cal': 1.5838181972503662, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 16060, 'loss': 0.2811150848865509, 'loss_CE': 0.12199067324399948, 'loss_cal': 1.5912439823150635, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 16280, 'loss': 0.2927246689796448, 'loss_CE': 0.14472360908985138, 'loss_cal': 1.480010747909546, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 16500, 'loss': 0.30748826265335083, 'loss_CE': 0.12189774215221405, 'loss_cal': 1.855905294418335, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 16720, 'loss': 0.33691126108169556, 'loss_CE': 0.15469831228256226, 'loss_cal': 1.8221296072006226, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 16940, 'loss': 0.34459418058395386, 'loss_CE': 0.165226012468338, 'loss_cal': 1.7936817407608032, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 17160, 'loss': 0.3093400001525879, 'loss_CE': 0.11944873631000519, 'loss_cal': 1.8989125490188599, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 17380, 'loss': 0.41471511125564575, 'loss_CE': 0.26859575510025024, 'loss_cal': 1.4611936807632446, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 17600, 'loss': 0.32641273736953735, 'loss_CE': 0.19252794981002808, 'loss_cal': 1.3388478755950928, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 17820, 'loss': 0.35018259286880493, 'loss_CE': 0.17716529965400696, 'loss_cal': 1.7301727533340454, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 18040, 'loss': 0.34334486722946167, 'loss_CE': 0.1809123158454895, 'loss_cal': 1.6243255138397217, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 18260, 'loss': 0.34441855549812317, 'loss_CE': 0.1810699850320816, 'loss_cal': 1.6334856748580933, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 18480, 'loss': 0.32225894927978516, 'loss_CE': 0.15076929330825806, 'loss_cal': 1.7148966789245605, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 18700, 'loss': 0.3239290416240692, 'loss_CE': 0.18635018169879913, 'loss_cal': 1.3757885694503784, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 18920, 'loss': 0.40136992931365967, 'loss_CE': 0.2734932005405426, 'loss_cal': 1.2787671089172363, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 19140, 'loss': 0.33439311385154724, 'loss_CE': 0.15913179516792297, 'loss_cal': 1.7526131868362427, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 19360, 'loss': 0.38632136583328247, 'loss_CE': 0.23413819074630737, 'loss_cal': 1.521831750869751, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 19580, 'loss': 0.29094448685646057, 'loss_CE': 0.14028918743133545, 'loss_cal': 1.5065529346466064, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 19800, 'loss': 0.32226723432540894, 'loss_CE': 0.10400226712226868, 'loss_cal': 2.182649850845337, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 20020, 'loss': 0.27921462059020996, 'loss_CE': 0.12300543487071991, 'loss_cal': 1.5620917081832886, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 20240, 'loss': 0.3268003463745117, 'loss_CE': 0.1364675909280777, 'loss_cal': 1.9033273458480835, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 20460, 'loss': 0.29473596811294556, 'loss_CE': 0.08264046907424927, 'loss_cal': 2.120954751968384, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 20680, 'loss': 0.38562533259391785, 'loss_CE': 0.24327386915683746, 'loss_cal': 1.4235146045684814, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 20900, 'loss': 0.3422442078590393, 'loss_CE': 0.17472240328788757, 'loss_cal': 1.6752182245254517, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 21120, 'loss': 0.388837993144989, 'loss_CE': 0.24251236021518707, 'loss_cal': 1.4632562398910522, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 21340, 'loss': 0.34657353162765503, 'loss_CE': 0.20151592791080475, 'loss_cal': 1.4505760669708252, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 21560, 'loss': 0.3191273808479309, 'loss_CE': 0.1520281434059143, 'loss_cal': 1.670992136001587, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 21780, 'loss': 0.2811572551727295, 'loss_CE': 0.1134408712387085, 'loss_cal': 1.6771636009216309, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n",
      "------------------------------\n",
      "bias_seen 0 bias_unseen 0\n",
      "{'iter': 22000, 'loss': 0.448726087808609, 'loss_CE': 0.29331687092781067, 'loss_cal': 1.5540921688079834, 'acc_seen': 0.5924230217933655, 'acc_novel': 0.5670598745346069, 'H': 0.5794640446589812, 'acc_zs': 0.6518011689186096}\n"
     ]
    }
   ],
   "source": [
    "best_performance = [0,0,0,0]\n",
    "for i in range(0,niters):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    batch_label, batch_feature, batch_att = dataloader.next_batch(batch_size)\n",
    "    out_package = model(batch_feature)\n",
    "    \n",
    "    in_package = out_package\n",
    "    in_package['batch_label'] = batch_label\n",
    "    \n",
    "    out_package=model.compute_loss(in_package)\n",
    "    loss,loss_CE,loss_cal = out_package['loss'],out_package['loss_CE'],out_package['loss_cal']\n",
    "    \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if i%report_interval==0:\n",
    "        print('-'*30)\n",
    "        acc_seen, acc_novel, H, acc_zs = eval_zs_gzsl(dataloader,model,device,bias_seen=-bias,bias_unseen=bias)\n",
    "        \n",
    "        if H > best_performance[2]:\n",
    "            best_performance = [acc_seen, acc_novel, H, acc_zs]\n",
    "        stats_package = {'iter':i, 'loss':loss.item(), 'loss_CE':loss_CE.item(),\n",
    "                         'loss_cal': loss_cal.item(),\n",
    "                         'acc_seen':best_performance[0], 'acc_novel':best_performance[1], 'H':best_performance[2], 'acc_zs':best_performance[3]}\n",
    "        \n",
    "        print(stats_package)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c411c872",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
