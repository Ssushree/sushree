{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254eac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b746b164",
   "metadata": {},
   "source": [
    "GZSL_AWA2_1: Experiments with direct 85 length attributes\n",
    "    Step 1 - Visual features are extracted from pre-trained ResNet101 (without finetuning)\n",
    "\tStep 2 - Class wise continous attributes are extracted (for AWA2: 50 categories, and each category has attribute vectors of length 85) \n",
    "\tStep 3 - Define 'model2' for attribute to class label mapping\n",
    "\t\t Define 'model1' for visual feature to class label mapping\n",
    "\t\t Train 'model2' and 'model1' through the iterative process\n",
    "\tStep 4 - Evaluate for seen and unseen categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9174f315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please add the folder name of the dataset to run it on different dataset.\n",
    "dataset = 'AWA2'\n",
    "path = 'E:/Sushree/Dataset/data/xlsa17/data/'\n",
    "\n",
    "res101 = scipy.io.loadmat(path + dataset + '/res101.mat')\n",
    "att_splits = scipy.io.loadmat(path + dataset + '/att_splits.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17ca09e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    2     4     5 ... 37318 37320 37321] 37321\n",
      "[    0     1     3 ... 37306 37307 37319] 37319\n",
      "[ 1046  1047  1048 ... 35288 35289 35290] 35290\n"
     ]
    }
   ],
   "source": [
    "# total number of instances or images = 37322: ranges from 0 to 37321\n",
    "\n",
    "trainval_loc = np.squeeze(att_splits['trainval_loc']-1) # -1: to consider the overflow problem\n",
    "print(np.unique(trainval_loc), np.max(np.unique(trainval_loc))) # smallest location: 2, largest location 37321\n",
    "\n",
    "test_seen_loc = np.squeeze(att_splits['test_seen_loc']-1)\n",
    "print(np.unique(test_seen_loc), np.max(np.unique(test_seen_loc))) # smallest location: 0, largest location 37319\n",
    "\n",
    "test_unseen_loc = np.squeeze(att_splits['test_unseen_loc']-1)\n",
    "print(np.unique(test_unseen_loc), np.max(np.unique(test_unseen_loc))) # smallest location: 1046, largest location 35290\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85fdebcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels [[ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " ...\n",
      " [38]\n",
      " [38]\n",
      " [38]] (37322, 1)\n",
      "unique_labels [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50] (50,)\n",
      "labels_trainval [[43]\n",
      " [22]\n",
      " [43]\n",
      " ...\n",
      " [40]\n",
      " [19]\n",
      " [46]] (23527, 1)\n",
      "unique_labels_trainval [ 1  2  3  4  5  6  8 10 11 12 13 14 15 16 17 18 19 20 21 22 25 26 27 28\n",
      " 29 32 33 35 36 37 38 39 40 42 43 44 45 46 48 49] (40,)\n",
      "labels_test_seen [[22]\n",
      " [49]\n",
      " [14]\n",
      " ...\n",
      " [25]\n",
      " [15]\n",
      " [27]] (5882, 1)\n",
      "unique_labels_test_seen [ 1  2  3  4  5  6  8 10 11 12 13 14 15 16 17 18 19 20 21 22 25 26 27 28\n",
      " 29 32 33 35 36 37 38 39 40 42 43 44 45 46 48 49] (40,)\n",
      "labels_test_unseen [[30]\n",
      " [30]\n",
      " [30]\n",
      " ...\n",
      " [47]\n",
      " [47]\n",
      " [47]] (7913, 1)\n",
      "unique_labels_test_unseen [ 7  9 23 24 30 31 34 41 47 50] (10,)\n",
      "correct number of instances for training, test seen and test unseen categories\n",
      "Number of overlapping classes between trainval and test seen: 40\n",
      "Number of overlapping classes between trainval and test unseen: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels = res101['labels']# direct class labels\n",
    "print('labels', labels, labels.shape)# 37322 x 1\n",
    "\n",
    "print('unique_labels', np.unique(labels), np.unique(labels).shape)# class labels range from 1 to 50, 50 classes\n",
    "\n",
    "# get the labels for trainval, test seen and test unseen sets\n",
    "\n",
    "labels_trainval = labels[trainval_loc]\n",
    "print('labels_trainval', labels_trainval, labels_trainval.shape)\n",
    "\n",
    "unique_labels_trainval = np.unique(labels_trainval) # labels min:1 max:49\n",
    "print('unique_labels_trainval', unique_labels_trainval, unique_labels_trainval.shape)# 40 classes\n",
    "\n",
    "\n",
    "labels_test_seen = labels[test_seen_loc]\n",
    "print('labels_test_seen', labels_test_seen, labels_test_seen.shape)\n",
    "\n",
    "unique_labels_test_seen = np.unique(labels_test_seen) # labels min:1 max:49\n",
    "print('unique_labels_test_seen', unique_labels_test_seen, unique_labels_test_seen.shape)# 40 classes\n",
    "\n",
    "\n",
    "labels_test_unseen = labels[test_unseen_loc]\n",
    "print('labels_test_unseen', labels_test_unseen, labels_test_unseen.shape)\n",
    "\n",
    "unique_labels_test_unseen = np.unique(labels_test_unseen) # labels min:7 max:50\n",
    "print('unique_labels_test_unseen', unique_labels_test_unseen, unique_labels_test_unseen.shape)# 10 classes\n",
    "\n",
    "\n",
    "if len(labels) == len(labels_trainval) + len(labels_test_seen) + len(labels_test_unseen):\n",
    "    print('correct number of instances for training, test seen and test unseen categories')\n",
    "    \n",
    "print(\"Number of overlapping classes between trainval and test seen:\",len(set(unique_labels_trainval).intersection(set(unique_labels_test_seen))))\n",
    "\n",
    "print(\"Number of overlapping classes between trainval and test unseen:\",len(set(unique_labels_trainval).intersection(set(unique_labels_test_unseen))))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "17890572",
   "metadata": {},
   "source": [
    "Step 1 - Visual features are extracted from pre-trained ResNet101 (without finetuning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43955a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for trainval: (23527, 2048)\n",
      "Features for test seen: (5882, 2048)\n",
      "Features for test unseen: (7913, 2048)\n"
     ]
    }
   ],
   "source": [
    "X_features = res101['features']\n",
    "\n",
    "# locations are already subtracted by 1, so they range from 0 to 37321\n",
    "trainval_vec = X_features[:, trainval_loc].transpose()\n",
    "test_seen_vec = X_features[:, test_seen_loc].transpose()\n",
    "test_unseen_vec = X_features[:, test_unseen_loc].transpose()\n",
    "\n",
    "print(\"Features for trainval:\", trainval_vec.shape) #(23527, 2048)\n",
    "print(\"Features for test seen:\", test_seen_vec.shape)# (5882, 2048)\n",
    "print(\"Features for test unseen:\", test_unseen_vec.shape) #(7913, 2048)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4656c127",
   "metadata": {},
   "source": [
    "Step 2 - Class wise continous attributes are extracted (for AWA2: 50 categories, and each category has attribute vectors of length 85) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48707767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85, 50)\n",
      "[[-0.00375358 -0.00375358 -0.00375358 ...  0.00882092  0.03640974\n",
      "   0.03145501]\n",
      " [ 0.12045618  0.00426584  0.         ...  0.17996306  0.0618086\n",
      "   0.03495531]\n",
      " [ 0.26584459  0.20652363  0.         ...  0.05026822  0.04274552\n",
      "   0.04915256]\n",
      " ...\n",
      " [ 0.22516498  0.15266022  0.         ...  0.12733492  0.10009694\n",
      "   0.01771   ]\n",
      " [ 0.19613947  0.1966714   0.         ...  0.01787277  0.06698743\n",
      "   0.25883601]\n",
      " [ 0.03819588  0.08046548  0.10363715 ...  0.01479997  0.05250999\n",
      "   0.14194515]] (50, 85)\n",
      "[[0.00575881 0.003829   0.         ... 0.03639079 0.13208508 0.01148699]\n",
      " [0.         0.00507555 0.         ... 0.15675628 0.09070911 0.01425057]\n",
      " [0.00575881 0.003829   0.         ... 0.03639079 0.13208508 0.01148699]\n",
      " ...\n",
      " [0.         0.06587863 0.         ... 0.02108505 0.10218637 0.0332632 ]\n",
      " [0.0084177  0.01262655 0.         ... 0.02104426 0.04138142 0.02316552]\n",
      " [0.03877321 0.15834626 0.         ... 0.1760296  0.07107783 0.30279846]] (23527, 85)\n",
      "[[0.         0.00507555 0.         ... 0.15675628 0.09070911 0.01425057]\n",
      " [0.19613947 0.1966714  0.         ... 0.01787277 0.06698743 0.25883601]\n",
      " [0.01928112 0.         0.         ... 0.10161998 0.0093374  0.        ]\n",
      " ...\n",
      " [0.13407657 0.02802316 0.         ... 0.02469312 0.11832941 0.10334422]\n",
      " [0.1170179  0.05564648 0.         ... 0.09686609 0.0632034  0.01789046]\n",
      " [0.03588774 0.04482569 0.         ... 0.07673723 0.0732708  0.05016127]] (5882, 85)\n",
      "[[0.27653654 0.00419864 0.         ... 0.06032152 0.10544938 0.01679457]\n",
      " [0.27653654 0.00419864 0.         ... 0.06032152 0.10544938 0.01679457]\n",
      " [0.27653654 0.00419864 0.         ... 0.06032152 0.10544938 0.01679457]\n",
      " ...\n",
      " [0.06218048 0.01590817 0.         ... 0.03693204 0.1114562  0.06188344]\n",
      " [0.06218048 0.01590817 0.         ... 0.03693204 0.1114562  0.06188344]\n",
      " [0.06218048 0.01590817 0.         ... 0.03693204 0.1114562  0.06188344]] (7913, 85)\n"
     ]
    }
   ],
   "source": [
    "signature = att_splits['att']\n",
    "print(signature.shape) #(85, 50)\n",
    "\n",
    "attribute = signature.transpose()\n",
    "print(attribute, attribute.shape)#(50, 85)\n",
    "\n",
    "#attribute[attribute<0]=0\n",
    "#print(attribute, attribute.shape)#(50, 85)\n",
    "\n",
    "# attribute is defined for all 50 classes, so we cant use locations directly, instead we have to use labels \n",
    "# that range from 1 to 50, so we have to subtract 1\n",
    "\n",
    "train_attributes = np.zeros((len(trainval_loc), 85))\n",
    "for i in range(len(trainval_loc)):\n",
    "    train_attributes[i] = attribute[int(labels_trainval[i])-1]\n",
    "\n",
    "print(train_attributes, train_attributes.shape)# (23527, 85)\n",
    "\n",
    "test_seen_attributes = np.zeros((len(test_seen_loc), 85))\n",
    "for i in range(len(test_seen_loc)):\n",
    "    test_seen_attributes[i] = attribute[int(labels_test_seen[i])-1]\n",
    "\n",
    "print(test_seen_attributes, test_seen_attributes.shape)# (5882, 85)\n",
    "\n",
    "test_unseen_attributes = np.zeros((len(test_unseen_loc), 85))\n",
    "for i in range(len(test_unseen_loc)):\n",
    "    test_unseen_attributes[i] = attribute[int(labels_test_unseen[i])-1]\n",
    "\n",
    "print(test_unseen_attributes, test_unseen_attributes.shape)# (7913, 85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd86867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signature for trainval: (85, 40)\n",
      "Signature for test seen: (85, 40)\n",
      "Signature for test unseen: (85, 10)\n"
     ]
    }
   ],
   "source": [
    "# as labels range from 1 to 50, we have subtract 1\n",
    "\n",
    "trainval_sig = signature[:, (unique_labels_trainval)-1]\n",
    "test_seen_sig = signature[:, (unique_labels_test_seen)-1]\n",
    "test_unseen_sig = signature[:, (unique_labels_test_unseen)-1]\n",
    "\n",
    "print(\"Signature for trainval:\", trainval_sig.shape)\n",
    "print(\"Signature for test seen:\", test_seen_sig.shape)\n",
    "print(\"Signature for test unseen:\", test_unseen_sig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74ca9ca5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34]\n",
      " [19]\n",
      " [34]\n",
      " ...\n",
      " [32]\n",
      " [16]\n",
      " [37]] (23527, 1)\n",
      "[[19]\n",
      " [39]\n",
      " [11]\n",
      " ...\n",
      " [20]\n",
      " [12]\n",
      " [22]] (5882, 1)\n",
      "[[4]\n",
      " [4]\n",
      " [4]\n",
      " ...\n",
      " [8]\n",
      " [8]\n",
      " [8]] (7913, 1)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] (40,)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] (40,)\n",
      "[0 1 2 3 4 5 6 7 8 9] (10,)\n"
     ]
    }
   ],
   "source": [
    "# by doing this modification, we are changing the range of trainval and test seen labels from 0 to 39 \n",
    "# and test unseen labels from 0 to 9\n",
    "\n",
    "k = 0\n",
    "new_labels_trainval = np.zeros((len(labels_trainval), 1), dtype = 'int')\n",
    "for labels in unique_labels_trainval:\n",
    "    new_labels_trainval[labels_trainval == labels] = k\n",
    "    k = k+1\n",
    "    \n",
    "print(new_labels_trainval, new_labels_trainval.shape)#(23527, 1)\n",
    "\n",
    "l = 0\n",
    "new_labels_test_seen = np.zeros((len(labels_test_seen), 1), dtype = 'int')\n",
    "for labels in unique_labels_test_seen:\n",
    "    new_labels_test_seen[labels_test_seen == labels] = l\n",
    "    l = l+1\n",
    "    \n",
    "print(new_labels_test_seen, new_labels_test_seen.shape)# (5882, 1)\n",
    "\n",
    "m = 0\n",
    "new_labels_test_unseen = np.zeros((len(labels_test_unseen), 1), dtype = 'int')\n",
    "for labels in unique_labels_test_unseen:\n",
    "    new_labels_test_unseen[labels_test_unseen == labels] = m\n",
    "    m = m+1  \n",
    "\n",
    "print(new_labels_test_unseen, new_labels_test_unseen.shape) #  (7913, 1)  \n",
    "\n",
    "\n",
    "print(np.unique(new_labels_trainval), np.unique(new_labels_trainval).shape)\n",
    "\n",
    "print(np.unique(new_labels_test_seen), np.unique(new_labels_test_seen).shape)\n",
    "\n",
    "print(np.unique(new_labels_test_unseen), np.unique(new_labels_test_unseen).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c560b958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23527\n",
      "40\n",
      "5882\n",
      "40\n",
      "7913\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#params for trainval and test set\n",
    "m_trainval = new_labels_trainval.shape[0]# number of instances in training set: 23527\n",
    "print(m_trainval)\n",
    "\n",
    "z_trainval = len(unique_labels_trainval)# number of classes in training set: 40\n",
    "print(z_trainval)\n",
    "\n",
    "\n",
    "n_test_seen = new_labels_test_seen.shape[0]# 5882\n",
    "print(n_test_seen)\n",
    "\n",
    "z1_test_seen = len(unique_labels_test_seen)# 40\n",
    "print(z1_test_seen)\n",
    "\n",
    "\n",
    "n_test_unseen = new_labels_test_unseen.shape[0]# 7913\n",
    "print(n_test_unseen)\n",
    "\n",
    "z1_test_unseen = len(unique_labels_test_unseen)# 10\n",
    "print(z1_test_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37635eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]] (23527, 40)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "gt_trainval = to_categorical(new_labels_trainval, z_trainval)\n",
    "\n",
    "print(gt_trainval, gt_trainval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b7c79ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#grountruth for trainval and test set\n",
    "#gt_trainval = 0*np.ones((m_trainval, z_trainval))# 23527, 40\n",
    "#gt_trainval[np.arange(m_trainval), np.squeeze(new_labels_trainval)] = 1\n",
    "\n",
    "#print(gt_trainval, gt_trainval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99410b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n",
      "85\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "input1_shape = trainval_vec.shape[1]\n",
    "print(input1_shape)\n",
    "\n",
    "attribute_shape = trainval_sig.shape[0]\n",
    "print(attribute_shape)\n",
    "\n",
    "output_shape = z_trainval\n",
    "print(output_shape)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8fe1e8d3",
   "metadata": {},
   "source": [
    "Step 3 - Define 'model2' for attribute to class label mapping\n",
    "\t\t Define 'model1' for visual feature to class label mapping\n",
    "\t\t Train 'model2' and 'model1' through the iterative process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3eecfe31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 85)]              0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 40)                3440      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,440\n",
      "Trainable params: 3,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from keras.optimizers import SGD, Adam, Adagrad\n",
    "\n",
    "# define model2 for attribute to class label mapping\n",
    "\n",
    "input2 = Input(shape = attribute_shape)\n",
    "output = Dense(output_shape, name=\"output\", activation='softmax')(input2)\n",
    "\n",
    "model2 = Model(inputs = input2, outputs = output)\n",
    "\n",
    "#sgd = SGD(learning_rate = 1e-2, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "opt = Adam(learning_rate = 1e-2, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0001)\n",
    "\n",
    "model2.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bde8378e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 2048)]            0         \n",
      "                                                                 \n",
      " intermediate (Dense)        (None, 85)                174165    \n",
      "                                                                 \n",
      " output (Dense)              (None, 40)                3440      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,605\n",
      "Trainable params: 177,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model1 for resnet feature to class label mapping\n",
    "\n",
    "input1 = Input(shape = input1_shape)\n",
    "#inter_pre = Dense(512, name=\"intermediate_previous\", activation='relu')(input1)\n",
    "inter = Dense(attribute_shape, name = \"intermediate\", activation = 'linear')(input1)\n",
    "output = Dense(output_shape, name=\"output\", activation='softmax')(inter)\n",
    "\n",
    "model1 = Model(inputs = input1, outputs = output)\n",
    "\n",
    "opt = Adam(learning_rate = 1e-2, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0001)\n",
    "\n",
    "model1.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9566a2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23527, 2048)\n",
      "(23527, 85)\n",
      "(23527, 40)\n"
     ]
    }
   ],
   "source": [
    "trainval_input1 = trainval_vec\n",
    "print(trainval_input1.shape)\n",
    "\n",
    "trainval_input2 = train_attributes\n",
    "print(trainval_input2.shape)\n",
    "\n",
    "trainval_output = gt_trainval\n",
    "print(trainval_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c995f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "batch_size = 16\n",
    "from sklearn.model_selection import train_test_split    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6928ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train1, X_val1, y_train1, y_val1 = train_test_split(trainval_input1, trainval_output, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#train_gen1 = DataGenerator(X_train1, y_train1, batch_size)   \n",
    "#val_gen1 = DataGenerator(X_val1, y_val1, batch_size)\n",
    "\n",
    "\n",
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(trainval_input2, trainval_output, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#train_gen2 = DataGenerator(X_train2, y_train2, batch_size)   \n",
    "#val_gen2 = DataGenerator(X_val2, y_val2, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22218dbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n",
      "model 2 is trained: training acc: 0.9285714030265808 , training loss: 0.863211452960968 , validation acc: 0.8125 , validation_loss: 0.9085986614227295\n",
      "model 1 is trained: training acc: 0.9642857313156128 , training loss: 0.8608346581459045 , validation acc: 0.8125 , validation_loss: 29.317358016967773\n",
      "micro average\n",
      "seen accuracy: 73.67236013527551 unseen accuracy: 49.18856976724767 harmonic mean: 58.99089367640173\n",
      "macro average\n",
      "seen accuracy: 76.91261475688542 unseen accuracy: 38.253506887400476 harmonic mean: 51.09449196210691\n",
      "best accuracy micro seen accuracy: 73.67236013527551 unseen accuracy: 49.18856976724767 harmonic mean: 58.99089367640173\n",
      "best accuracy macro seen accuracy: 76.91261475688542 unseen accuracy: 38.253506887400476 harmonic mean: 51.09449196210691\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 1\n",
      "model 2 is trained: training acc: 0.9910714030265808 , training loss: 0.3475036323070526 , validation acc: 1.0 , validation_loss: 0.27758052945137024\n",
      "model 1 is trained: training acc: 0.9732142686843872 , training loss: 2.003528118133545 , validation acc: 0.875 , validation_loss: 89.33351135253906\n",
      "micro average\n",
      "seen accuracy: 81.95910907316964 unseen accuracy: 53.9882507542992 harmonic mean: 65.09620985441428\n",
      "macro average\n",
      "seen accuracy: 84.7670860251615 unseen accuracy: 48.90686212561607 harmonic mean: 62.026928154267964\n",
      "best accuracy micro seen accuracy: 81.95910907316964 unseen accuracy: 53.9882507542992 harmonic mean: 65.09620985441428\n",
      "best accuracy macro seen accuracy: 84.7670860251615 unseen accuracy: 48.90686212561607 harmonic mean: 62.026928154267964\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 2\n",
      "model 2 is trained: training acc: 1.0 , training loss: 0.19928106665611267 , validation acc: 1.0 , validation_loss: 0.14667409658432007\n",
      "model 1 is trained: training acc: 0.9821428656578064 , training loss: 0.5910503268241882 , validation acc: 0.9375 , validation_loss: 3.3093185424804688\n",
      "micro average\n",
      "seen accuracy: 81.61538619186301 unseen accuracy: 44.32395432209714 harmonic mean: 57.44855634125634\n",
      "macro average\n",
      "seen accuracy: 84.92009520571234 unseen accuracy: 38.45570580058133 harmonic mean: 52.93845585848139\n",
      "best accuracy micro seen accuracy: 81.95910907316964 unseen accuracy: 53.9882507542992 harmonic mean: 65.09620985441428\n",
      "best accuracy macro seen accuracy: 84.7670860251615 unseen accuracy: 48.90686212561607 harmonic mean: 62.026928154267964\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 3\n",
      "model 2 is trained: training acc: 1.0 , training loss: 0.16099953651428223 , validation acc: 1.0 , validation_loss: 0.2271685153245926\n",
      "model 1 is trained: training acc: 0.9821428656578064 , training loss: 1.395140528678894 , validation acc: 0.875 , validation_loss: 43.698822021484375\n",
      "micro average\n",
      "seen accuracy: 85.57708197472176 unseen accuracy: 55.143853173131184 harmonic mean: 67.0696231295059\n",
      "macro average\n",
      "seen accuracy: 87.81026861611697 unseen accuracy: 47.946417288007076 harmonic mean: 62.02549440863211\n",
      "best accuracy micro seen accuracy: 85.57708197472176 unseen accuracy: 55.143853173131184 harmonic mean: 67.0696231295059\n",
      "best accuracy macro seen accuracy: 84.7670860251615 unseen accuracy: 48.90686212561607 harmonic mean: 62.026928154267964\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 4\n",
      "model 2 is trained: training acc: 1.0 , training loss: 0.1273464858531952 , validation acc: 1.0 , validation_loss: 0.12470676004886627\n",
      "model 1 is trained: training acc: 0.9821428656578064 , training loss: 3.1254730224609375 , validation acc: 0.9375 , validation_loss: 28.831573486328125\n",
      "micro average\n",
      "seen accuracy: 84.59192179082208 unseen accuracy: 53.78270847114136 harmonic mean: 65.75746811502005\n",
      "macro average\n",
      "seen accuracy: 87.50425025501531 unseen accuracy: 41.70352584354859 harmonic mean: 56.48631796195638\n",
      "best accuracy micro seen accuracy: 85.57708197472176 unseen accuracy: 55.143853173131184 harmonic mean: 67.0696231295059\n",
      "best accuracy macro seen accuracy: 84.7670860251615 unseen accuracy: 48.90686212561607 harmonic mean: 62.026928154267964\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 5\n",
      "model 2 is trained: training acc: 1.0 , training loss: 0.1140630766749382 , validation acc: 1.0 , validation_loss: 0.11996696889400482\n",
      "model 1 is trained: training acc: 0.9811320900917053 , training loss: 3.5125997066497803 , validation acc: 0.8125 , validation_loss: 13.409401893615723\n",
      "micro average\n",
      "seen accuracy: 84.82009643877832 unseen accuracy: 49.29269083369546 harmonic mean: 62.35066581304394\n",
      "macro average\n",
      "seen accuracy: 87.23223393403605 unseen accuracy: 43.77606470365222 harmonic mean: 58.29682480651551\n",
      "best accuracy micro seen accuracy: 85.57708197472176 unseen accuracy: 55.143853173131184 harmonic mean: 67.0696231295059\n",
      "best accuracy macro seen accuracy: 84.7670860251615 unseen accuracy: 48.90686212561607 harmonic mean: 62.026928154267964\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 6\n",
      "model 2 is trained: training acc: 1.0 , training loss: 0.10778888314962387 , validation acc: 1.0 , validation_loss: 0.09958559274673462\n",
      "model 1 is trained: training acc: 1.0 , training loss: 0.0 , validation acc: 1.0 , validation_loss: 0.0\n",
      "micro average\n",
      "seen accuracy: 85.19231977165367 unseen accuracy: 48.88967717106737 harmonic mean: 62.126536090743926\n",
      "macro average\n",
      "seen accuracy: 88.28629717783068 unseen accuracy: 40.70516870971819 harmonic mean: 55.72009894844995\n",
      "best accuracy micro seen accuracy: 85.57708197472176 unseen accuracy: 55.143853173131184 harmonic mean: 67.0696231295059\n",
      "best accuracy macro seen accuracy: 84.7670860251615 unseen accuracy: 48.90686212561607 harmonic mean: 62.026928154267964\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 7\n",
      "model 2 is trained: training acc: 1.0 , training loss: 0.08942590653896332 , validation acc: 1.0 , validation_loss: 0.08188927173614502\n",
      "model 1 is trained: training acc: 0.9821428656578064 , training loss: 4.942784786224365 , validation acc: 0.875 , validation_loss: 3.7734909057617188\n",
      "micro average\n",
      "seen accuracy: 84.67548796758312 unseen accuracy: 52.887137329649356 harmonic mean: 65.10844280443861\n",
      "macro average\n",
      "seen accuracy: 86.6031961917715 unseen accuracy: 47.352457980538354 harmonic mean: 61.22734025659181\n",
      "best accuracy micro seen accuracy: 85.57708197472176 unseen accuracy: 55.143853173131184 harmonic mean: 67.0696231295059\n",
      "best accuracy macro seen accuracy: 84.7670860251615 unseen accuracy: 48.90686212561607 harmonic mean: 62.026928154267964\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 8\n",
      "model 2 is trained: training acc: 1.0 , training loss: 0.08795865625143051 , validation acc: 1.0 , validation_loss: 0.07091279327869415\n",
      "model 1 is trained: training acc: 0.9910714030265808 , training loss: 0.03250535950064659 , validation acc: 0.9375 , validation_loss: 35.954925537109375\n",
      "micro average\n",
      "seen accuracy: 87.35579100684892 unseen accuracy: 56.411931132070116 harmonic mean: 68.55375870119387\n",
      "macro average\n",
      "seen accuracy: 89.39136348180891 unseen accuracy: 49.14697333501832 harmonic mean: 63.423815506463754\n",
      "best accuracy micro seen accuracy: 87.35579100684892 unseen accuracy: 56.411931132070116 harmonic mean: 68.55375870119387\n",
      "best accuracy macro seen accuracy: 89.39136348180891 unseen accuracy: 49.14697333501832 harmonic mean: 63.423815506463754\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 9\n",
      "model 2 is trained: training acc: 1.0 , training loss: 0.07218160480260849 , validation acc: 1.0 , validation_loss: 0.07761119306087494\n",
      "model 1 is trained: training acc: 0.9910714030265808 , training loss: 0.4489092230796814 , validation acc: 0.9375 , validation_loss: 6.8746795654296875\n",
      "micro average\n",
      "seen accuracy: 85.76617011603031 unseen accuracy: 51.19363500254595 harmonic mean: 64.11635887894234\n",
      "macro average\n",
      "seen accuracy: 87.4702482148929 unseen accuracy: 42.99254391507646 harmonic mean: 57.649670473020024\n",
      "best accuracy micro seen accuracy: 87.35579100684892 unseen accuracy: 56.411931132070116 harmonic mean: 68.55375870119387\n",
      "best accuracy macro seen accuracy: 89.39136348180891 unseen accuracy: 49.14697333501832 harmonic mean: 63.423815506463754\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "iteration = 10\n",
    "epochs1 = 100\n",
    "epochs2 = 200\n",
    "\n",
    "best_performance_micro = [0, 0, 0]\n",
    "best_performance_macro = [0, 0, 0]\n",
    "\n",
    "save_path = 'C:/Users/Admin/Sushree_Codes/Sush_3/Results/'\n",
    "name = 'model1_AWA2_it10_100eph_adam_cce_16bch_1e-2lr_model2_adam_200'\n",
    "        \n",
    "    \n",
    "for i in range(iteration):\n",
    "    X_train2_it = X_train2[(len(X_train2)//iteration)*i:(len(X_train2)//iteration)*(i+1)]\n",
    "    X_val2_it = X_val2[(len(X_val2)//iteration)*i:(len(X_val2)//iteration)*(i+1)]\n",
    "    y_train2_it = y_train2[(len(y_train2)//iteration)*i:(len(y_train2)//iteration)*(i+1)]\n",
    "    y_val2_it = y_val2[(len(y_val2)//iteration)*i:(len(y_val2)//iteration)*(i+1)]\n",
    "    \n",
    "    train_gen2 = DataGenerator(X_train2_it, y_train2_it, batch_size)   \n",
    "    val_gen2 = DataGenerator(X_val2_it, y_val2_it, batch_size)\n",
    "\n",
    "    train_summary2 = model2.fit(train_gen2, epochs = epochs2, verbose = 0, callbacks = None, validation_data = val_gen2, \n",
    "                              shuffle = True, steps_per_epoch = len(train_gen2)//batch_size, \n",
    "                              validation_steps = len(val_gen2)//batch_size)\n",
    "\n",
    "    print(\"iteration:\", i)\n",
    "    print('model 2 is trained:', 'training acc:', train_summary2.history['accuracy'][-1], ',',  \n",
    "          'training loss:', train_summary2.history['loss'][-1], ',', \n",
    "          'validation acc:', train_summary2.history['val_accuracy'][-1], ',',\n",
    "         'validation_loss:', train_summary2.history['val_loss'][-1])\n",
    "\n",
    "    weights_list2 = model2.get_weights()\n",
    "    #print(weights_list2)\n",
    "\n",
    "    model1.layers[-1].set_weights(weights_list2)\n",
    "\n",
    "    X_train1_it = X_train1[(len(X_train1)//iteration)*i:(len(X_train1)//iteration)*(i+1)]\n",
    "    X_val1_it = X_val1[(len(X_val1)//iteration)*i:(len(X_val1)//iteration)*(i+1)]\n",
    "    y_train1_it = y_train1[(len(y_train1)//iteration)*i:(len(y_train1)//iteration)*(i+1)]\n",
    "    y_val1_it = y_val1[(len(y_val1)//iteration)*i:(len(y_val1)//iteration)*(i+1)]\n",
    "    \n",
    "    train_gen1 = DataGenerator(X_train1_it, y_train1_it, batch_size)   \n",
    "    val_gen1 = DataGenerator(X_val1_it, y_val1_it, batch_size)\n",
    "    \n",
    "    for layer in model1.layers[2:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    train_summary1 = model1.fit(train_gen1, epochs = epochs1, verbose = 0, callbacks = None, validation_data = val_gen1, \n",
    "                              shuffle = True, steps_per_epoch = len(train_gen1)//batch_size, \n",
    "                              validation_steps = len(val_gen1)//batch_size)\n",
    "    \n",
    "    #print(\"iteration:\", i)\n",
    "    print('model 1 is trained:', 'training acc:', train_summary1.history['accuracy'][-1], ',',  \n",
    "          'training loss:', train_summary1.history['loss'][-1], ',', \n",
    "          'validation acc:', train_summary1.history['val_accuracy'][-1], ',',\n",
    "         'validation_loss:', train_summary1.history['val_loss'][-1])\n",
    "    \n",
    "    weights_list1 = Model(inputs = model1.input, outputs = model1.layers[-1].output).get_weights()\n",
    "    \n",
    "    #predictions\n",
    "    #outputs_seen = np.matmul(np.matmul(test_seen_vec, np.matmul(weights_list1[0], weights_list1[2])), test_seen_sig)\n",
    "    outputs_seen = np.matmul(np.matmul(test_seen_vec, weights_list1[0]), test_seen_sig)\n",
    "    \n",
    "    preds_seen = np.array([np.argmax(output) for output in outputs_seen])\n",
    "    \n",
    "    cm_seen = confusion_matrix(new_labels_test_seen, preds_seen)\n",
    "    #print(cm)\n",
    "    # Compute macro average (averaging performance metrics by first calculating the metric separately for each class and \n",
    "    # then averaging these class-specific metrics)\n",
    "    cm_seen_micro = cm_seen.astype('float') / cm_seen.sum(axis=1)[:, np.newaxis]\n",
    "    #print(cm)\n",
    "    avg_seen_micro = (sum(cm_seen_micro.diagonal())/len(unique_labels_test_seen))*100\n",
    "\n",
    "    avg_seen_macro = (sum(cm_seen.diagonal())/len(new_labels_test_seen))*100\n",
    "    \n",
    "    #predictions\n",
    "    outputs_unseen = np.matmul(np.matmul(test_unseen_vec, weights_list1[0]), test_unseen_sig)\n",
    "    \n",
    "    preds_unseen = np.array([np.argmax(output) for output in outputs_unseen])\n",
    "    \n",
    "    cm_unseen = confusion_matrix(new_labels_test_unseen, preds_unseen)\n",
    "    # Compute macro average (averaging performance metrics by first calculating the metric separately for each class and \n",
    "    # then averaging these class-specific metrics)\n",
    "    cm_unseen_micro = cm_unseen.astype('float') / cm_unseen.sum(axis=1)[:, np.newaxis]\n",
    "    avg_unseen_micro = (sum(cm_unseen_micro.diagonal())/len(unique_labels_test_unseen))*100\n",
    "\n",
    "    avg_unseen_macro = (sum(cm_unseen.diagonal())/len(new_labels_test_unseen))*100\n",
    "    \n",
    "    harmonic_micro = (2*avg_seen_micro*avg_unseen_micro) / (avg_seen_micro + avg_unseen_micro)\n",
    "    harmonic_macro = (2*avg_seen_macro*avg_unseen_macro) / (avg_seen_macro + avg_unseen_macro)\n",
    "    \n",
    "    print('micro average')\n",
    "    print('seen accuracy:', avg_seen_micro, 'unseen accuracy:', avg_unseen_micro, 'harmonic mean:', harmonic_micro)\n",
    "    \n",
    "    print('macro average')\n",
    "    print('seen accuracy:', avg_seen_macro, 'unseen accuracy:', avg_unseen_macro, 'harmonic mean:', harmonic_macro)\n",
    "    \n",
    "    if harmonic_micro > best_performance_micro[2]:\n",
    "        best_performance_micro = [avg_seen_micro, avg_unseen_micro, harmonic_micro]\n",
    "        model1.save_weights(save_path + 'bw_micro_' + name + '.h5', overwrite=True)\n",
    "        \n",
    "    if harmonic_macro > best_performance_macro[2]:\n",
    "        best_performance_macro = [avg_seen_macro, avg_unseen_macro, harmonic_macro]\n",
    "        model1.save_weights(save_path + 'bw_macro_' + name + '.h5', overwrite=True)\n",
    "        \n",
    "    print('best accuracy micro','seen accuracy:', best_performance_micro[0], 'unseen accuracy:', best_performance_micro[1], 'harmonic mean:', best_performance_micro[2])\n",
    "    print('best accuracy macro', 'seen accuracy:', best_performance_macro[0], 'unseen accuracy:', best_performance_macro[1], 'harmonic mean:', best_performance_macro[2])\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    weights_list3 = model1.get_weights()\n",
    "    model2.set_weights(weights_list3[2:])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5febed2d",
   "metadata": {},
   "source": [
    "Step 4 - Evaluate for seen and unseen categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92c61599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] (5882, 40)\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 40.6137 - accuracy: 0.9148\n",
      "184/184 [==============================] - 0s 778us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.3452841"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt_test_seen = to_categorical(new_labels_test_seen, z1_test_seen)\n",
    "\n",
    "print(gt_test_seen, gt_test_seen.shape)\n",
    "\n",
    "model1.evaluate(test_seen_vec, gt_test_seen)\n",
    "\n",
    "p = model1.predict(test_seen_vec)\n",
    "\n",
    "import tensorflow\n",
    "cce = tensorflow.keras.losses.CategoricalCrossentropy()\n",
    "cce(gt_test_seen, p).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "33336d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "69.78682534316047"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_seen_updated = 91.48\n",
    "unseen_accuracy = 56.41\n",
    "(2*accuracy_seen_updated*unseen_accuracy) / (accuracy_seen_updated + unseen_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c997d690",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
