{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6e42e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "raw",
   "id": "aacdede7",
   "metadata": {},
   "source": [
    "Code Description: \n",
    "\n",
    "GZSL_CUB_5: Experiments with Bert attributes and latent embedding\n",
    "\tStep 1 - Class wise continous attributes are extracted (for CUB: 200 categories, and each category has attribute vectors of length 312) \n",
    "\tStep 2 - Word vectors are extracted for each semantic attribute using pretrained language models (w2v, Bert, Bart, GPT) \n",
    "             New attributes are formed by aggregating the continous attribute values and word vectors\n",
    "\tStep 3 - Visual features are extracted from pre-trained ResNet101 (without finetuning)\n",
    "\tStep 4 - New attribute vectors are transformed into a lower dimensional space using 'model_transform_attribute'\n",
    "\tStep 5 - 'embedding_model' is trained to perform embedding between visual features and attribute vectors (or semantic features)\n",
    "\t         embedding_model_0 is used to extract embedded visual features\n",
    "\t\t     embedding_model_1 is used to extract embedded semantic features\n",
    "\tStep 6 - Define 'model2' for attribute to class label mapping\n",
    "\t\t     Define 'model1' for visual feature to class label mapping\n",
    "\t\t     Train 'model2' and 'model1' through the iterative process\n",
    "\tStep 7 - Evaluate for seen and unseen categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64bb0868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please add the folder name of the dataset to run it on different dataset.\n",
    "dataset = 'CUB'\n",
    "path = 'E:/Sushree/Dataset/data/xlsa17/data/'\n",
    "\n",
    "res101 = scipy.io.loadmat(path + dataset + '/res101.mat')\n",
    "att_splits = scipy.io.loadmat(path + dataset + '/att_splits.mat')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c6c562e4",
   "metadata": {},
   "source": [
    "Step 1 - Class wise continous attributes are extracted (for CUB: 200 categories, and each category has attribute vectors of length 312) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6082508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "signature = att_splits['att']\n",
    "#signature = att_splits['original_att']\n",
    "#signature = signature/100\n",
    "print(signature.shape) #(312, 200)\n",
    "\n",
    "attribute = signature.transpose()\n",
    "attribute[attribute<0] = 0\n",
    "print(attribute, attribute.shape)#(200, 312)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2366d4b5",
   "metadata": {},
   "source": [
    "Step 2 - Word vectors are extracted for each semantic attribute using pretrained language models (w2v, Bert, Bart, GPT) \n",
    "         New attributes are formed by aggregating the continous attribute values and word vectors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2293d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import pandas as pd\n",
    "print('Load pretrain w2v model')\n",
    "\n",
    "#model_name = 'word2vec-google-news-300' # length = 300\n",
    "#model = api.load(model_name)\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer, TFBertModel, BartTokenizer, TFBartModel, GPT2Tokenizer, TFGPT2Model\n",
    "from transformers import OpenAIGPTTokenizer, TFOpenAIGPTModel\n",
    "\n",
    "# Bert model\n",
    "#---------------------------------------------------------------------------\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased') # length 768\n",
    "model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-large-uncased') # 1024\n",
    "#model = TFBertModel.from_pretrained(\"bert-large-uncased\")\n",
    "\n",
    "# Bart model\n",
    "#---------------------------------------------------------------------------\n",
    "#tokenizer = BartTokenizer.from_pretrained('facebook/bart-base') # length 768\n",
    "#model = TFBartModel.from_pretrained(\"facebook/bart-base\")\n",
    "\n",
    "#tokenizer = BartTokenizer.from_pretrained('facebook/bart-large') # length 1024\n",
    "#model = TFBartModel.from_pretrained(\"facebook/bart-large\")\n",
    "\n",
    "# GPT2 model\n",
    "#---------------------------------------------------------------------------\n",
    "#tokenizer = GPT2Tokenizer.from_pretrained('gpt2') # length 768\n",
    "#model = TFGPT2Model.from_pretrained('gpt2')\n",
    "\n",
    "# GPT model\n",
    "#---------------------------------------------------------------------------\n",
    "#tokenizer = OpenAIGPTTokenizer.from_pretrained('openai-gpt')# length 768\n",
    "#model = TFOpenAIGPTModel.from_pretrained('openai-gpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d5899c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#tokenizer = OpenAIGPTTokenizer.from_pretrained('openai-gpt')\n",
    "#model = TFOpenAIGPTModel.from_pretrained('openai-gpt')\n",
    "#encoded_input = tokenizer('sushree', return_tensors='tf')\n",
    "#print(encoded_input)\n",
    "#length = encoded_input.input_ids.shape[1]\n",
    "#print(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25be9a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tokenizer)\n",
    "#out = model(encoded_input).last_hidden_state[:, 2, :]\n",
    "#print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab0196a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "dim_w2v = 768\n",
    "\n",
    "#%%\n",
    "#For CUB\n",
    "replace_word = [('spatulate','broad'),('upperparts','upper parts'),('grey','gray'), ('eyering', 'eye ring')] # for CUB\n",
    "\n",
    "\n",
    "path = 'E:/Sushree/Dataset/CUB_200_2011/CUB_200_2011/attributes/attributes.txt'\n",
    "df=pd.read_csv(path,sep=' ',header = None, names = ['idx','des'])\n",
    "des = df['des'].values\n",
    "\n",
    "#%% replace out of dictionary (OOD) words\n",
    "for pair in replace_word:\n",
    "    for idx,s in enumerate(des):\n",
    "        des[idx] = s.replace(pair[0],pair[1])\n",
    "print('Done replacing OOD words')\n",
    "\n",
    "#%% filter\n",
    "new_des = [' '.join(i.split('_')) for i in des]\n",
    "new_des = [' '.join(i.split('-')) for i in new_des]\n",
    "new_des = [' '.join(i.split('::')) for i in new_des]\n",
    "new_des = [i.split('(')[0] for i in new_des]\n",
    "new_des = [i[4:] for i in new_des]\n",
    "\n",
    "df['new_des'] = des\n",
    "df.to_csv('E:/Sushree/Dataset/CUB_200_2011/CUB_200_2011/attributes/new_des.csv')\n",
    "print('Done preprocessing attribute des')\n",
    "import pickle\n",
    "\n",
    "\n",
    "# for word2vec\n",
    "# -----------------------------------------------------------------------------------\n",
    "#counter_err = 0\n",
    "#\n",
    "#all_w2v = []\n",
    "#for s in new_des:\n",
    "#    print(s)\n",
    "#    words = s.split(' ')\n",
    "#    if words[-1] == '':     #remove empty element\n",
    "#        words = words[:-1]\n",
    "#    w2v = np.zeros(dim_w2v)\n",
    "#    for w in words:\n",
    "#        try:\n",
    "#            w2v += model[w]\n",
    "#        except Exception as e:\n",
    "#            print(e)\n",
    "#            counter_err += 1\n",
    "#    w2v = w2v / len(words)  \n",
    "#    all_w2v.append(w2v[np.newaxis,:])\n",
    "    \n",
    "#print('counter_err ',counter_err)\n",
    "\n",
    "#w2v_att = np.concatenate(all_w2v,axis=0)\n",
    "#print(w2v_att, w2v_att.shape)\n",
    "\n",
    "# for Bert attributes\n",
    "# -----------------------------------------------------------------------------------\n",
    "counter_err = 0\n",
    "counter = 0\n",
    "w2v_att = np.zeros((signature.shape[0], dim_w2v))\n",
    "for s in des:\n",
    "    print(s)\n",
    "    w2v = np.zeros(dim_w2v)\n",
    "    encoded_input = tokenizer(s, return_tensors='tf')\n",
    "    length = encoded_input.input_ids.shape[1]\n",
    "    #print(length)\n",
    "    for i in range(length-2): # for Bert, Bart\n",
    "    #for i in range(length): # for GPT2\n",
    "        try:\n",
    "            w2v = w2v + model(encoded_input).last_hidden_state[:, i+1, :] # for Bert, Bart\n",
    "            #w2v = w2v + model(encoded_input).last_hidden_state[:, i, :] # for GPT2\n",
    "        #print(model(encoded_input).last_hidden_state[:, i+1, :][:,1:2])\n",
    "        #print(w2v[:, 1:2])\n",
    "        #print(w2v.shape)\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            counter_err += 1\n",
    "    w2v = w2v / (length - 2)# for Bert, Bart\n",
    "    #w2v = w2v / length # for GPT2\n",
    "    #print(w2v[:, 1:2])\n",
    "    w2v_att[counter] = w2v\n",
    "    counter = counter + 1\n",
    "\n",
    "print('counter_err ',counter_err)\n",
    "print(w2v_att, w2v_att.shape)\n",
    "# -----------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "attribute_new = np.einsum('ij,jl->ijl', attribute, w2v_att)\n",
    "\n",
    "attribute_new = np.reshape(attribute_new, [attribute_new.shape[0], attribute_new.shape[1]* attribute_new.shape[2]])\n",
    "print(attribute_new, attribute_new.shape)\n",
    "\n",
    "#attribute_new[attribute_new<0] = 0\n",
    "#print(attribute_new, attribute_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237b819e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# total number of instances or images = 11788: ranges from 0 to 11787\n",
    "\n",
    "trainval_loc = np.squeeze(att_splits['trainval_loc']-1) # -1: to consider the overflow problem\n",
    "print(np.unique(trainval_loc), np.max(np.unique(trainval_loc))) # smallest location: 2, largest location 11787\n",
    "\n",
    "labels = res101['labels']# direct class labels\n",
    "print('labels', labels, labels.shape)# 11788 x 1\n",
    "\n",
    "print('unique_labels', np.unique(labels), np.unique(labels).shape)# class labels range from 1 to 200, 200 classes\n",
    "\n",
    "# get the labels for trainval, test seen and test unseen sets\n",
    "\n",
    "labels_trainval = labels[trainval_loc]\n",
    "print('labels_trainval', labels_trainval, labels_trainval.shape)\n",
    "\n",
    "unique_labels_trainval = np.unique(labels_trainval) # labels min:1 max:200\n",
    "print('unique_labels_trainval', unique_labels_trainval, unique_labels_trainval.shape)# 200 classes\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cb503206",
   "metadata": {},
   "source": [
    "Step 3 - Visual features are extracted from pre-trained ResNet101 (without finetuning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88acec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features = res101['features']\n",
    "\n",
    "# locations are already subtracted by 1, so they range from 0 to 11787\n",
    "trainval_vec = X_features[:, trainval_loc].transpose()\n",
    "print(\"Features for trainval:\", trainval_vec.shape) #(7057, 2048)\n",
    "\n",
    "# attribute is defined for all 200 classes, so we cant use locations directly, instead we have to use labels \n",
    "# that range from 1 to 200, so we have to subtract 1\n",
    "\n",
    "trainval_attributes = np.zeros((len(trainval_loc), attribute_new.shape[1]))\n",
    "for i in range(len(trainval_loc)):\n",
    "    trainval_attributes[i] = attribute_new[int(labels_trainval[i])-1]\n",
    "\n",
    "print(trainval_attributes, trainval_attributes.shape)# (7057, 319488)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5e6b0183",
   "metadata": {},
   "source": [
    "Step 4 - New attribute vectors are transformed into a lower dimensional space using 'model_transform_attribute'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc71b12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from keras.optimizers import SGD, Adam, Adagrad\n",
    "import keras.backend as K\n",
    "\n",
    "attribute_shape_new = attribute_new.shape[1]\n",
    "print(attribute_shape_new)\n",
    "\n",
    "# define model for attribute transformation\n",
    "\n",
    "inputt = Input(shape = attribute_shape_new)\n",
    "hidden = Dense(4096, name=\"layer1\", activation='linear')(inputt)\n",
    "output = Dense(2048, name=\"layer3\", activation='linear')(hidden)\n",
    "\n",
    "model_transform_attribute = Model(inputs = inputt, outputs = output)\n",
    "\n",
    "#sgd = SGD(learning_rate = 1e-2, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "opt = Adam(learning_rate = 1e-2, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0001)\n",
    "\n",
    "model_transform_attribute.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "for layer in model_transform_attribute.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "model_transform_attribute.summary()\n",
    "\n",
    "attribute_new = model_transform_attribute.predict(attribute_new)\n",
    "print(attribute_new, attribute_new.shape)\n",
    "\n",
    "\n",
    "trainval_attributes = np.zeros((len(trainval_loc), attribute_new.shape[1]))\n",
    "for i in range(len(trainval_loc)):\n",
    "    trainval_attributes[i] = attribute_new[int(labels_trainval[i])-1]\n",
    "\n",
    "print(trainval_attributes, trainval_attributes.shape)# (7057, 85)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e99b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_input1 = np.reshape(trainval_vec, [trainval_vec.shape[0], 1, 1, trainval_vec.shape[1]])\n",
    "print(trainval_input1.shape)\n",
    "\n",
    "trainval_input2 = np.reshape(trainval_attributes, [trainval_attributes.shape[0], 1, 1, trainval_attributes.shape[1]])\n",
    "print(trainval_input2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d22fe48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(trainval_input1, trainval_input2, test_size = 0.2, random_state = 42)\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "batch_size = 8\n",
    "train_gen = DataGenerator(X_train, y_train, batch_size)   \n",
    "val_gen = DataGenerator(X_val, y_val, batch_size)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "36fff63b",
   "metadata": {},
   "source": [
    "Step 5 - 'embedding_model' is trained to perform embedding between visual features and attribute vectors (or semantic features)\n",
    "         embedding_model_0 is used to extract embedded visual features\n",
    "         embedding_model_1 is used to extract embedded semantic features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74a76d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding model\n",
    "# -----------------------------------------------------------------------------------\n",
    "inputt = Input(shape = (1, 1, trainval_vec.shape[1]))\n",
    "hidden1 = Conv2D(2048, 1, name=\"layer1\", activation='relu')(inputt)\n",
    "output1 = Conv2D(1024, 1, name=\"layer2\", activation='relu')(hidden1)\n",
    "hidden2 = Conv2D(1024, 1, name=\"layer3\", activation='relu')(output1)\n",
    "output2 = Conv2D(trainval_attributes.shape[1], 1, name=\"layer4\", activation='linear')(hidden2)\n",
    "\n",
    "embedding_model = Model(inputs = inputt, outputs = output2)\n",
    "\n",
    "# embedding model variants\n",
    "# -----------------------------------------------------------------------------------\n",
    "\n",
    "#inputt = Input(shape = (1, 1, trainval_vec.shape[1]))\n",
    "#hidden1 = Conv2D(1024, 1, name=\"layer1\", activation='relu')(inputt)\n",
    "#output1 = Conv2D(1024, 1, name=\"layer2\", activation='relu')(hidden1)\n",
    "#hidden2 = Conv2D(1024, 1, name=\"layer3\", activation='relu')(output1)\n",
    "#output2 = Conv2D(trainval_attributes.shape[1], 1, name=\"layer4\", activation='linear')(hidden2)\n",
    "\n",
    "#embedding_model = Model(inputs = inputt, outputs = output2)\n",
    "\n",
    "\n",
    "adam = Adam(learning_rate = 0.0001, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0001)\n",
    "embedding_model.compile(adam, loss = tf.keras.losses.CosineSimilarity(axis=-1, reduction=tf.keras.losses.Reduction.AUTO), metrics = ['accuracy'])\n",
    "#embedding_model.compile(adam, loss = cosine_loss, metrics = ['accuracy'])\n",
    "\n",
    "embedding_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c663ebb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#CosineSimilarity is a number between -1 and 1. When it is a negative number between -1 and 0, 0 indicates orthogonality and \n",
    "#values closer to -1 indicate greater similarity. The values closer to 1 indicate greater dissimilarity. \n",
    "\n",
    "save_path = 'C:/Users/Admin/Sushree_Codes/Sush_3/Results/CUB/BertAttribute/with_LE/Embedding Model/'\n",
    "name = 'Reembedding_model_Bert_2048_1024_1024_CUB_200eph_adam_cos_16bch_0.0001lr'\n",
    "\n",
    "\n",
    "#file_path = save_path + 'bw_' + name + '.h5'\n",
    "\n",
    "#model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "#    filepath = file_path,\n",
    "#    monitor = 'val_accuracy',\n",
    "#    mode = 'max',\n",
    "#    save_best_only=True)\n",
    "\n",
    "#train_summary = embedding_model.fit(train_gen, epochs = 200, verbose = 1, callbacks = [model_checkpoint_callback], validation_data = val_gen, \n",
    "#                              shuffle = True, steps_per_epoch = len(train_gen)//batch_size, \n",
    "#                              validation_steps = len(val_gen)//batch_size)\n",
    "\n",
    "embedding_model.load_weights(save_path + 'bw_' + name + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34cf8bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model_0 = Model(inputs = embedding_model.input, outputs = embedding_model.layers[-3].output) # for embedding model\n",
    "#embedding_model_0 = Model(inputs = embedding_model.input, outputs = embedding_model.layers[-2].output) # for embedding model variants\n",
    "embedding_model_0.summary()\n",
    "\n",
    "trainval_vec = embedding_model_0.predict(trainval_input1)\n",
    "print(trainval_vec, trainval_vec.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47c5d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputt = Input(shape = (1, 1, trainval_attributes.shape[1]))\n",
    "hidden1 = Conv2DTranspose(1024, 1, name=\"layer1\", activation='relu')(inputt)\n",
    "\n",
    "embedding_model_1 = Model(inputs = inputt, outputs = hidden1)\n",
    "embedding_model_1.summary()\n",
    "\n",
    "w_list = Model(inputs = embedding_model_0.layers[-2].output, outputs = embedding_model_0.output).get_weights()\n",
    "#print(weights_list2)\n",
    "\n",
    "embedding_model_1.set_weights([np.transpose(w_list[0], (0, 1, 3, 2)), w_list[1]])\n",
    "\n",
    "trainval_attributes = embedding_model_1.predict(trainval_input2)\n",
    "print(trainval_attributes, trainval_attributes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c3e6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attribute_new = np.reshape(attribute_new, [attribute_new.shape[0], 1, 1, attribute_new.shape[1]])\n",
    "\n",
    "# as labels range from 1 to 200, we have subtract 1\n",
    "attribute_2 = embedding_model_1.predict(attribute_new)\n",
    "print(attribute_2, attribute_2.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecaa989",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "signature_2 = attribute_2.transpose()\n",
    "signature_2 = np.reshape(signature_2, [signature_2.shape[0], signature_2.shape[3]])\n",
    "print(signature_2, signature_2.shape)#(1024, 200)\n",
    "\n",
    "trainval_sig = signature_2[:, (unique_labels_trainval)-1]\n",
    "print(\"Signature for trainval:\", trainval_sig.shape)# (1024, 150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581a4c12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# by doing this modification, we are changing the range of trainval and test seen labels from 0 to 149 \n",
    "# and test unseen labels from 0 to 49\n",
    "\n",
    "k = 0\n",
    "new_labels_trainval = np.zeros((len(labels_trainval), 1), dtype = 'int')\n",
    "for labels in unique_labels_trainval:\n",
    "    new_labels_trainval[labels_trainval == labels] = k\n",
    "    k = k+1\n",
    "    \n",
    "print(new_labels_trainval, new_labels_trainval.shape)#(7057, 1)\n",
    "print(np.unique(new_labels_trainval), np.unique(new_labels_trainval).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee1341e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#params for trainval and test set\n",
    "m_trainval = new_labels_trainval.shape[0]# number of instances in training set: 7057\n",
    "print(m_trainval)\n",
    "\n",
    "z_trainval = len(unique_labels_trainval)# number of classes in training set: 150\n",
    "print(z_trainval)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845b8e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "gt_trainval = to_categorical(new_labels_trainval, z_trainval)\n",
    "\n",
    "print(gt_trainval, gt_trainval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08067319",
   "metadata": {},
   "outputs": [],
   "source": [
    "input1_shape = trainval_vec.shape[3]\n",
    "print(input1_shape)\n",
    "\n",
    "attribute_shape = trainval_sig.shape[0]\n",
    "print(attribute_shape)\n",
    "\n",
    "output_shape = z_trainval\n",
    "print(output_shape)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b18da34",
   "metadata": {},
   "source": [
    "Step 6 - Define 'model2' for attribute to class label mapping\n",
    "         Define 'model1' for visual feature to class label mapping\n",
    "         Train 'model2' and 'model1' through the iterative process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96792076",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from keras.optimizers import SGD, Adam, Adagrad\n",
    "\n",
    "# define model2 for attribute to class label mapping\n",
    "\n",
    "input2 = Input(shape = (1, 1, attribute_shape))\n",
    "flat = Flatten()(input2)\n",
    "output = Dense(output_shape, name=\"output\", activation='softmax')(flat)\n",
    "\n",
    "model2 = Model(inputs = input2, outputs = output)\n",
    "\n",
    "\n",
    "opt = Adam(learning_rate = 1e-2, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0001)\n",
    "#opt = SGD(learning_rate = 1e-2, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "model2.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b285876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model1 for visual feature to class label mapping\n",
    "\n",
    "input1 = Input(shape = (1,1, input1_shape))\n",
    "#inter_pre = Dense(512, name=\"intermediate_previous\", activation='relu')(input1)\n",
    "inter = Conv1D(attribute_shape, kernel_size = 1, name = \"intermediate\", activation = 'linear')(input1)\n",
    "flat = Flatten()(inter)\n",
    "output = Dense(output_shape, name=\"output\", activation='softmax')(flat)\n",
    "\n",
    "model1 = Model(inputs = input1, outputs = output)\n",
    "\n",
    "opt = Adam(learning_rate = 1e-2, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0001)\n",
    "#opt = SGD(learning_rate = 1e-2, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "model1.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd4ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_input1 = trainval_vec\n",
    "print(trainval_input1.shape)\n",
    "\n",
    "trainval_input2 = trainval_attributes\n",
    "print(trainval_input2.shape)\n",
    "\n",
    "trainval_output = gt_trainval\n",
    "print(trainval_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec915dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "batch_size = 8\n",
    "from sklearn.model_selection import train_test_split    \n",
    "\n",
    "\n",
    "X_train1, X_val1, y_train1, y_val1 = train_test_split(trainval_input1, trainval_output, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#train_gen1 = DataGenerator(X_train1, y_train1, batch_size)   \n",
    "#val_gen1 = DataGenerator(X_val1, y_val1, batch_size)\n",
    "\n",
    "\n",
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(trainval_input2, trainval_output, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#train_gen2 = DataGenerator(X_train2, y_train2, batch_size)   \n",
    "#val_gen2 = DataGenerator(X_val2, y_val2, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3fb3ece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels = res101['labels']# direct class labels\n",
    "print('labels', labels, labels.shape)# 7057 x 1\n",
    "\n",
    "test_seen_loc = np.squeeze(att_splits['test_seen_loc']-1)\n",
    "print(np.unique(test_seen_loc), np.max(np.unique(test_seen_loc))) # smallest location: 0, largest location 11727\n",
    "\n",
    "labels_test_seen = labels[test_seen_loc]\n",
    "print('labels_test_seen', labels_test_seen, labels_test_seen.shape)\n",
    "\n",
    "unique_labels_test_seen = np.unique(labels_test_seen) # labels min:1 max:200\n",
    "print('unique_labels_test_seen', unique_labels_test_seen, unique_labels_test_seen.shape)# 150 classes\n",
    "\n",
    "test_seen_vec = X_features[:, test_seen_loc].transpose()\n",
    "print(\"Features for test seen:\", test_seen_vec.shape)# (1764, 2048)\n",
    "\n",
    "test_seen_vec = np.reshape(test_seen_vec, [test_seen_vec.shape[0], 1, 1, test_seen_vec.shape[1]])\n",
    "test_seen_vec = embedding_model_0.predict(test_seen_vec)\n",
    "print(test_seen_vec.shape)\n",
    "\n",
    "\n",
    "test_seen_attributes = np.zeros((len(test_seen_loc), attribute_2.shape[1], attribute_2.shape[2], attribute_2.shape[3]))\n",
    "for i in range(len(test_seen_loc)):\n",
    "    test_seen_attributes[i] = attribute_2[int(labels_test_seen[i])-1]\n",
    "\n",
    "print(test_seen_attributes, test_seen_attributes.shape)# 1764, 1, 1, 1024\n",
    "\n",
    "\n",
    "\n",
    "test_seen_sig = signature_2[:, (unique_labels_test_seen)-1]\n",
    "print(\"Signature for test seen:\", test_seen_sig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33b196f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_unseen_loc = np.squeeze(att_splits['test_unseen_loc']-1)\n",
    "print(np.unique(test_unseen_loc), np.max(np.unique(test_unseen_loc))) # smallest location: 1046, largest location 35290\n",
    "\n",
    "labels_test_unseen = labels[test_unseen_loc]\n",
    "print('labels_test_unseen', labels_test_unseen, labels_test_unseen.shape)\n",
    "\n",
    "unique_labels_test_unseen = np.unique(labels_test_unseen) # labels min:7 max:50\n",
    "print('unique_labels_test_unseen', unique_labels_test_unseen, unique_labels_test_unseen.shape)# 10 classes\n",
    "\n",
    "\n",
    "test_unseen_vec = X_features[:, test_unseen_loc].transpose()\n",
    "print(\"Features for test unseen:\", test_unseen_vec.shape) #(7913, 2048)\n",
    "\n",
    "\n",
    "test_unseen_vec = np.reshape(test_unseen_vec, [test_unseen_vec.shape[0], 1, 1, test_unseen_vec.shape[1]])\n",
    "test_unseen_vec = embedding_model_0.predict(test_unseen_vec)\n",
    "print(test_unseen_vec.shape)\n",
    "\n",
    "#test_unseen_attributes = np.zeros((len(test_unseen_loc), attribute_new.shape[1]))\n",
    "#for i in range(len(test_unseen_loc)):\n",
    "#    test_unseen_attributes[i] = attribute_new[int(labels_test_unseen[i])-1]\n",
    "\n",
    "#print(test_unseen_attributes, test_unseen_attributes.shape)# (7913, 85)\n",
    "\n",
    "\n",
    "#test_unseen_attributes_2 = model0.predict(test_unseen_attributes)\n",
    "#print(test_unseen_attributes_2, test_unseen_attributes_2.shape)\n",
    "\n",
    "test_unseen_sig = signature_2[:, (unique_labels_test_unseen)-1]\n",
    "\n",
    "print(\"Signature for test unseen:\", test_unseen_sig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ef41ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "l = 0\n",
    "new_labels_test_seen = np.zeros((len(labels_test_seen), 1), dtype = 'int')\n",
    "for labels in unique_labels_test_seen:\n",
    "    new_labels_test_seen[labels_test_seen == labels] = l\n",
    "    l = l+1\n",
    "    \n",
    "print(new_labels_test_seen, new_labels_test_seen.shape)# (5882, 1)\n",
    "\n",
    "\n",
    "\n",
    "n_test_seen = new_labels_test_seen.shape[0]# 5882\n",
    "print(n_test_seen)\n",
    "\n",
    "z1_test_seen = len(unique_labels_test_seen)# 40\n",
    "print(z1_test_seen)\n",
    "\n",
    "\n",
    "m = 0\n",
    "new_labels_test_unseen = np.zeros((len(labels_test_unseen), 1), dtype = 'int')\n",
    "for labels in unique_labels_test_unseen:\n",
    "    new_labels_test_unseen[labels_test_unseen == labels] = m\n",
    "    m = m+1  \n",
    "\n",
    "print(new_labels_test_unseen, new_labels_test_unseen.shape) #  (7913, 1)  \n",
    "\n",
    "n_test_unseen = new_labels_test_unseen.shape[0]# 7913\n",
    "print(n_test_unseen)\n",
    "\n",
    "z1_test_unseen = len(unique_labels_test_unseen)# 10\n",
    "print(z1_test_unseen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f527990a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "iteration = 5\n",
    "epochs1 = 100\n",
    "epochs2 = 200\n",
    "\n",
    "best_performance_micro = [0, 0, 0]\n",
    "best_performance_macro = [0, 0, 0]\n",
    "\n",
    "save_path = 'C:/Users/Admin/Sushree_Codes/Sush_3/Results/CUB/BertAttribute/with_LE/'\n",
    "name = 'Remodel1_conv_CUB_LE_BertattT'\n",
    "    \n",
    "for i in range(iteration):\n",
    "    X_train2_it = X_train2[(len(X_train2)//iteration)*i:(len(X_train2)//iteration)*(i+1)]\n",
    "    X_val2_it = X_val2[(len(X_val2)//iteration)*i:(len(X_val2)//iteration)*(i+1)]\n",
    "    y_train2_it = y_train2[(len(y_train2)//iteration)*i:(len(y_train2)//iteration)*(i+1)]\n",
    "    y_val2_it = y_val2[(len(y_val2)//iteration)*i:(len(y_val2)//iteration)*(i+1)]\n",
    "    \n",
    "    train_gen2 = DataGenerator(X_train2_it, y_train2_it, batch_size)   \n",
    "    val_gen2 = DataGenerator(X_val2_it, y_val2_it, batch_size)\n",
    "\n",
    "    train_summary2 = model2.fit(train_gen2, epochs = epochs2, verbose = 0, callbacks = None, validation_data = val_gen2, \n",
    "                              shuffle = True, steps_per_epoch = len(train_gen2)//batch_size, \n",
    "                              validation_steps = len(val_gen2)//batch_size)\n",
    "\n",
    "    print(\"iteration:\", i)\n",
    "    print('model 2 is trained:', 'training acc:', train_summary2.history['accuracy'][-1], ',',  \n",
    "          'training loss:', train_summary2.history['loss'][-1], ',', \n",
    "          'validation acc:', train_summary2.history['val_accuracy'][-1], ',',\n",
    "          'validation_loss:', train_summary2.history['val_loss'][-1])\n",
    "\n",
    "    weights_list2 = model2.get_weights()\n",
    "    #print(weights_list2)\n",
    "\n",
    "    model1.layers[-1].set_weights(weights_list2)\n",
    "\n",
    "    X_train1_it = X_train1[(len(X_train1)//iteration)*i:(len(X_train1)//iteration)*(i+1)]\n",
    "    X_val1_it = X_val1[(len(X_val1)//iteration)*i:(len(X_val1)//iteration)*(i+1)]\n",
    "    y_train1_it = y_train1[(len(y_train1)//iteration)*i:(len(y_train1)//iteration)*(i+1)]\n",
    "    y_val1_it = y_val1[(len(y_val1)//iteration)*i:(len(y_val1)//iteration)*(i+1)]\n",
    "    \n",
    "    train_gen1 = DataGenerator(X_train1_it, y_train1_it, batch_size)   \n",
    "    val_gen1 = DataGenerator(X_val1_it, y_val1_it, batch_size)\n",
    "    \n",
    "    for layer in model1.layers[2:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    train_summary1 = model1.fit(train_gen1, epochs = epochs1, verbose = 0, callbacks = None, validation_data = val_gen1, \n",
    "                              shuffle = True, steps_per_epoch = len(train_gen1)//batch_size, \n",
    "                              validation_steps = len(val_gen1)//batch_size)\n",
    "    \n",
    "    #print(\"iteration:\", i)\n",
    "    print('model 1 is trained:', 'training acc:', train_summary1.history['accuracy'][-1], ',',  \n",
    "          'training loss:', train_summary1.history['loss'][-1], ',', \n",
    "          'validation acc:', train_summary1.history['val_accuracy'][-1], ',',\n",
    "         'validation_loss:', train_summary1.history['val_loss'][-1])\n",
    "    \n",
    "    weights_list1 = Model(inputs = model1.input, outputs = model1.layers[-1].output).get_weights()\n",
    "    \n",
    "    #predictions\n",
    "    #outputs_seen = np.matmul(np.matmul(test_seen_vec, np.matmul(weights_list1[0], weights_list1[2])), test_seen_sig)\n",
    "    #outputs_seen = np.matmul(np.matmul(test_seen_vec, weights_list1[0]), test_seen_sig)\n",
    "    \n",
    "    outputs_seen = np.matmul(np.matmul(test_seen_vec, weights_list1[0][0]), test_seen_sig)\n",
    "    preds_seen = np.array([np.argmax(output) for output in outputs_seen])\n",
    "    \n",
    "    cm_seen = confusion_matrix(new_labels_test_seen, preds_seen)\n",
    "    #print(cm)\n",
    "    # Compute macro average (averaging performance metrics by first calculating the metric separately for each class and \n",
    "    # then averaging these class-specific metrics)\n",
    "    cm_seen_micro = cm_seen.astype('float') / cm_seen.sum(axis=1)[:, np.newaxis]\n",
    "    #print(cm)\n",
    "    avg_seen_micro = (sum(cm_seen_micro.diagonal())/len(unique_labels_test_seen))*100\n",
    "\n",
    "    avg_seen_macro = (sum(cm_seen.diagonal())/len(new_labels_test_seen))*100\n",
    "    \n",
    "    #predictions\n",
    "    #outputs_unseen = np.matmul(np.matmul(test_unseen_vec, weights_list1[0]), test_unseen_sig)\n",
    "    outputs_unseen = np.matmul(np.matmul(test_unseen_vec, weights_list1[0][0]), test_unseen_sig)\n",
    "    \n",
    "    preds_unseen = np.array([np.argmax(output) for output in outputs_unseen])\n",
    "    \n",
    "    cm_unseen = confusion_matrix(new_labels_test_unseen, preds_unseen)\n",
    "    # Compute macro average (averaging performance metrics by first calculating the metric separately for each class and \n",
    "    # then averaging these class-specific metrics)\n",
    "    cm_unseen_micro = cm_unseen.astype('float') / cm_unseen.sum(axis=1)[:, np.newaxis]\n",
    "    avg_unseen_micro = (sum(cm_unseen_micro.diagonal())/len(unique_labels_test_unseen))*100\n",
    "\n",
    "    avg_unseen_macro = (sum(cm_unseen.diagonal())/len(new_labels_test_unseen))*100\n",
    "    \n",
    "    harmonic_micro = (2*avg_seen_micro*avg_unseen_micro) / (avg_seen_micro + avg_unseen_micro)\n",
    "    harmonic_macro = (2*avg_seen_macro*avg_unseen_macro) / (avg_seen_macro + avg_unseen_macro)\n",
    "    \n",
    "    print('micro average')\n",
    "    print('seen accuracy:', avg_seen_micro, 'unseen accuracy:', avg_unseen_micro, 'harmonic mean:', harmonic_micro)\n",
    "    \n",
    "    print('macro average')\n",
    "    print('seen accuracy:', avg_seen_macro, 'unseen accuracy:', avg_unseen_macro, 'harmonic mean:', harmonic_macro)\n",
    "    \n",
    "    if harmonic_micro > best_performance_micro[2]:\n",
    "        best_performance_micro = [avg_seen_micro, avg_unseen_micro, harmonic_micro]\n",
    "        model1.save_weights(save_path + 'bw_micro_' + name + '.h5', overwrite=True)\n",
    "        \n",
    "    if harmonic_macro > best_performance_macro[2]:\n",
    "        best_performance_macro = [avg_seen_macro, avg_unseen_macro, harmonic_macro]\n",
    "        model1.save_weights(save_path + 'bw_macro_' + name + '.h5', overwrite=True)\n",
    "        \n",
    "    print('best accuracy micro','seen accuracy:', best_performance_micro[0], 'unseen accuracy:', best_performance_micro[1], 'harmonic mean:', best_performance_micro[2])\n",
    "    print('best accuracy macro', 'seen accuracy:', best_performance_macro[0], 'unseen accuracy:', best_performance_macro[1], 'harmonic mean:', best_performance_macro[2])\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    weights_list3 = model1.get_weights()\n",
    "    model2.set_weights(weights_list3[2:])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "47c29ad6",
   "metadata": {},
   "source": [
    "Step 7 - Evaluate for seen and unseen categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bc47e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_test_seen = to_categorical(new_labels_test_seen, z1_test_seen)\n",
    "\n",
    "print(gt_test_seen, gt_test_seen.shape)\n",
    "\n",
    "#test_seen_vec = np.reshape(test_seen_vec, [test_seen_vec.shape[0], 1, 1, test_seen_vec.shape[1]])\n",
    "res1 = model1.evaluate(test_seen_vec, gt_test_seen)\n",
    "\n",
    "p1 = model1.predict(test_seen_vec, verbose = 0)\n",
    "\n",
    "import tensorflow\n",
    "cce = tensorflow.keras.losses.CategoricalCrossentropy()\n",
    "print('cce = ', cce(gt_test_seen, p1).numpy())\n",
    "\n",
    "#test_seen_attributes = np.reshape(train_attributes, [test_seen_attributes.shape[0], 1, train_attributes.shape[1]])\n",
    "#test_seen_attributes = np.reshape(test_seen_attributes, [test_seen_attributes.shape[0], 1, 1, test_seen_attributes.shape[1]])\n",
    "\n",
    "res2 = model2.evaluate(test_seen_attributes, gt_test_seen)\n",
    "\n",
    "p2 = model2.predict(test_seen_attributes, verbose = 0)\n",
    "\n",
    "import tensorflow\n",
    "cce = tensorflow.keras.losses.CategoricalCrossentropy()\n",
    "print('cce = ', cce(gt_test_seen, p2).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3d7cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accuracy_seen_updated = res1[1]*100\n",
    "unseen_accuracy = 44.09\n",
    "h = (2*accuracy_seen_updated*unseen_accuracy) / (accuracy_seen_updated + unseen_accuracy)\n",
    "print(h)\n",
    "\n",
    "\n",
    "accuracy_seen_updated2 = ((res1[1]*100)+(res2[1]*100))/2\n",
    "print(accuracy_seen_updated2)\n",
    "h = (2*accuracy_seen_updated2*unseen_accuracy) / (accuracy_seen_updated2 + unseen_accuracy)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb1f6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "pp1 = np.array([np.argmax(output) for output in p1])\n",
    "pp2 = np.array([np.argmax(output) for output in p2])\n",
    "\n",
    "seen_macro1 = precision_recall_fscore_support(new_labels_test_seen, pp1, average = 'macro')\n",
    "seen_macro2 = precision_recall_fscore_support(new_labels_test_seen, pp2, average = 'macro')\n",
    "print('precision_seen_macro', (seen_macro1[0] + seen_macro2[0])/2, 'recall_seen_macro', (seen_macro1[1] + seen_macro2[1])/2, 'f1_seen_macro', (seen_macro1[2] + seen_macro2[2])/2)\n",
    "\n",
    "\n",
    "seen_micro1 = precision_recall_fscore_support(new_labels_test_seen, pp1, average = 'micro')\n",
    "seen_micro2 = precision_recall_fscore_support(new_labels_test_seen, pp2, average = 'micro')\n",
    "print('precision_seen_micro', (seen_micro1[0] + seen_micro2[0])/2, 'recall_seen_micro', (seen_micro1[1] + seen_micro2[1])/2, 'f1_seen_micro', (seen_micro1[2] + seen_micro2[2])/2)\n",
    "\n",
    "unseen_macro = precision_recall_fscore_support(new_labels_test_unseen, preds_unseen, average = 'macro')\n",
    "unseen_micro = precision_recall_fscore_support(new_labels_test_unseen, preds_unseen, average = 'micro')\n",
    "\n",
    "print('precision_unseen_macro', unseen_macro[0], 'recall_unseen_macro', unseen_macro[1], 'f1_unseen_macro', unseen_macro[2])\n",
    "print('precision_unseen_micro', unseen_micro[0], 'recall_unseen_micro', unseen_micro[1], 'f1_unseen_micro', unseen_micro[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc438ad0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
