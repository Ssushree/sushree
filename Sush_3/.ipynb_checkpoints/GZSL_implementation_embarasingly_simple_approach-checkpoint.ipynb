{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f99f667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae4d8a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please add the folder name of the dataset to run it on different dataset.\n",
    "dataset = 'AWA2'\n",
    "path = 'E:/Sushree/Dataset/data/xlsa17/data/'\n",
    "\n",
    "res101 = scipy.io.loadmat(path + dataset + '/res101.mat')\n",
    "att_splits = scipy.io.loadmat(path + dataset + '/att_splits.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45865a57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " ...\n",
      " [38]\n",
      " [38]\n",
      " [38]] (37322, 1)\n",
      "[[43]\n",
      " [22]\n",
      " [43]\n",
      " ...\n",
      " [40]\n",
      " [19]\n",
      " [46]] (23527, 1)\n",
      "[[22]\n",
      " [49]\n",
      " [14]\n",
      " ...\n",
      " [25]\n",
      " [15]\n",
      " [27]] (5882, 1)\n",
      "[[30]\n",
      " [30]\n",
      " [30]\n",
      " ...\n",
      " [47]\n",
      " [47]\n",
      " [47]] (7913, 1)\n",
      "correct number of instances for training, test seen and test unseen categories\n"
     ]
    }
   ],
   "source": [
    "trainval_loc = np.squeeze(att_splits['trainval_loc']-1)\n",
    "test_seen_loc = np.squeeze(att_splits['test_seen_loc']-1)\n",
    "test_unseen_loc = np.squeeze(att_splits['test_unseen_loc']-1)\n",
    "\n",
    "labels = res101['labels']# direct class labels\n",
    "print(labels, labels.shape)\n",
    "\n",
    "labels_trainval = labels[trainval_loc]\n",
    "print(labels_trainval, labels_trainval.shape)\n",
    "\n",
    "labels_test_seen = labels[test_seen_loc]\n",
    "print(labels_test_seen, labels_test_seen.shape)\n",
    "\n",
    "labels_test_unseen = labels[test_unseen_loc]\n",
    "print(labels_test_unseen, labels_test_unseen.shape)\n",
    "\n",
    "if len(labels) == len(labels_trainval) + len(labels_test_seen) + len(labels_test_unseen):\n",
    "    print('correct number of instances for training, test seen and test unseen categories')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "05791cfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50] (50,)\n",
      "[ 1  2  3  4  5  6  8 10 11 12 13 14 15 16 17 18 19 20 21 22 25 26 27 28\n",
      " 29 32 33 35 36 37 38 39 40 42 43 44 45 46 48 49] (40,)\n",
      "[ 1  2  3  4  5  6  8 10 11 12 13 14 15 16 17 18 19 20 21 22 25 26 27 28\n",
      " 29 32 33 35 36 37 38 39 40 42 43 44 45 46 48 49] (40,)\n",
      "[ 7  9 23 24 30 31 34 41 47 50] (10,)\n",
      "Number of overlapping classes between trainval and test seen: 40\n",
      "Number of overlapping classes between trainval and test unseen: 0\n"
     ]
    }
   ],
   "source": [
    "unique_labels = np.unique(labels)\n",
    "print(unique_labels, unique_labels.shape)\n",
    "\n",
    "trainval_labels_seen = np.unique(labels_trainval)\n",
    "print(trainval_labels_seen, trainval_labels_seen.shape)\n",
    "\n",
    "test_labels_seen = np.unique(labels_test_seen)\n",
    "print(test_labels_seen, test_labels_seen.shape)\n",
    "\n",
    "test_labels_unseen = np.unique(labels_test_unseen)\n",
    "print(test_labels_unseen, test_labels_unseen.shape)\n",
    "\n",
    "print(\"Number of overlapping classes between trainval and test seen:\",len(set(trainval_labels_seen).intersection(set(test_labels_seen))))\n",
    "\n",
    "print(\"Number of overlapping classes between trainval and test unseen:\",len(set(trainval_labels_seen).intersection(set(test_labels_unseen))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2d91d6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for trainval: (23527, 2048)\n",
      "Features for test seen: (5882, 2048)\n",
      "Features for test unseen: (7913, 2048)\n"
     ]
    }
   ],
   "source": [
    "X_features = res101['features']\n",
    "\n",
    "trainval_vec = X_features[:, trainval_loc].transpose()\n",
    "test_seen_vec = X_features[:, test_seen_loc].transpose()\n",
    "test_unseen_vec = X_features[:, test_unseen_loc].transpose()\n",
    "\n",
    "print(\"Features for trainval:\", trainval_vec.shape)\n",
    "print(\"Features for test seen:\", test_seen_vec.shape)\n",
    "print(\"Features for test unseen:\", test_unseen_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3d941e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85, 50)\n",
      "[[0.00575881 0.003829   0.         ... 0.03639079 0.13208508 0.01148699]\n",
      " [0.         0.00507555 0.         ... 0.15675628 0.09070911 0.01425057]\n",
      " [0.00575881 0.003829   0.         ... 0.03639079 0.13208508 0.01148699]\n",
      " ...\n",
      " [0.         0.06587863 0.         ... 0.02108505 0.10218637 0.0332632 ]\n",
      " [0.0084177  0.01262655 0.         ... 0.02104426 0.04138142 0.02316552]\n",
      " [0.03877321 0.15834626 0.         ... 0.1760296  0.07107783 0.30279846]] (23527, 85)\n",
      "[[0.         0.00507555 0.         ... 0.15675628 0.09070911 0.01425057]\n",
      " [0.19613947 0.1966714  0.         ... 0.01787277 0.06698743 0.25883601]\n",
      " [0.01928112 0.         0.         ... 0.10161998 0.0093374  0.        ]\n",
      " ...\n",
      " [0.13407657 0.02802316 0.         ... 0.02469312 0.11832941 0.10334422]\n",
      " [0.1170179  0.05564648 0.         ... 0.09686609 0.0632034  0.01789046]\n",
      " [0.03588774 0.04482569 0.         ... 0.07673723 0.0732708  0.05016127]] (5882, 85)\n",
      "[[0.27653654 0.00419864 0.         ... 0.06032152 0.10544938 0.01679457]\n",
      " [0.27653654 0.00419864 0.         ... 0.06032152 0.10544938 0.01679457]\n",
      " [0.27653654 0.00419864 0.         ... 0.06032152 0.10544938 0.01679457]\n",
      " ...\n",
      " [0.06218048 0.01590817 0.         ... 0.03693204 0.1114562  0.06188344]\n",
      " [0.06218048 0.01590817 0.         ... 0.03693204 0.1114562  0.06188344]\n",
      " [0.06218048 0.01590817 0.         ... 0.03693204 0.1114562  0.06188344]] (7913, 85)\n"
     ]
    }
   ],
   "source": [
    "#Signature matrix\n",
    "signature = att_splits['att']\n",
    "print(signature.shape)\n",
    "\n",
    "attribute = signature.transpose()\n",
    "train_attributes = np.zeros((len(trainval_loc), 85))\n",
    "for i in range(len(trainval_loc)):\n",
    "    train_attributes[i] = attribute[int(labels_trainval[i])-1]\n",
    "\n",
    "print(train_attributes, train_attributes.shape)\n",
    "\n",
    "test_seen_attributes = np.zeros((len(test_seen_loc), 85))\n",
    "for i in range(len(test_seen_loc)):\n",
    "    test_seen_attributes[i] = attribute[int(labels_test_seen[i])-1]\n",
    "\n",
    "print(test_seen_attributes, test_seen_attributes.shape)\n",
    "\n",
    "test_unseen_attributes = np.zeros((len(test_unseen_loc), 85))\n",
    "for i in range(len(test_unseen_loc)):\n",
    "    test_unseen_attributes[i] = attribute[int(labels_test_unseen[i])-1]\n",
    "\n",
    "print(test_unseen_attributes, test_unseen_attributes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd4bc0de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  2  3  4  5  6  8 10 11 12 13 14 15 16 17 18 19 20 21 22 25 26 27 28\n",
      " 29 32 33 35 36 37 38 39 40 42 43 44 45 46 48 49] (40,)\n",
      "[ 1  2  3  4  5  6  8 10 11 12 13 14 15 16 17 18 19 20 21 22 25 26 27 28\n",
      " 29 32 33 35 36 37 38 39 40 42 43 44 45 46 48 49] (40,)\n",
      "[ 7  9 23 24 30 31 34 41 47 50] (10,)\n",
      "Number of overlapping classes between trainval and test seen: 40\n",
      "Number of overlapping classes between trainval and test unseen: 0\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5a57454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34]\n",
      " [19]\n",
      " [34]\n",
      " ...\n",
      " [32]\n",
      " [16]\n",
      " [37]] (23527, 1)\n",
      "[[19]\n",
      " [39]\n",
      " [11]\n",
      " ...\n",
      " [20]\n",
      " [12]\n",
      " [22]] (5882, 1)\n",
      "[[4]\n",
      " [4]\n",
      " [4]\n",
      " ...\n",
      " [8]\n",
      " [8]\n",
      " [8]] (7913, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "k = 0\n",
    "for labels in trainval_labels_seen:\n",
    "    labels_trainval[labels_trainval == labels] = k\n",
    "    k = k+1\n",
    "    \n",
    "print(labels_trainval, labels_trainval.shape)\n",
    "\n",
    "l = 0\n",
    "for labels in test_labels_seen:\n",
    "    labels_test_seen[labels_test_seen == labels] = l\n",
    "    l = l+1\n",
    "\n",
    "print(labels_test_seen, labels_test_seen.shape)\n",
    "\n",
    "m = 0\n",
    "for labels in test_labels_unseen:\n",
    "    labels_test_unseen[labels_test_unseen == labels] = m\n",
    "    m = m+1  \n",
    "\n",
    "print(labels_test_unseen, labels_test_unseen.shape)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea375470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] (40,)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] (40,)\n",
      "[0 1 2 3 4 5 6 7 8 9] (10,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(np.unique(labels_trainval), np.unique(labels_trainval).shape)\n",
    "\n",
    "print(np.unique(labels_test_seen), np.unique(labels_test_seen).shape)\n",
    "\n",
    "print(np.unique(labels_test_unseen), np.unique(labels_test_unseen).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "726d9ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for trainval: (23527, 2048)\n",
      "Features for test seen: (5882, 2048)\n",
      "Features for test unseen: (7913, 2048)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fd69063",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85, 50)\n",
      "Signature for trainval: (85, 40)\n",
      "Signature for test seen: (85, 40)\n",
      "Signature for test unseen: (85, 10)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "trainval_sig = signature[:, (trainval_labels_seen)-1]\n",
    "test_seen_sig = signature[:, (test_labels_seen)-1]\n",
    "test_unseen_sig = signature[:, (test_labels_unseen)-1]\n",
    "\n",
    "print(\"Signature for trainval:\", trainval_sig.shape)\n",
    "print(\"Signature for test seen:\", test_seen_sig.shape)\n",
    "print(\"Signature for test unseen:\", test_unseen_sig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "050e3253",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.00375358  0.12045618  0.26584459 ...  0.03877321  0.22516498\n",
      "   0.19613947]\n",
      " [-0.00375358  0.00426584  0.20652363 ...  0.15834626  0.15266022\n",
      "   0.1966714 ]\n",
      " [-0.00375358  0.          0.         ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.00882092  0.17996306  0.05026822 ...  0.1760296   0.12733492\n",
      "   0.01787277]\n",
      " [ 0.03640974  0.0618086   0.04274552 ...  0.07107783  0.10009694\n",
      "   0.06698743]\n",
      " [ 0.03145501  0.03495531  0.04915256 ...  0.30279846  0.01771\n",
      "   0.25883601]]\n"
     ]
    }
   ],
   "source": [
    "print(trainval_sig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb690ae3",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'signature' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m attribute \u001b[38;5;241m=\u001b[39m \u001b[43msignature\u001b[49m\u001b[38;5;241m.\u001b[39mtranspose()\n\u001b[0;32m      2\u001b[0m train_attributes \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mlen\u001b[39m(trainval_loc), \u001b[38;5;241m85\u001b[39m))\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(trainval_loc)):\n",
      "\u001b[1;31mNameError\u001b[0m: name 'signature' is not defined"
     ]
    }
   ],
   "source": [
    "attribute = signature.transpose()\n",
    "train_attributes = np.zeros((len(trainval_loc), 85))\n",
    "for i in range(len(trainval_loc)):\n",
    "    train_attributes[i] = attribute[int(labels_trainval[i])]\n",
    "\n",
    "print(train_attributes, train_attributes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "9ff1087e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21482"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainval_loc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d6d57206",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(labels_trainval[21481])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7fc57f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.25015811, 0.25015811, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.29081174, 0.10707614, 0.02262131, 0.06118637, 0.14361146,\n",
       "       0.02406272, 0.03494683, 0.11395961, 0.        , 0.        ,\n",
       "       0.22488932, 0.        , 0.        , 0.11478327, 0.06436335,\n",
       "       0.1807057 , 0.19038374, 0.        , 0.04230096, 0.01838533,\n",
       "       0.        , 0.        , 0.        , 0.02809278, 0.        ,\n",
       "       0.01226669, 0.        , 0.        , 0.22830163, 0.20841606,\n",
       "       0.00367707, 0.08780832, 0.04780185, 0.11401844, 0.        ,\n",
       "       0.26180705, 0.12504964, 0.05883305, 0.        , 0.        ,\n",
       "       0.08683758, 0.        , 0.01512009, 0.        , 0.21856476,\n",
       "       0.        , 0.0943682 , 0.23141978, 0.01226669, 0.        ,\n",
       "       0.        , 0.        , 0.01594376, 0.26745502, 0.        ,\n",
       "       0.        , 0.        , 0.12216682, 0.17329274, 0.02573946,\n",
       "       0.08557266, 0.02941652, 0.02941652, 0.        , 0.24342173,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.15664298,\n",
       "       0.06656959, 0.23709717, 0.00367707, 0.05615614, 0.02924002])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attribute[37]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5048cfd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23527\n",
      "40\n",
      "5882\n",
      "40\n",
      "7913\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#params for trainval and test set\n",
    "m_trainval = labels_trainval.shape[0]# number of instances in training set: 23527\n",
    "print(m_trainval)\n",
    "\n",
    "z_trainval = len(trainval_labels_seen)# number of classes in training set: 40\n",
    "print(z_trainval)\n",
    "\n",
    "\n",
    "n_test_seen = labels_test_seen.shape[0]# 5882\n",
    "print(n_test_seen)\n",
    "\n",
    "z1_test_seen = len(test_labels_seen)# 40\n",
    "print(z1_test_seen)\n",
    "\n",
    "\n",
    "n_test_unseen = labels_test_unseen.shape[0]# 7913\n",
    "print(n_test_unseen)\n",
    "\n",
    "z1_test_unseen = len(test_labels_unseen)# 10\n",
    "print(z1_test_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "074a4042",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]] (23527, 40)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#grountruth for trainval and test set\n",
    "gt_trainval = 0*np.ones((m_trainval, z_trainval))# 23527, 40\n",
    "gt_trainval[np.arange(m_trainval), np.squeeze(labels_trainval)] = 1\n",
    "\n",
    "print(gt_trainval, gt_trainval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9807beb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n",
      "85\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "input1_shape = trainval_vec.shape[1]\n",
    "print(input1_shape)\n",
    "\n",
    "attribute_shape = trainval_sig.shape[0]\n",
    "print(attribute_shape)\n",
    "\n",
    "output_shape = z_trainval\n",
    "print(output_shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7137414a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 2048)]            0         \n",
      "                                                                 \n",
      " intermediate (Dense)        (None, 85)                174165    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 174,165\n",
      "Trainable params: 174,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 85)]              0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 40)                3440      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,440\n",
      "Trainable params: 3,440\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from keras.optimizers import SGD, Adam, Adagrad\n",
    "\n",
    "input1 = Input(shape = input1_shape)\n",
    "inter = Dense(attribute_shape, name=\"intermediate\", activation='relu')(input1)\n",
    "\n",
    "model1 = Model(inputs = input1, outputs = inter)\n",
    "\n",
    "adam = Adam(learning_rate = 0.0001, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0001)\n",
    "model1.compile(adam, loss = 'mse', metrics = ['accuracy'])\n",
    "\n",
    "model1.summary()\n",
    "\n",
    "input2 = model1.output\n",
    "output = Dense(output_shape, name=\"output\", activation='softmax')(input2)\n",
    "\n",
    "model2 = Model(inputs = input2, outputs = output)\n",
    "\n",
    "sgd = SGD(learning_rate = 1e-2, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "model2.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0c00284f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23527, 2048)\n",
      "(23527, 85)\n",
      "(23527, 40)\n"
     ]
    }
   ],
   "source": [
    "trainval_input1 = trainval_vec\n",
    "print(trainval_input1.shape)\n",
    "\n",
    "trainval_inter = train_attributes\n",
    "print(trainval_inter.shape)\n",
    "\n",
    "trainval_output = gt_trainval\n",
    "print(trainval_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0e8325fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cf6778ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train1, X_val1, y_train1, y_val1 = train_test_split(trainval_input1, trainval_inter, test_size = 0.2, random_state = 42)\n",
    "\n",
    "\n",
    "train_gen1 = DataGenerator(X_train1, y_train1, batch_size)   \n",
    "val_gen1 = DataGenerator(X_val1, y_val1, batch_size)\n",
    "\n",
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(trainval_inter, trainval_output, test_size = 0.2, random_state = 42)\n",
    "\n",
    "\n",
    "train_gen2 = DataGenerator(X_train2, y_train2, batch_size)   \n",
    "val_gen2 = DataGenerator(X_val2, y_val2, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d3d9813a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 3.0717 - accuracy: 0.4358 - val_loss: 2.7282 - val_accuracy: 0.4722\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.3335 - accuracy: 0.5163 - val_loss: 2.2146 - val_accuracy: 0.5833\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.8218 - accuracy: 0.6344 - val_loss: 1.8502 - val_accuracy: 0.6250\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.6317 - accuracy: 0.7055 - val_loss: 1.5648 - val_accuracy: 0.7118\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.2145 - accuracy: 0.7842 - val_loss: 1.3609 - val_accuracy: 0.7500\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1787 - accuracy: 0.7808 - val_loss: 1.1759 - val_accuracy: 0.7674\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9644 - accuracy: 0.7928 - val_loss: 1.0293 - val_accuracy: 0.7674\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8149 - accuracy: 0.8211 - val_loss: 0.9099 - val_accuracy: 0.8056\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.7533 - accuracy: 0.8759 - val_loss: 0.8085 - val_accuracy: 0.9028\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.6291 - accuracy: 0.9144 - val_loss: 0.7292 - val_accuracy: 0.9028\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.9401 - val_loss: 0.6677 - val_accuracy: 0.9236\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.5197 - accuracy: 0.9426 - val_loss: 0.6109 - val_accuracy: 0.9236\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.4704 - accuracy: 0.9606 - val_loss: 0.5625 - val_accuracy: 0.9444\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.4544 - accuracy: 0.9615 - val_loss: 0.5179 - val_accuracy: 0.9444\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.4214 - accuracy: 0.9606 - val_loss: 0.4763 - val_accuracy: 0.9444\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.9589 - val_loss: 0.4406 - val_accuracy: 0.9444\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.9649 - val_loss: 0.4105 - val_accuracy: 0.9444\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.3063 - accuracy: 0.9700 - val_loss: 0.3824 - val_accuracy: 0.9444\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.3031 - accuracy: 0.9658 - val_loss: 0.3572 - val_accuracy: 0.9444\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2896 - accuracy: 0.9640 - val_loss: 0.3335 - val_accuracy: 0.9444\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2701 - accuracy: 0.9663 - val_loss: 0.3116 - val_accuracy: 0.9479\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2642 - accuracy: 0.9658 - val_loss: 0.2913 - val_accuracy: 0.9479\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2366 - accuracy: 0.9700 - val_loss: 0.2755 - val_accuracy: 0.9479\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2331 - accuracy: 0.9923 - val_loss: 0.2622 - val_accuracy: 0.9931\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2360 - accuracy: 0.9940 - val_loss: 0.2478 - val_accuracy: 0.9931\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.2165 - accuracy: 0.9957 - val_loss: 0.2381 - val_accuracy: 0.9931\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1883 - accuracy: 1.0000 - val_loss: 0.2308 - val_accuracy: 0.9931\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1999 - accuracy: 0.9966 - val_loss: 0.2237 - val_accuracy: 0.9931\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1896 - accuracy: 1.0000 - val_loss: 0.2184 - val_accuracy: 0.9931\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1974 - accuracy: 0.9949 - val_loss: 0.2140 - val_accuracy: 0.9931\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1888 - accuracy: 0.9966 - val_loss: 0.2109 - val_accuracy: 0.9931\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1906 - accuracy: 0.9897 - val_loss: 0.2079 - val_accuracy: 0.9792\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1893 - accuracy: 0.9889 - val_loss: 0.2050 - val_accuracy: 0.9792\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1724 - accuracy: 0.9931 - val_loss: 0.2025 - val_accuracy: 0.9792\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1837 - accuracy: 0.9888 - val_loss: 0.2003 - val_accuracy: 0.9792\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1908 - accuracy: 0.9854 - val_loss: 0.1980 - val_accuracy: 0.9792\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1682 - accuracy: 0.9949 - val_loss: 0.1964 - val_accuracy: 0.9792\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1870 - accuracy: 0.9863 - val_loss: 0.1947 - val_accuracy: 0.9792\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1847 - accuracy: 0.9863 - val_loss: 0.1929 - val_accuracy: 0.9792\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1744 - accuracy: 0.9897 - val_loss: 0.1912 - val_accuracy: 0.9792\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1688 - accuracy: 0.9932 - val_loss: 0.1899 - val_accuracy: 0.9792\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1609 - accuracy: 0.9966 - val_loss: 0.1888 - val_accuracy: 0.9792\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1815 - accuracy: 0.9897 - val_loss: 0.1877 - val_accuracy: 0.9792\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1627 - accuracy: 0.9940 - val_loss: 0.1865 - val_accuracy: 0.9792\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1748 - accuracy: 0.9880 - val_loss: 0.1854 - val_accuracy: 0.9792\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1699 - accuracy: 0.9914 - val_loss: 0.1843 - val_accuracy: 0.9792\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1737 - accuracy: 0.9880 - val_loss: 0.1833 - val_accuracy: 0.9792\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1616 - accuracy: 0.9932 - val_loss: 0.1824 - val_accuracy: 0.9792\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1682 - accuracy: 0.9872 - val_loss: 0.1812 - val_accuracy: 0.9792\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1593 - accuracy: 0.9914 - val_loss: 0.1802 - val_accuracy: 0.9792\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1605 - accuracy: 0.9906 - val_loss: 0.1794 - val_accuracy: 0.9792\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1664 - accuracy: 0.9854 - val_loss: 0.1785 - val_accuracy: 0.9792\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1626 - accuracy: 0.9923 - val_loss: 0.1777 - val_accuracy: 0.9792\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1629 - accuracy: 0.9897 - val_loss: 0.1769 - val_accuracy: 0.9792\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1513 - accuracy: 0.9940 - val_loss: 0.1762 - val_accuracy: 0.9792\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1671 - accuracy: 0.9888 - val_loss: 0.1753 - val_accuracy: 0.9792\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1700 - accuracy: 0.9862 - val_loss: 0.1745 - val_accuracy: 0.9792\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1640 - accuracy: 0.9897 - val_loss: 0.1735 - val_accuracy: 0.9792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1678 - accuracy: 0.9879 - val_loss: 0.1728 - val_accuracy: 0.9792\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1593 - accuracy: 0.9923 - val_loss: 0.1721 - val_accuracy: 0.9792\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1581 - accuracy: 0.9932 - val_loss: 0.1718 - val_accuracy: 0.9792\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1531 - accuracy: 0.9940 - val_loss: 0.1713 - val_accuracy: 0.9792\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1589 - accuracy: 0.9889 - val_loss: 0.1705 - val_accuracy: 0.9792\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1542 - accuracy: 0.9906 - val_loss: 0.1696 - val_accuracy: 0.9792\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1541 - accuracy: 0.9897 - val_loss: 0.1689 - val_accuracy: 0.9792\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1592 - accuracy: 0.9897 - val_loss: 0.1682 - val_accuracy: 0.9792\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1566 - accuracy: 0.9880 - val_loss: 0.1675 - val_accuracy: 0.9792\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1519 - accuracy: 0.9906 - val_loss: 0.1667 - val_accuracy: 0.9792\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1531 - accuracy: 0.9897 - val_loss: 0.1660 - val_accuracy: 0.9792\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1539 - accuracy: 0.9914 - val_loss: 0.1656 - val_accuracy: 0.9792\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1474 - accuracy: 0.9914 - val_loss: 0.1653 - val_accuracy: 0.9792\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1503 - accuracy: 0.9872 - val_loss: 0.1646 - val_accuracy: 0.9792\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1475 - accuracy: 0.9914 - val_loss: 0.1639 - val_accuracy: 0.9792\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1529 - accuracy: 0.9914 - val_loss: 0.1633 - val_accuracy: 0.9792\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1495 - accuracy: 0.9880 - val_loss: 0.1625 - val_accuracy: 0.9792\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1589 - accuracy: 0.9837 - val_loss: 0.1617 - val_accuracy: 0.9792\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1397 - accuracy: 0.9949 - val_loss: 0.1613 - val_accuracy: 0.9792\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1515 - accuracy: 0.9889 - val_loss: 0.1606 - val_accuracy: 0.9792\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1512 - accuracy: 0.9889 - val_loss: 0.1601 - val_accuracy: 0.9792\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1429 - accuracy: 0.9889 - val_loss: 0.1595 - val_accuracy: 0.9792\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1489 - accuracy: 0.9889 - val_loss: 0.1592 - val_accuracy: 0.9792\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1495 - accuracy: 0.9846 - val_loss: 0.1588 - val_accuracy: 0.9792\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1455 - accuracy: 0.9897 - val_loss: 0.1582 - val_accuracy: 0.9792\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1430 - accuracy: 0.9940 - val_loss: 0.1577 - val_accuracy: 0.9792\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1461 - accuracy: 0.9872 - val_loss: 0.1570 - val_accuracy: 0.9792\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1388 - accuracy: 0.9940 - val_loss: 0.1565 - val_accuracy: 0.9792\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1409 - accuracy: 0.9906 - val_loss: 0.1561 - val_accuracy: 0.9792\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1408 - accuracy: 0.9897 - val_loss: 0.1555 - val_accuracy: 0.9792\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1373 - accuracy: 0.9897 - val_loss: 0.1552 - val_accuracy: 0.9792\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1454 - accuracy: 0.9932 - val_loss: 0.1549 - val_accuracy: 0.9792\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1353 - accuracy: 0.9940 - val_loss: 0.1545 - val_accuracy: 0.9792\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1369 - accuracy: 0.9914 - val_loss: 0.1541 - val_accuracy: 0.9792\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1448 - accuracy: 0.9863 - val_loss: 0.1533 - val_accuracy: 0.9792\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1418 - accuracy: 0.9889 - val_loss: 0.1528 - val_accuracy: 0.9792\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1401 - accuracy: 0.9932 - val_loss: 0.1522 - val_accuracy: 0.9792\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1492 - accuracy: 0.9854 - val_loss: 0.1515 - val_accuracy: 0.9792\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1359 - accuracy: 0.9914 - val_loss: 0.1511 - val_accuracy: 0.9792\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1402 - accuracy: 0.9889 - val_loss: 0.1507 - val_accuracy: 0.9792\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1407 - accuracy: 0.9897 - val_loss: 0.1503 - val_accuracy: 0.9792\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1371 - accuracy: 0.9897 - val_loss: 0.1498 - val_accuracy: 0.9792\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1437 - accuracy: 0.9880 - val_loss: 0.1493 - val_accuracy: 0.9792\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1356 - accuracy: 0.9897 - val_loss: 0.1488 - val_accuracy: 0.9792\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1450 - accuracy: 0.9872 - val_loss: 0.1483 - val_accuracy: 0.9792\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1366 - accuracy: 0.9932 - val_loss: 0.1477 - val_accuracy: 0.9792\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1327 - accuracy: 0.9905 - val_loss: 0.1475 - val_accuracy: 0.9792\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1352 - accuracy: 0.9906 - val_loss: 0.1472 - val_accuracy: 0.9792\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1351 - accuracy: 0.9914 - val_loss: 0.1467 - val_accuracy: 0.9792\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1361 - accuracy: 0.9897 - val_loss: 0.1463 - val_accuracy: 0.9792\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9906 - val_loss: 0.1460 - val_accuracy: 0.9792\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9906 - val_loss: 0.1454 - val_accuracy: 0.9792\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1311 - accuracy: 0.9906 - val_loss: 0.1449 - val_accuracy: 0.9792\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1295 - accuracy: 0.9949 - val_loss: 0.1446 - val_accuracy: 0.9792\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1414 - accuracy: 0.9854 - val_loss: 0.1440 - val_accuracy: 0.9792\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1291 - accuracy: 0.9905 - val_loss: 0.1436 - val_accuracy: 0.9792\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1353 - accuracy: 0.9889 - val_loss: 0.1430 - val_accuracy: 0.9792\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1363 - accuracy: 0.9889 - val_loss: 0.1426 - val_accuracy: 0.9792\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1456 - accuracy: 0.9829 - val_loss: 0.1419 - val_accuracy: 0.9792\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1340 - accuracy: 0.9906 - val_loss: 0.1415 - val_accuracy: 0.9792\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.9914 - val_loss: 0.1411 - val_accuracy: 0.9792\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1296 - accuracy: 0.9889 - val_loss: 0.1405 - val_accuracy: 0.9792\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1442 - accuracy: 0.9837 - val_loss: 0.1398 - val_accuracy: 0.9792\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1314 - accuracy: 0.9863 - val_loss: 0.1393 - val_accuracy: 0.9792\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1309 - accuracy: 0.9949 - val_loss: 0.1389 - val_accuracy: 0.9931\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1302 - accuracy: 0.9940 - val_loss: 0.1384 - val_accuracy: 0.9931\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1299 - accuracy: 0.9957 - val_loss: 0.1381 - val_accuracy: 0.9931\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1187 - accuracy: 0.9991 - val_loss: 0.1378 - val_accuracy: 0.9931\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1251 - accuracy: 0.9974 - val_loss: 0.1373 - val_accuracy: 0.9931\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1305 - accuracy: 0.9949 - val_loss: 0.1369 - val_accuracy: 0.9931\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1263 - accuracy: 0.9983 - val_loss: 0.1366 - val_accuracy: 0.9931\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1255 - accuracy: 0.9966 - val_loss: 0.1362 - val_accuracy: 0.9931\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1249 - accuracy: 0.9974 - val_loss: 0.1359 - val_accuracy: 0.9792\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1279 - accuracy: 0.9880 - val_loss: 0.1354 - val_accuracy: 0.9792\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1262 - accuracy: 0.9914 - val_loss: 0.1350 - val_accuracy: 0.9931\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.1328 - accuracy: 0.9940 - val_loss: 0.1346 - val_accuracy: 0.9931\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1378 - accuracy: 0.9863 - val_loss: 0.1339 - val_accuracy: 0.9931\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 0.9949 - val_loss: 0.1336 - val_accuracy: 0.9931\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1245 - accuracy: 0.9966 - val_loss: 0.1331 - val_accuracy: 0.9931\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1239 - accuracy: 0.9940 - val_loss: 0.1328 - val_accuracy: 0.9792\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1204 - accuracy: 0.9922 - val_loss: 0.1326 - val_accuracy: 0.9792\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.1311 - accuracy: 0.9846 - val_loss: 0.1321 - val_accuracy: 0.9792\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.1219 - accuracy: 0.9914 - val_loss: 0.1318 - val_accuracy: 0.9792\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.1167 - accuracy: 0.9932 - val_loss: 0.1316 - val_accuracy: 0.9792\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1221 - accuracy: 0.9897 - val_loss: 0.1312 - val_accuracy: 0.9792\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1216 - accuracy: 0.9923 - val_loss: 0.1310 - val_accuracy: 0.9792\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.9914 - val_loss: 0.1308 - val_accuracy: 0.9792\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1247 - accuracy: 0.9897 - val_loss: 0.1305 - val_accuracy: 0.9792\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1240 - accuracy: 0.9897 - val_loss: 0.1302 - val_accuracy: 0.9792\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1225 - accuracy: 0.9906 - val_loss: 0.1299 - val_accuracy: 0.9792\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1218 - accuracy: 0.9914 - val_loss: 0.1296 - val_accuracy: 0.9792\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1210 - accuracy: 0.9897 - val_loss: 0.1293 - val_accuracy: 0.9792\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1269 - accuracy: 0.9889 - val_loss: 0.1291 - val_accuracy: 0.9792\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1048 - accuracy: 0.9974 - val_loss: 0.1289 - val_accuracy: 0.9792\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1161 - accuracy: 0.9889 - val_loss: 0.1285 - val_accuracy: 0.9792\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.9880 - val_loss: 0.1282 - val_accuracy: 0.9792\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1202 - accuracy: 0.9889 - val_loss: 0.1278 - val_accuracy: 0.9792\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1108 - accuracy: 0.9966 - val_loss: 0.1276 - val_accuracy: 0.9792\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1238 - accuracy: 0.9837 - val_loss: 0.1270 - val_accuracy: 0.9792\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.9897 - val_loss: 0.1267 - val_accuracy: 0.9931\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1235 - accuracy: 0.9949 - val_loss: 0.1262 - val_accuracy: 0.9931\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1171 - accuracy: 0.9940 - val_loss: 0.1260 - val_accuracy: 0.9792\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1152 - accuracy: 0.9932 - val_loss: 0.1258 - val_accuracy: 0.9792\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1214 - accuracy: 0.9906 - val_loss: 0.1257 - val_accuracy: 0.9792\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1180 - accuracy: 0.9889 - val_loss: 0.1252 - val_accuracy: 0.9792\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1168 - accuracy: 0.9889 - val_loss: 0.1246 - val_accuracy: 0.9931\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1132 - accuracy: 0.9966 - val_loss: 0.1242 - val_accuracy: 0.9931\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1162 - accuracy: 0.9966 - val_loss: 0.1240 - val_accuracy: 0.9931\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1135 - accuracy: 0.9966 - val_loss: 0.1237 - val_accuracy: 0.9931\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.9966 - val_loss: 0.1234 - val_accuracy: 0.9931\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1138 - accuracy: 0.9966 - val_loss: 0.1231 - val_accuracy: 0.9931\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1173 - accuracy: 0.9957 - val_loss: 0.1228 - val_accuracy: 0.9931\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1053 - accuracy: 0.9991 - val_loss: 0.1227 - val_accuracy: 0.9931\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1119 - accuracy: 0.9966 - val_loss: 0.1225 - val_accuracy: 0.9931\n",
      "Epoch 173/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1122 - accuracy: 0.9974 - val_loss: 0.1220 - val_accuracy: 0.9931\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1069 - accuracy: 0.9983 - val_loss: 0.1218 - val_accuracy: 0.9931\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1074 - accuracy: 0.9974 - val_loss: 0.1215 - val_accuracy: 0.9931\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1107 - accuracy: 0.9983 - val_loss: 0.1214 - val_accuracy: 0.9931\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1109 - accuracy: 0.9983 - val_loss: 0.1212 - val_accuracy: 0.9931\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1148 - accuracy: 0.9957 - val_loss: 0.1208 - val_accuracy: 0.9931\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1102 - accuracy: 0.9991 - val_loss: 0.1204 - val_accuracy: 0.9931\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1092 - accuracy: 0.9991 - val_loss: 0.1203 - val_accuracy: 0.9931\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1060 - accuracy: 0.9983 - val_loss: 0.1201 - val_accuracy: 0.9931\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1085 - accuracy: 0.9965 - val_loss: 0.1198 - val_accuracy: 0.9931\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1062 - accuracy: 0.9983 - val_loss: 0.1197 - val_accuracy: 0.9931\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1089 - accuracy: 0.9974 - val_loss: 0.1195 - val_accuracy: 0.9931\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1095 - accuracy: 0.9974 - val_loss: 0.1191 - val_accuracy: 0.9931\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1068 - accuracy: 0.9974 - val_loss: 0.1188 - val_accuracy: 0.9931\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1104 - accuracy: 0.9957 - val_loss: 0.1184 - val_accuracy: 0.9931\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1013 - accuracy: 0.9974 - val_loss: 0.1183 - val_accuracy: 0.9931\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1075 - accuracy: 0.9974 - val_loss: 0.1181 - val_accuracy: 0.9931\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1043 - accuracy: 0.9974 - val_loss: 0.1178 - val_accuracy: 0.9931\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1036 - accuracy: 0.9983 - val_loss: 0.1176 - val_accuracy: 0.9931\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1128 - accuracy: 0.9957 - val_loss: 0.1171 - val_accuracy: 0.9931\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1053 - accuracy: 0.9974 - val_loss: 0.1169 - val_accuracy: 0.9931\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1053 - accuracy: 0.9974 - val_loss: 0.1167 - val_accuracy: 0.9931\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1071 - accuracy: 0.9974 - val_loss: 0.1164 - val_accuracy: 0.9931\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1053 - accuracy: 0.9966 - val_loss: 0.1161 - val_accuracy: 0.9931\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1091 - accuracy: 0.9957 - val_loss: 0.1157 - val_accuracy: 0.9931\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1054 - accuracy: 0.9966 - val_loss: 0.1154 - val_accuracy: 0.9931\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1062 - accuracy: 0.9966 - val_loss: 0.1152 - val_accuracy: 0.9931\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1032 - accuracy: 0.9983 - val_loss: 0.1149 - val_accuracy: 0.9931\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1046 - accuracy: 0.9983 - val_loss: 0.1147 - val_accuracy: 0.9931\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1082 - accuracy: 0.9940 - val_loss: 0.1144 - val_accuracy: 0.9931\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1022 - accuracy: 0.9974 - val_loss: 0.1140 - val_accuracy: 0.9931\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1030 - accuracy: 0.9957 - val_loss: 0.1137 - val_accuracy: 0.9931\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1021 - accuracy: 0.9957 - val_loss: 0.1134 - val_accuracy: 0.9931\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1064 - accuracy: 0.9974 - val_loss: 0.1132 - val_accuracy: 0.9931\n",
      "Epoch 207/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1006 - accuracy: 0.9974 - val_loss: 0.1131 - val_accuracy: 0.9931\n",
      "Epoch 208/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1015 - accuracy: 0.9983 - val_loss: 0.1128 - val_accuracy: 0.9931\n",
      "Epoch 209/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1055 - accuracy: 0.9974 - val_loss: 0.1126 - val_accuracy: 0.9931\n",
      "Epoch 210/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1000 - accuracy: 0.9974 - val_loss: 0.1124 - val_accuracy: 0.9931\n",
      "Epoch 211/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1042 - accuracy: 0.9949 - val_loss: 0.1121 - val_accuracy: 0.9931\n",
      "Epoch 212/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1047 - accuracy: 0.9966 - val_loss: 0.1117 - val_accuracy: 0.9931\n",
      "Epoch 213/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1026 - accuracy: 0.9983 - val_loss: 0.1116 - val_accuracy: 0.9931\n",
      "Epoch 214/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1007 - accuracy: 0.9974 - val_loss: 0.1114 - val_accuracy: 0.9931\n",
      "Epoch 215/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1041 - accuracy: 0.9966 - val_loss: 0.1111 - val_accuracy: 0.9931\n",
      "Epoch 216/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0991 - accuracy: 0.9983 - val_loss: 0.1108 - val_accuracy: 0.9931\n",
      "Epoch 217/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1057 - accuracy: 0.9949 - val_loss: 0.1106 - val_accuracy: 0.9931\n",
      "Epoch 218/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1000 - accuracy: 0.9983 - val_loss: 0.1105 - val_accuracy: 0.9931\n",
      "Epoch 219/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.9966 - val_loss: 0.1101 - val_accuracy: 0.9931\n",
      "Epoch 220/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1050 - accuracy: 0.9983 - val_loss: 0.1098 - val_accuracy: 0.9931\n",
      "Epoch 221/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1023 - accuracy: 0.9974 - val_loss: 0.1095 - val_accuracy: 0.9931\n",
      "Epoch 222/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0967 - accuracy: 0.9974 - val_loss: 0.1094 - val_accuracy: 0.9931\n",
      "Epoch 223/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1051 - accuracy: 0.9949 - val_loss: 0.1090 - val_accuracy: 0.9931\n",
      "Epoch 224/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1032 - accuracy: 0.9957 - val_loss: 0.1088 - val_accuracy: 0.9931\n",
      "Epoch 225/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0991 - accuracy: 0.9974 - val_loss: 0.1085 - val_accuracy: 0.9931\n",
      "Epoch 226/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0985 - accuracy: 0.9983 - val_loss: 0.1083 - val_accuracy: 0.9931\n",
      "Epoch 227/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0971 - accuracy: 0.9974 - val_loss: 0.1082 - val_accuracy: 0.9931\n",
      "Epoch 228/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0988 - accuracy: 0.9966 - val_loss: 0.1079 - val_accuracy: 0.9931\n",
      "Epoch 229/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0962 - accuracy: 0.9983 - val_loss: 0.1076 - val_accuracy: 0.9931\n",
      "Epoch 230/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0995 - accuracy: 0.9966 - val_loss: 0.1073 - val_accuracy: 0.9931\n",
      "Epoch 231/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0975 - accuracy: 0.9974 - val_loss: 0.1071 - val_accuracy: 0.9931\n",
      "Epoch 232/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0967 - accuracy: 0.9974 - val_loss: 0.1069 - val_accuracy: 0.9931\n",
      "Epoch 233/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0999 - accuracy: 0.9957 - val_loss: 0.1067 - val_accuracy: 0.9931\n",
      "Epoch 234/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0944 - accuracy: 0.9983 - val_loss: 0.1065 - val_accuracy: 0.9931\n",
      "Epoch 235/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.9974 - val_loss: 0.1063 - val_accuracy: 0.9931\n",
      "Epoch 236/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0934 - accuracy: 0.9974 - val_loss: 0.1061 - val_accuracy: 0.9931\n",
      "Epoch 237/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1027 - accuracy: 0.9949 - val_loss: 0.1058 - val_accuracy: 0.9931\n",
      "Epoch 238/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0928 - accuracy: 0.9974 - val_loss: 0.1056 - val_accuracy: 0.9931\n",
      "Epoch 239/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.1021 - accuracy: 0.9940 - val_loss: 0.1052 - val_accuracy: 0.9931\n",
      "Epoch 240/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0957 - accuracy: 0.9974 - val_loss: 0.1050 - val_accuracy: 0.9931\n",
      "Epoch 241/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0946 - accuracy: 0.9957 - val_loss: 0.1048 - val_accuracy: 0.9931\n",
      "Epoch 242/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0923 - accuracy: 0.9974 - val_loss: 0.1046 - val_accuracy: 0.9931\n",
      "Epoch 243/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0915 - accuracy: 0.9974 - val_loss: 0.1044 - val_accuracy: 0.9931\n",
      "Epoch 244/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.9957 - val_loss: 0.1042 - val_accuracy: 0.9931\n",
      "Epoch 245/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0948 - accuracy: 0.9957 - val_loss: 0.1042 - val_accuracy: 0.9931\n",
      "Epoch 246/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0903 - accuracy: 0.9991 - val_loss: 0.1039 - val_accuracy: 0.9931\n",
      "Epoch 247/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0943 - accuracy: 0.9957 - val_loss: 0.1038 - val_accuracy: 0.9931\n",
      "Epoch 248/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0937 - accuracy: 0.9957 - val_loss: 0.1036 - val_accuracy: 0.9931\n",
      "Epoch 249/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.9983 - val_loss: 0.1035 - val_accuracy: 0.9931\n",
      "Epoch 250/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0933 - accuracy: 0.9966 - val_loss: 0.1033 - val_accuracy: 0.9931\n",
      "Epoch 251/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0926 - accuracy: 0.9966 - val_loss: 0.1031 - val_accuracy: 0.9931\n",
      "Epoch 252/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0940 - accuracy: 0.9957 - val_loss: 0.1028 - val_accuracy: 0.9931\n",
      "Epoch 253/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0958 - accuracy: 0.9957 - val_loss: 0.1026 - val_accuracy: 0.9931\n",
      "Epoch 254/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0978 - accuracy: 0.9957 - val_loss: 0.1021 - val_accuracy: 0.9931\n",
      "Epoch 255/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0972 - accuracy: 0.9949 - val_loss: 0.1018 - val_accuracy: 0.9931\n",
      "Epoch 256/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0912 - accuracy: 0.9974 - val_loss: 0.1015 - val_accuracy: 0.9931\n",
      "Epoch 257/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0912 - accuracy: 0.9974 - val_loss: 0.1013 - val_accuracy: 0.9931\n",
      "Epoch 258/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0918 - accuracy: 0.9966 - val_loss: 0.1011 - val_accuracy: 0.9931\n",
      "Epoch 259/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0930 - accuracy: 0.9949 - val_loss: 0.1008 - val_accuracy: 0.9931\n",
      "Epoch 260/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0975 - accuracy: 0.9949 - val_loss: 0.1006 - val_accuracy: 0.9931\n",
      "Epoch 261/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0960 - accuracy: 0.9966 - val_loss: 0.1003 - val_accuracy: 0.9931\n",
      "Epoch 262/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 0.9974 - val_loss: 0.1000 - val_accuracy: 0.9931\n",
      "Epoch 263/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0935 - accuracy: 0.9957 - val_loss: 0.0998 - val_accuracy: 0.9931\n",
      "Epoch 264/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0892 - accuracy: 0.9983 - val_loss: 0.0996 - val_accuracy: 0.9931\n",
      "Epoch 265/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0891 - accuracy: 0.9965 - val_loss: 0.0994 - val_accuracy: 0.9931\n",
      "Epoch 266/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0882 - accuracy: 0.9991 - val_loss: 0.0994 - val_accuracy: 0.9931\n",
      "Epoch 267/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0925 - accuracy: 0.9966 - val_loss: 0.0992 - val_accuracy: 0.9931\n",
      "Epoch 268/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0897 - accuracy: 0.9966 - val_loss: 0.0991 - val_accuracy: 0.9931\n",
      "Epoch 269/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0926 - accuracy: 0.9966 - val_loss: 0.0988 - val_accuracy: 0.9931\n",
      "Epoch 270/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0904 - accuracy: 0.9966 - val_loss: 0.0986 - val_accuracy: 0.9931\n",
      "Epoch 271/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0882 - accuracy: 0.9983 - val_loss: 0.0985 - val_accuracy: 0.9931\n",
      "Epoch 272/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0939 - accuracy: 0.9957 - val_loss: 0.0982 - val_accuracy: 0.9931\n",
      "Epoch 273/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0940 - accuracy: 0.9957 - val_loss: 0.0979 - val_accuracy: 0.9931\n",
      "Epoch 274/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0876 - accuracy: 0.9974 - val_loss: 0.0977 - val_accuracy: 0.9931\n",
      "Epoch 275/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0873 - accuracy: 0.9974 - val_loss: 0.0975 - val_accuracy: 0.9931\n",
      "Epoch 276/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0884 - accuracy: 0.9966 - val_loss: 0.0974 - val_accuracy: 0.9931\n",
      "Epoch 277/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0904 - accuracy: 0.9966 - val_loss: 0.0971 - val_accuracy: 0.9931\n",
      "Epoch 278/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0850 - accuracy: 0.9974 - val_loss: 0.0969 - val_accuracy: 0.9931\n",
      "Epoch 279/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.9974 - val_loss: 0.0968 - val_accuracy: 0.9931\n",
      "Epoch 280/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0900 - accuracy: 0.9974 - val_loss: 0.0967 - val_accuracy: 0.9931\n",
      "Epoch 281/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0884 - accuracy: 0.9974 - val_loss: 0.0966 - val_accuracy: 0.9931\n",
      "Epoch 282/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0896 - accuracy: 0.9966 - val_loss: 0.0964 - val_accuracy: 0.9931\n",
      "Epoch 283/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0905 - accuracy: 0.9974 - val_loss: 0.0963 - val_accuracy: 0.9931\n",
      "Epoch 284/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0959 - accuracy: 0.9940 - val_loss: 0.0959 - val_accuracy: 0.9931\n",
      "Epoch 285/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0851 - accuracy: 0.9966 - val_loss: 0.0957 - val_accuracy: 0.9931\n",
      "Epoch 286/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0831 - accuracy: 0.9983 - val_loss: 0.0956 - val_accuracy: 0.9931\n",
      "Epoch 287/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0921 - accuracy: 0.9923 - val_loss: 0.0953 - val_accuracy: 0.9931\n",
      "Epoch 288/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0882 - accuracy: 0.9966 - val_loss: 0.0951 - val_accuracy: 0.9931\n",
      "Epoch 289/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.9974 - val_loss: 0.0949 - val_accuracy: 0.9931\n",
      "Epoch 290/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0884 - accuracy: 0.9957 - val_loss: 0.0947 - val_accuracy: 0.9931\n",
      "Epoch 291/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0820 - accuracy: 0.9991 - val_loss: 0.0946 - val_accuracy: 0.9931\n",
      "Epoch 292/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0915 - accuracy: 0.9940 - val_loss: 0.0942 - val_accuracy: 0.9931\n",
      "Epoch 293/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0825 - accuracy: 0.9991 - val_loss: 0.0942 - val_accuracy: 0.9931\n",
      "Epoch 294/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0845 - accuracy: 0.9983 - val_loss: 0.0941 - val_accuracy: 0.9931\n",
      "Epoch 295/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 1.0000 - val_loss: 0.0941 - val_accuracy: 0.9931\n",
      "Epoch 296/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0875 - accuracy: 0.9966 - val_loss: 0.0939 - val_accuracy: 0.9931\n",
      "Epoch 297/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0919 - accuracy: 0.9922 - val_loss: 0.0935 - val_accuracy: 0.9931\n",
      "Epoch 298/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 0.9949 - val_loss: 0.0932 - val_accuracy: 0.9931\n",
      "Epoch 299/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0855 - accuracy: 0.9974 - val_loss: 0.0930 - val_accuracy: 0.9931\n",
      "Epoch 300/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.9966 - val_loss: 0.0929 - val_accuracy: 0.9931\n"
     ]
    }
   ],
   "source": [
    "train_summary = model2.fit(train_gen2, epochs = 300, verbose = 1, callbacks = None, validation_data = val_gen2, \n",
    "                              shuffle = True, steps_per_epoch = len(train_gen2)//batch_size, \n",
    "                              validation_steps = len(val_gen2)//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a0c4da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = 'C:/Users/Admin/Sushree_Codes/Sush_3/'\n",
    "model2.save_weights(save_path + 'Wt_model2' + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c075e5ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 2048)]            0         \n",
      "                                                                 \n",
      " intermediate (Dense)        (None, 85)                174165    \n",
      "                                                                 \n",
      " output (Dense)              (None, 40)                3440      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,605\n",
      "Trainable params: 177,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input3 = Input(shape = input1_shape)\n",
    "inter = Dense(attribute_shape, name=\"intermediate\", activation='relu')(input3)\n",
    "output = Dense(output_shape, name=\"output\", activation='softmax')(inter)\n",
    "\n",
    "model3 = Model(inputs = input3, outputs = output)\n",
    "\n",
    "sgd = SGD(learning_rate = 1e-2, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "model3.compile(optimizer = sgd, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "47976d1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[-3.4564517 , -0.17492539,  2.1705472 , ...,  3.0319984 ,\n",
      "         2.2827573 , -3.67224   ],\n",
      "       [-3.3251076 , -1.2743205 ,  2.4047508 , ...,  2.9714718 ,\n",
      "         2.2566836 , -0.18638717],\n",
      "       [-0.34292933, -0.04266982, -1.0343393 , ..., -0.19991793,\n",
      "        -0.28823745, -0.3012657 ],\n",
      "       ...,\n",
      "       [-1.6799802 ,  1.9725007 , -0.46724603, ..., -1.3348672 ,\n",
      "         1.8250695 , -1.6302878 ],\n",
      "       [-0.45967197,  1.3369285 , -1.250105  , ..., -0.08949838,\n",
      "        -0.74216974,  1.5056039 ],\n",
      "       [-0.9486043 , -0.5829431 , -0.31829196, ..., -1.586378  ,\n",
      "         0.00606878, -1.8187298 ]], dtype=float32), array([ 3.0456557 , -0.6572741 ,  1.4842889 ,  0.36507162,  2.506289  ,\n",
      "       -0.64306617,  1.4028404 ,  0.7003959 ,  0.9181239 , -0.08180781,\n",
      "       -0.10943434, -2.884452  ,  0.5799886 ,  1.6129472 ,  0.47310877,\n",
      "        1.7963727 , -1.0500752 , -4.8039393 ,  0.5915175 ,  0.7056291 ,\n",
      "       -2.007241  , -3.0374057 , -3.3440409 , -0.07155439, -0.9027668 ,\n",
      "        1.5351851 ,  0.9080587 ,  0.51578027, -1.8054702 , -2.4219532 ,\n",
      "       -0.6267959 , -1.2234375 ,  3.2680566 , -0.6408101 ,  2.403719  ,\n",
      "       -0.63872653, -0.01906267,  1.3802243 , -0.4452569 ,  1.2212461 ],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "weights_list = model2.get_weights()\n",
    "print(weights_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "71147953",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.layers[-1].set_weights(weights_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "57e753e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3.layers[-1].trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7fde6d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 2048)]            0         \n",
      "                                                                 \n",
      " intermediate (Dense)        (None, 85)                174165    \n",
      "                                                                 \n",
      " output (Dense)              (None, 40)                3440      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 177,605\n",
      "Trainable params: 177,605\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "47fd3707",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(trainval_input1, trainval_output, test_size = 0.2, random_state = 42)\n",
    "\n",
    "\n",
    "train_gen2 = DataGenerator(X_train2, y_train2, batch_size)   \n",
    "val_gen2 = DataGenerator(X_val2, y_val2, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6b588a46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 2.5755 - accuracy: 0.4101 - val_loss: 2.3221 - val_accuracy: 0.4618\n",
      "Epoch 2/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.8240 - accuracy: 0.5094 - val_loss: 1.7173 - val_accuracy: 0.5868\n",
      "Epoch 3/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2713 - accuracy: 0.6396 - val_loss: 1.5787 - val_accuracy: 0.5868\n",
      "Epoch 4/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.3391 - accuracy: 0.6353 - val_loss: 1.6213 - val_accuracy: 0.6250\n",
      "Epoch 5/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.3552 - accuracy: 0.6490 - val_loss: 1.4749 - val_accuracy: 0.5729\n",
      "Epoch 6/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2422 - accuracy: 0.6729 - val_loss: 1.5893 - val_accuracy: 0.5764\n",
      "Epoch 7/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2020 - accuracy: 0.6370 - val_loss: 1.5309 - val_accuracy: 0.5625\n",
      "Epoch 8/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2806 - accuracy: 0.6293 - val_loss: 1.5018 - val_accuracy: 0.5903\n",
      "Epoch 9/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2112 - accuracy: 0.6259 - val_loss: 1.4683 - val_accuracy: 0.6007\n",
      "Epoch 10/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0787 - accuracy: 0.6610 - val_loss: 1.4305 - val_accuracy: 0.6007\n",
      "Epoch 11/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1090 - accuracy: 0.6670 - val_loss: 1.5446 - val_accuracy: 0.5938\n",
      "Epoch 12/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1221 - accuracy: 0.6661 - val_loss: 1.6597 - val_accuracy: 0.6250\n",
      "Epoch 13/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1735 - accuracy: 0.6618 - val_loss: 2.3922 - val_accuracy: 0.5694\n",
      "Epoch 14/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0941 - accuracy: 0.6755 - val_loss: 1.4355 - val_accuracy: 0.6493\n",
      "Epoch 15/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1554 - accuracy: 0.6396 - val_loss: 1.8885 - val_accuracy: 0.6007\n",
      "Epoch 16/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0986 - accuracy: 0.6481 - val_loss: 1.3274 - val_accuracy: 0.6111\n",
      "Epoch 17/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0481 - accuracy: 0.6798 - val_loss: 1.4160 - val_accuracy: 0.5972\n",
      "Epoch 18/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1784 - accuracy: 0.6575 - val_loss: 1.7645 - val_accuracy: 0.6215\n",
      "Epoch 19/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0529 - accuracy: 0.6644 - val_loss: 1.5132 - val_accuracy: 0.6250\n",
      "Epoch 20/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1609 - accuracy: 0.6507 - val_loss: 1.5012 - val_accuracy: 0.6111\n",
      "Epoch 21/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0965 - accuracy: 0.6776 - val_loss: 1.7609 - val_accuracy: 0.6146\n",
      "Epoch 22/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0751 - accuracy: 0.6875 - val_loss: 1.6221 - val_accuracy: 0.6181\n",
      "Epoch 23/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1519 - accuracy: 0.6558 - val_loss: 1.4469 - val_accuracy: 0.6285\n",
      "Epoch 24/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1846 - accuracy: 0.6567 - val_loss: 1.4407 - val_accuracy: 0.6319\n",
      "Epoch 25/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1148 - accuracy: 0.6490 - val_loss: 1.6154 - val_accuracy: 0.5903\n",
      "Epoch 26/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1635 - accuracy: 0.6618 - val_loss: 1.5989 - val_accuracy: 0.5660\n",
      "Epoch 27/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1598 - accuracy: 0.6618 - val_loss: 1.4345 - val_accuracy: 0.6215\n",
      "Epoch 28/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0258 - accuracy: 0.6550 - val_loss: 1.3763 - val_accuracy: 0.6354\n",
      "Epoch 29/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1990 - accuracy: 0.6618 - val_loss: 1.5122 - val_accuracy: 0.6215\n",
      "Epoch 30/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1409 - accuracy: 0.6652 - val_loss: 1.5702 - val_accuracy: 0.6285\n",
      "Epoch 31/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.2368 - accuracy: 0.6378 - val_loss: 1.3715 - val_accuracy: 0.6146\n",
      "Epoch 32/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0706 - accuracy: 0.6943 - val_loss: 1.4198 - val_accuracy: 0.6181\n",
      "Epoch 33/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2032 - accuracy: 0.6276 - val_loss: 1.5508 - val_accuracy: 0.6319\n",
      "Epoch 34/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0905 - accuracy: 0.6798 - val_loss: 1.3919 - val_accuracy: 0.6528\n",
      "Epoch 35/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.2179 - accuracy: 0.6525 - val_loss: 1.4071 - val_accuracy: 0.6389\n",
      "Epoch 36/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1023 - accuracy: 0.6772 - val_loss: 1.6134 - val_accuracy: 0.5972\n",
      "Epoch 37/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0034 - accuracy: 0.6926 - val_loss: 1.4698 - val_accuracy: 0.6354\n",
      "Epoch 38/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9696 - accuracy: 0.6884 - val_loss: 1.4998 - val_accuracy: 0.6354\n",
      "Epoch 39/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0346 - accuracy: 0.6815 - val_loss: 1.3941 - val_accuracy: 0.6250\n",
      "Epoch 40/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0245 - accuracy: 0.6943 - val_loss: 1.4722 - val_accuracy: 0.6076\n",
      "Epoch 41/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9844 - accuracy: 0.6926 - val_loss: 1.3898 - val_accuracy: 0.6493\n",
      "Epoch 42/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0037 - accuracy: 0.6764 - val_loss: 1.5341 - val_accuracy: 0.6146\n",
      "Epoch 43/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1139 - accuracy: 0.6729 - val_loss: 1.5504 - val_accuracy: 0.6042\n",
      "Epoch 44/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9773 - accuracy: 0.6961 - val_loss: 1.5631 - val_accuracy: 0.6215\n",
      "Epoch 45/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1640 - accuracy: 0.6789 - val_loss: 1.6697 - val_accuracy: 0.5938\n",
      "Epoch 46/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.2081 - accuracy: 0.6481 - val_loss: 1.4030 - val_accuracy: 0.6632\n",
      "Epoch 47/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0752 - accuracy: 0.6789 - val_loss: 1.4891 - val_accuracy: 0.6181\n",
      "Epoch 48/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1527 - accuracy: 0.6858 - val_loss: 1.5939 - val_accuracy: 0.6285\n",
      "Epoch 49/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2724 - accuracy: 0.6421 - val_loss: 1.3363 - val_accuracy: 0.6597\n",
      "Epoch 50/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1435 - accuracy: 0.6592 - val_loss: 1.4153 - val_accuracy: 0.6076\n",
      "Epoch 51/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2424 - accuracy: 0.6644 - val_loss: 1.5588 - val_accuracy: 0.6215\n",
      "Epoch 52/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1940 - accuracy: 0.6670 - val_loss: 1.6480 - val_accuracy: 0.5729\n",
      "Epoch 53/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1288 - accuracy: 0.6866 - val_loss: 1.5794 - val_accuracy: 0.6250\n",
      "Epoch 54/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1960 - accuracy: 0.6592 - val_loss: 1.3388 - val_accuracy: 0.6285\n",
      "Epoch 55/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1202 - accuracy: 0.6464 - val_loss: 1.3454 - val_accuracy: 0.6597\n",
      "Epoch 56/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1912 - accuracy: 0.6550 - val_loss: 1.5711 - val_accuracy: 0.6146\n",
      "Epoch 57/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2148 - accuracy: 0.6610 - val_loss: 1.4001 - val_accuracy: 0.6285\n",
      "Epoch 58/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1580 - accuracy: 0.6635 - val_loss: 1.3096 - val_accuracy: 0.6632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9629 - accuracy: 0.6687 - val_loss: 1.4143 - val_accuracy: 0.6493\n",
      "Epoch 60/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1392 - accuracy: 0.6698 - val_loss: 1.7580 - val_accuracy: 0.5938\n",
      "Epoch 61/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0459 - accuracy: 0.6926 - val_loss: 1.5819 - val_accuracy: 0.6215\n",
      "Epoch 62/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1131 - accuracy: 0.6764 - val_loss: 1.4179 - val_accuracy: 0.6562\n",
      "Epoch 63/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1138 - accuracy: 0.6845 - val_loss: 1.3131 - val_accuracy: 0.6597\n",
      "Epoch 64/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0576 - accuracy: 0.6729 - val_loss: 1.6079 - val_accuracy: 0.6042\n",
      "Epoch 65/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1943 - accuracy: 0.6404 - val_loss: 1.4877 - val_accuracy: 0.6007\n",
      "Epoch 66/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2903 - accuracy: 0.6113 - val_loss: 1.4351 - val_accuracy: 0.6181\n",
      "Epoch 67/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9835 - accuracy: 0.6618 - val_loss: 1.2580 - val_accuracy: 0.6215\n",
      "Epoch 68/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1918 - accuracy: 0.6712 - val_loss: 1.2202 - val_accuracy: 0.6354\n",
      "Epoch 69/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1032 - accuracy: 0.6515 - val_loss: 1.4080 - val_accuracy: 0.6146\n",
      "Epoch 70/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9861 - accuracy: 0.6789 - val_loss: 1.4654 - val_accuracy: 0.6354\n",
      "Epoch 71/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0208 - accuracy: 0.6897 - val_loss: 1.3574 - val_accuracy: 0.6215\n",
      "Epoch 72/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0578 - accuracy: 0.6755 - val_loss: 1.2620 - val_accuracy: 0.6389\n",
      "Epoch 73/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0312 - accuracy: 0.6652 - val_loss: 1.1965 - val_accuracy: 0.6285\n",
      "Epoch 74/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2001 - accuracy: 0.6678 - val_loss: 1.2949 - val_accuracy: 0.6250\n",
      "Epoch 75/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1784 - accuracy: 0.6670 - val_loss: 1.6261 - val_accuracy: 0.6076\n",
      "Epoch 76/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0125 - accuracy: 0.6918 - val_loss: 1.7483 - val_accuracy: 0.6007\n",
      "Epoch 77/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0993 - accuracy: 0.6789 - val_loss: 1.4197 - val_accuracy: 0.6181\n",
      "Epoch 78/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1390 - accuracy: 0.6652 - val_loss: 1.6177 - val_accuracy: 0.5938\n",
      "Epoch 79/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0189 - accuracy: 0.6866 - val_loss: 1.3389 - val_accuracy: 0.6354\n",
      "Epoch 80/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.3697 - accuracy: 0.6275 - val_loss: 1.7431 - val_accuracy: 0.5660\n",
      "Epoch 81/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1386 - accuracy: 0.6618 - val_loss: 2.1545 - val_accuracy: 0.6111\n",
      "Epoch 82/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0225 - accuracy: 0.7021 - val_loss: 1.8221 - val_accuracy: 0.6146\n",
      "Epoch 83/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1449 - accuracy: 0.6747 - val_loss: 1.9191 - val_accuracy: 0.5833\n",
      "Epoch 84/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9763 - accuracy: 0.6875 - val_loss: 1.7074 - val_accuracy: 0.6007\n",
      "Epoch 85/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1096 - accuracy: 0.6832 - val_loss: 1.7554 - val_accuracy: 0.6319\n",
      "Epoch 86/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2248 - accuracy: 0.6567 - val_loss: 1.4863 - val_accuracy: 0.6285\n",
      "Epoch 87/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.2561 - accuracy: 0.6627 - val_loss: 1.6437 - val_accuracy: 0.5938\n",
      "Epoch 88/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1014 - accuracy: 0.6764 - val_loss: 1.6177 - val_accuracy: 0.6181\n",
      "Epoch 89/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1158 - accuracy: 0.6755 - val_loss: 1.6693 - val_accuracy: 0.5938\n",
      "Epoch 90/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0781 - accuracy: 0.6712 - val_loss: 1.3621 - val_accuracy: 0.6285\n",
      "Epoch 91/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0035 - accuracy: 0.6875 - val_loss: 1.5813 - val_accuracy: 0.6146\n",
      "Epoch 92/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1266 - accuracy: 0.6695 - val_loss: 1.4764 - val_accuracy: 0.6076\n",
      "Epoch 93/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1223 - accuracy: 0.6721 - val_loss: 1.4150 - val_accuracy: 0.6424\n",
      "Epoch 94/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0858 - accuracy: 0.6858 - val_loss: 2.0939 - val_accuracy: 0.6146\n",
      "Epoch 95/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1051 - accuracy: 0.6789 - val_loss: 1.6126 - val_accuracy: 0.6076\n",
      "Epoch 96/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0371 - accuracy: 0.6644 - val_loss: 1.3383 - val_accuracy: 0.6181\n",
      "Epoch 97/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0929 - accuracy: 0.6764 - val_loss: 1.7346 - val_accuracy: 0.6424\n",
      "Epoch 98/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1325 - accuracy: 0.6721 - val_loss: 1.7864 - val_accuracy: 0.5694\n",
      "Epoch 99/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1965 - accuracy: 0.6618 - val_loss: 1.4378 - val_accuracy: 0.6493\n",
      "Epoch 100/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0810 - accuracy: 0.6592 - val_loss: 1.5438 - val_accuracy: 0.6215\n",
      "Epoch 101/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0920 - accuracy: 0.6678 - val_loss: 1.8147 - val_accuracy: 0.6111\n",
      "Epoch 102/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0062 - accuracy: 0.7012 - val_loss: 2.1696 - val_accuracy: 0.6146\n",
      "Epoch 103/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0858 - accuracy: 0.6738 - val_loss: 1.6778 - val_accuracy: 0.5590\n",
      "Epoch 104/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0166 - accuracy: 0.7046 - val_loss: 1.6593 - val_accuracy: 0.5903\n",
      "Epoch 105/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1899 - accuracy: 0.6704 - val_loss: 1.4511 - val_accuracy: 0.6215\n",
      "Epoch 106/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1452 - accuracy: 0.6678 - val_loss: 1.4994 - val_accuracy: 0.5729\n",
      "Epoch 107/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1006 - accuracy: 0.6687 - val_loss: 1.6026 - val_accuracy: 0.6111\n",
      "Epoch 108/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0066 - accuracy: 0.6849 - val_loss: 1.7459 - val_accuracy: 0.6319\n",
      "Epoch 109/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0579 - accuracy: 0.6764 - val_loss: 1.4656 - val_accuracy: 0.6146\n",
      "Epoch 110/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0347 - accuracy: 0.6901 - val_loss: 1.8737 - val_accuracy: 0.5972\n",
      "Epoch 111/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1117 - accuracy: 0.6781 - val_loss: 2.0335 - val_accuracy: 0.5799\n",
      "Epoch 112/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1481 - accuracy: 0.6664 - val_loss: 1.4314 - val_accuracy: 0.6667\n",
      "Epoch 113/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0220 - accuracy: 0.6935 - val_loss: 1.7822 - val_accuracy: 0.5972\n",
      "Epoch 114/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0294 - accuracy: 0.7063 - val_loss: 1.5018 - val_accuracy: 0.6389\n",
      "Epoch 115/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0277 - accuracy: 0.6747 - val_loss: 1.7219 - val_accuracy: 0.6007\n",
      "Epoch 116/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0783 - accuracy: 0.6729 - val_loss: 1.6150 - val_accuracy: 0.6007\n",
      "Epoch 117/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1270 - accuracy: 0.6798 - val_loss: 1.6864 - val_accuracy: 0.6285\n",
      "Epoch 118/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1620 - accuracy: 0.6789 - val_loss: 1.4618 - val_accuracy: 0.6493\n",
      "Epoch 119/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0481 - accuracy: 0.6747 - val_loss: 1.2852 - val_accuracy: 0.6319\n",
      "Epoch 120/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1084 - accuracy: 0.6712 - val_loss: 1.5001 - val_accuracy: 0.6389\n",
      "Epoch 121/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0648 - accuracy: 0.6875 - val_loss: 1.2557 - val_accuracy: 0.6528\n",
      "Epoch 122/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0910 - accuracy: 0.6854 - val_loss: 1.7428 - val_accuracy: 0.5972\n",
      "Epoch 123/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1242 - accuracy: 0.6610 - val_loss: 1.8632 - val_accuracy: 0.6007\n",
      "Epoch 124/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0776 - accuracy: 0.7115 - val_loss: 1.4543 - val_accuracy: 0.6076\n",
      "Epoch 125/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0640 - accuracy: 0.6837 - val_loss: 1.8359 - val_accuracy: 0.6007\n",
      "Epoch 126/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2401 - accuracy: 0.6490 - val_loss: 1.8614 - val_accuracy: 0.6007\n",
      "Epoch 127/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0220 - accuracy: 0.7063 - val_loss: 1.5779 - val_accuracy: 0.6076\n",
      "Epoch 128/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1464 - accuracy: 0.6815 - val_loss: 1.5393 - val_accuracy: 0.6493\n",
      "Epoch 129/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.2482 - accuracy: 0.6644 - val_loss: 1.7702 - val_accuracy: 0.5799\n",
      "Epoch 130/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1632 - accuracy: 0.6515 - val_loss: 1.5534 - val_accuracy: 0.6111\n",
      "Epoch 131/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0764 - accuracy: 0.6772 - val_loss: 1.5820 - val_accuracy: 0.6632\n",
      "Epoch 132/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0210 - accuracy: 0.7046 - val_loss: 1.5745 - val_accuracy: 0.6354\n",
      "Epoch 133/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0870 - accuracy: 0.6832 - val_loss: 1.8118 - val_accuracy: 0.6111\n",
      "Epoch 134/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1402 - accuracy: 0.6764 - val_loss: 1.5770 - val_accuracy: 0.6493\n",
      "Epoch 135/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9751 - accuracy: 0.6918 - val_loss: 2.0011 - val_accuracy: 0.6458\n",
      "Epoch 136/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9815 - accuracy: 0.7055 - val_loss: 1.5867 - val_accuracy: 0.6354\n",
      "Epoch 137/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0901 - accuracy: 0.6909 - val_loss: 1.5246 - val_accuracy: 0.6458\n",
      "Epoch 138/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9255 - accuracy: 0.7149 - val_loss: 1.6418 - val_accuracy: 0.6076\n",
      "Epoch 139/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1533 - accuracy: 0.6704 - val_loss: 1.8479 - val_accuracy: 0.5868\n",
      "Epoch 140/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0207 - accuracy: 0.6866 - val_loss: 1.3500 - val_accuracy: 0.6493\n",
      "Epoch 141/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1795 - accuracy: 0.6541 - val_loss: 1.2704 - val_accuracy: 0.6354\n",
      "Epoch 142/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0884 - accuracy: 0.6789 - val_loss: 1.9563 - val_accuracy: 0.6285\n",
      "Epoch 143/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9383 - accuracy: 0.7098 - val_loss: 2.0279 - val_accuracy: 0.6111\n",
      "Epoch 144/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9910 - accuracy: 0.6819 - val_loss: 1.4766 - val_accuracy: 0.6389\n",
      "Epoch 145/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1263 - accuracy: 0.6644 - val_loss: 1.3092 - val_accuracy: 0.6354\n",
      "Epoch 146/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0659 - accuracy: 0.6798 - val_loss: 1.6178 - val_accuracy: 0.6215\n",
      "Epoch 147/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9477 - accuracy: 0.6969 - val_loss: 1.2594 - val_accuracy: 0.6667\n",
      "Epoch 148/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0815 - accuracy: 0.6755 - val_loss: 1.7353 - val_accuracy: 0.5556\n",
      "Epoch 149/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0615 - accuracy: 0.6807 - val_loss: 1.7425 - val_accuracy: 0.6250\n",
      "Epoch 150/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9290 - accuracy: 0.7243 - val_loss: 1.5548 - val_accuracy: 0.6701\n",
      "Epoch 151/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1010 - accuracy: 0.6824 - val_loss: 1.8235 - val_accuracy: 0.6528\n",
      "Epoch 152/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2598 - accuracy: 0.6635 - val_loss: 1.7113 - val_accuracy: 0.5625\n",
      "Epoch 153/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1096 - accuracy: 0.6815 - val_loss: 1.5312 - val_accuracy: 0.6250\n",
      "Epoch 154/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0063 - accuracy: 0.7106 - val_loss: 1.5379 - val_accuracy: 0.6389\n",
      "Epoch 155/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1083 - accuracy: 0.6704 - val_loss: 1.7488 - val_accuracy: 0.6458\n",
      "Epoch 156/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.2012 - accuracy: 0.6447 - val_loss: 1.5618 - val_accuracy: 0.6042\n",
      "Epoch 157/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0713 - accuracy: 0.7029 - val_loss: 1.5852 - val_accuracy: 0.6389\n",
      "Epoch 158/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0508 - accuracy: 0.6678 - val_loss: 1.7634 - val_accuracy: 0.6354\n",
      "Epoch 159/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0590 - accuracy: 0.6926 - val_loss: 1.7243 - val_accuracy: 0.5972\n",
      "Epoch 160/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1329 - accuracy: 0.6652 - val_loss: 1.6382 - val_accuracy: 0.6146\n",
      "Epoch 161/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0570 - accuracy: 0.7012 - val_loss: 1.5982 - val_accuracy: 0.6562\n",
      "Epoch 162/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9642 - accuracy: 0.7115 - val_loss: 1.4676 - val_accuracy: 0.6771\n",
      "Epoch 163/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9955 - accuracy: 0.7029 - val_loss: 1.7626 - val_accuracy: 0.6458\n",
      "Epoch 164/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0487 - accuracy: 0.6978 - val_loss: 1.4047 - val_accuracy: 0.6632\n",
      "Epoch 165/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1179 - accuracy: 0.6678 - val_loss: 1.6125 - val_accuracy: 0.6424\n",
      "Epoch 166/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0413 - accuracy: 0.6781 - val_loss: 2.1834 - val_accuracy: 0.6215\n",
      "Epoch 167/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0078 - accuracy: 0.6892 - val_loss: 1.8406 - val_accuracy: 0.6042\n",
      "Epoch 168/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9903 - accuracy: 0.7080 - val_loss: 1.2646 - val_accuracy: 0.6667\n",
      "Epoch 169/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0141 - accuracy: 0.6969 - val_loss: 1.3119 - val_accuracy: 0.6458\n",
      "Epoch 170/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0002 - accuracy: 0.6807 - val_loss: 1.5774 - val_accuracy: 0.6146\n",
      "Epoch 171/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0912 - accuracy: 0.6721 - val_loss: 1.3766 - val_accuracy: 0.6424\n",
      "Epoch 172/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0833 - accuracy: 0.6849 - val_loss: 2.2178 - val_accuracy: 0.6215\n",
      "Epoch 173/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0325 - accuracy: 0.7115 - val_loss: 1.5687 - val_accuracy: 0.6597\n",
      "Epoch 174/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9739 - accuracy: 0.7217 - val_loss: 1.8034 - val_accuracy: 0.6493\n",
      "Epoch 175/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9470 - accuracy: 0.7106 - val_loss: 2.6293 - val_accuracy: 0.5972\n",
      "Epoch 176/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0597 - accuracy: 0.6918 - val_loss: 1.4886 - val_accuracy: 0.6493\n",
      "Epoch 177/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9706 - accuracy: 0.7063 - val_loss: 1.5465 - val_accuracy: 0.6667\n",
      "Epoch 178/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1361 - accuracy: 0.6824 - val_loss: 1.2859 - val_accuracy: 0.6597\n",
      "Epoch 179/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0556 - accuracy: 0.6884 - val_loss: 1.4546 - val_accuracy: 0.6528\n",
      "Epoch 180/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0703 - accuracy: 0.6807 - val_loss: 1.5030 - val_accuracy: 0.6319\n",
      "Epoch 181/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0938 - accuracy: 0.6772 - val_loss: 1.9847 - val_accuracy: 0.6042\n",
      "Epoch 182/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0278 - accuracy: 0.6849 - val_loss: 2.0802 - val_accuracy: 0.6146\n",
      "Epoch 183/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0599 - accuracy: 0.6892 - val_loss: 1.4710 - val_accuracy: 0.6562\n",
      "Epoch 184/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1412 - accuracy: 0.6721 - val_loss: 1.5274 - val_accuracy: 0.6389\n",
      "Epoch 185/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0095 - accuracy: 0.7063 - val_loss: 1.4216 - val_accuracy: 0.6319\n",
      "Epoch 186/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9050 - accuracy: 0.7098 - val_loss: 1.4026 - val_accuracy: 0.6701\n",
      "Epoch 187/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9852 - accuracy: 0.6978 - val_loss: 1.5267 - val_accuracy: 0.6424\n",
      "Epoch 188/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9833 - accuracy: 0.6943 - val_loss: 1.5311 - val_accuracy: 0.6389\n",
      "Epoch 189/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1177 - accuracy: 0.6789 - val_loss: 1.5606 - val_accuracy: 0.6493\n",
      "Epoch 190/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9739 - accuracy: 0.7063 - val_loss: 1.3168 - val_accuracy: 0.6528\n",
      "Epoch 191/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9133 - accuracy: 0.7140 - val_loss: 1.4599 - val_accuracy: 0.6632\n",
      "Epoch 192/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1455 - accuracy: 0.6789 - val_loss: 1.6607 - val_accuracy: 0.6250\n",
      "Epoch 193/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0859 - accuracy: 0.6858 - val_loss: 1.6650 - val_accuracy: 0.6389\n",
      "Epoch 194/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0548 - accuracy: 0.6901 - val_loss: 1.5570 - val_accuracy: 0.5833\n",
      "Epoch 195/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0258 - accuracy: 0.6961 - val_loss: 1.6496 - val_accuracy: 0.6667\n",
      "Epoch 196/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9718 - accuracy: 0.7063 - val_loss: 1.6086 - val_accuracy: 0.6424\n",
      "Epoch 197/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9263 - accuracy: 0.7106 - val_loss: 1.5281 - val_accuracy: 0.6111\n",
      "Epoch 198/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1370 - accuracy: 0.6807 - val_loss: 1.3212 - val_accuracy: 0.6424\n",
      "Epoch 199/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0864 - accuracy: 0.6824 - val_loss: 1.6052 - val_accuracy: 0.6215\n",
      "Epoch 200/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0228 - accuracy: 0.6815 - val_loss: 1.4019 - val_accuracy: 0.6736\n",
      "Epoch 201/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9394 - accuracy: 0.7200 - val_loss: 1.2771 - val_accuracy: 0.6562\n",
      "Epoch 202/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8751 - accuracy: 0.7038 - val_loss: 1.6590 - val_accuracy: 0.6354\n",
      "Epoch 203/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0176 - accuracy: 0.6926 - val_loss: 1.4982 - val_accuracy: 0.6215\n",
      "Epoch 204/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8474 - accuracy: 0.7354 - val_loss: 1.5874 - val_accuracy: 0.6458\n",
      "Epoch 205/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9531 - accuracy: 0.7132 - val_loss: 1.7495 - val_accuracy: 0.6424\n",
      "Epoch 206/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8417 - accuracy: 0.7354 - val_loss: 1.3712 - val_accuracy: 0.6354\n",
      "Epoch 207/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8947 - accuracy: 0.7200 - val_loss: 1.4397 - val_accuracy: 0.6632\n",
      "Epoch 208/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9065 - accuracy: 0.7132 - val_loss: 1.3756 - val_accuracy: 0.6806\n",
      "Epoch 209/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0184 - accuracy: 0.6952 - val_loss: 1.4254 - val_accuracy: 0.6667\n",
      "Epoch 210/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9503 - accuracy: 0.7055 - val_loss: 1.4814 - val_accuracy: 0.6250\n",
      "Epoch 211/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9372 - accuracy: 0.6978 - val_loss: 1.4369 - val_accuracy: 0.6493\n",
      "Epoch 212/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0211 - accuracy: 0.6789 - val_loss: 1.4633 - val_accuracy: 0.6736\n",
      "Epoch 213/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9700 - accuracy: 0.6986 - val_loss: 1.3470 - val_accuracy: 0.6632\n",
      "Epoch 214/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0757 - accuracy: 0.6969 - val_loss: 1.3141 - val_accuracy: 0.6667\n",
      "Epoch 215/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0374 - accuracy: 0.6849 - val_loss: 1.5533 - val_accuracy: 0.6458\n",
      "Epoch 216/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0400 - accuracy: 0.6952 - val_loss: 1.3435 - val_accuracy: 0.7049\n",
      "Epoch 217/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8915 - accuracy: 0.7406 - val_loss: 1.4617 - val_accuracy: 0.6701\n",
      "Epoch 218/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0015 - accuracy: 0.6815 - val_loss: 1.6488 - val_accuracy: 0.6354\n",
      "Epoch 219/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9359 - accuracy: 0.7063 - val_loss: 1.5303 - val_accuracy: 0.6181\n",
      "Epoch 220/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0217 - accuracy: 0.6789 - val_loss: 1.2936 - val_accuracy: 0.6736\n",
      "Epoch 221/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9003 - accuracy: 0.7252 - val_loss: 1.4663 - val_accuracy: 0.6215\n",
      "Epoch 222/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0075 - accuracy: 0.6858 - val_loss: 1.3140 - val_accuracy: 0.6771\n",
      "Epoch 223/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1016 - accuracy: 0.6824 - val_loss: 1.5268 - val_accuracy: 0.6285\n",
      "Epoch 224/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0883 - accuracy: 0.6704 - val_loss: 1.2106 - val_accuracy: 0.6632\n",
      "Epoch 225/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0624 - accuracy: 0.6832 - val_loss: 1.3911 - val_accuracy: 0.6354\n",
      "Epoch 226/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0538 - accuracy: 0.6940 - val_loss: 1.2181 - val_accuracy: 0.6771\n",
      "Epoch 227/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9975 - accuracy: 0.7053 - val_loss: 1.4507 - val_accuracy: 0.6354\n",
      "Epoch 228/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0391 - accuracy: 0.7063 - val_loss: 1.2428 - val_accuracy: 0.6528\n",
      "Epoch 229/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0197 - accuracy: 0.6807 - val_loss: 1.1898 - val_accuracy: 0.6667\n",
      "Epoch 230/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0767 - accuracy: 0.6854 - val_loss: 1.6086 - val_accuracy: 0.6319\n",
      "Epoch 231/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0451 - accuracy: 0.7063 - val_loss: 1.4234 - val_accuracy: 0.6458\n",
      "Epoch 232/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0560 - accuracy: 0.6918 - val_loss: 1.3534 - val_accuracy: 0.6354\n",
      "Epoch 233/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9993 - accuracy: 0.6978 - val_loss: 1.5623 - val_accuracy: 0.6424\n",
      "Epoch 234/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9194 - accuracy: 0.7021 - val_loss: 1.3468 - val_accuracy: 0.6667\n",
      "Epoch 235/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0156 - accuracy: 0.7106 - val_loss: 1.6400 - val_accuracy: 0.6562\n",
      "Epoch 236/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0637 - accuracy: 0.6952 - val_loss: 1.6686 - val_accuracy: 0.6250\n",
      "Epoch 237/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1379 - accuracy: 0.6644 - val_loss: 1.4197 - val_accuracy: 0.6979\n",
      "Epoch 238/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0134 - accuracy: 0.6986 - val_loss: 1.6556 - val_accuracy: 0.6389\n",
      "Epoch 239/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9524 - accuracy: 0.7089 - val_loss: 1.4585 - val_accuracy: 0.6424\n",
      "Epoch 240/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1110 - accuracy: 0.6866 - val_loss: 1.5088 - val_accuracy: 0.6667\n",
      "Epoch 241/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9027 - accuracy: 0.7183 - val_loss: 2.0418 - val_accuracy: 0.6042\n",
      "Epoch 242/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9861 - accuracy: 0.7072 - val_loss: 1.4980 - val_accuracy: 0.6771\n",
      "Epoch 243/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8645 - accuracy: 0.7132 - val_loss: 1.4832 - val_accuracy: 0.6597\n",
      "Epoch 244/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9179 - accuracy: 0.7115 - val_loss: 1.6836 - val_accuracy: 0.6250\n",
      "Epoch 245/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0449 - accuracy: 0.6858 - val_loss: 1.9789 - val_accuracy: 0.6215\n",
      "Epoch 246/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.1534 - accuracy: 0.6721 - val_loss: 1.6426 - val_accuracy: 0.6354\n",
      "Epoch 247/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0593 - accuracy: 0.6755 - val_loss: 1.4046 - val_accuracy: 0.6528\n",
      "Epoch 248/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9478 - accuracy: 0.7038 - val_loss: 1.5609 - val_accuracy: 0.6354\n",
      "Epoch 249/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9699 - accuracy: 0.6926 - val_loss: 1.5294 - val_accuracy: 0.6667\n",
      "Epoch 250/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9873 - accuracy: 0.6932 - val_loss: 1.4715 - val_accuracy: 0.6458\n",
      "Epoch 251/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9968 - accuracy: 0.7029 - val_loss: 1.5017 - val_accuracy: 0.7014\n",
      "Epoch 252/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9836 - accuracy: 0.7277 - val_loss: 1.4878 - val_accuracy: 0.6354\n",
      "Epoch 253/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9920 - accuracy: 0.7072 - val_loss: 1.9979 - val_accuracy: 0.6215\n",
      "Epoch 254/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9827 - accuracy: 0.6969 - val_loss: 1.2925 - val_accuracy: 0.6562\n",
      "Epoch 255/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9297 - accuracy: 0.7149 - val_loss: 1.3719 - val_accuracy: 0.6528\n",
      "Epoch 256/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9953 - accuracy: 0.6961 - val_loss: 1.5613 - val_accuracy: 0.6458\n",
      "Epoch 257/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0255 - accuracy: 0.7226 - val_loss: 1.6426 - val_accuracy: 0.6250\n",
      "Epoch 258/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0597 - accuracy: 0.6986 - val_loss: 1.5254 - val_accuracy: 0.6528\n",
      "Epoch 259/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9153 - accuracy: 0.7089 - val_loss: 1.8776 - val_accuracy: 0.6146\n",
      "Epoch 260/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9479 - accuracy: 0.6875 - val_loss: 1.4696 - val_accuracy: 0.6597\n",
      "Epoch 261/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0011 - accuracy: 0.7063 - val_loss: 1.7028 - val_accuracy: 0.6562\n",
      "Epoch 262/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9216 - accuracy: 0.7209 - val_loss: 1.3814 - val_accuracy: 0.6771\n",
      "Epoch 263/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0613 - accuracy: 0.7038 - val_loss: 1.5104 - val_accuracy: 0.6458\n",
      "Epoch 264/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9443 - accuracy: 0.6969 - val_loss: 1.6079 - val_accuracy: 0.6458\n",
      "Epoch 265/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9206 - accuracy: 0.7200 - val_loss: 1.4361 - val_accuracy: 0.6528\n",
      "Epoch 266/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9164 - accuracy: 0.7115 - val_loss: 1.4887 - val_accuracy: 0.6701\n",
      "Epoch 267/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9160 - accuracy: 0.7080 - val_loss: 1.3216 - val_accuracy: 0.6528\n",
      "Epoch 268/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8698 - accuracy: 0.7269 - val_loss: 1.3734 - val_accuracy: 0.6597\n",
      "Epoch 269/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9397 - accuracy: 0.7158 - val_loss: 1.5517 - val_accuracy: 0.6389\n",
      "Epoch 270/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9623 - accuracy: 0.7372 - val_loss: 1.5607 - val_accuracy: 0.6181\n",
      "Epoch 271/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9679 - accuracy: 0.6995 - val_loss: 1.5079 - val_accuracy: 0.6562\n",
      "Epoch 272/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9406 - accuracy: 0.7226 - val_loss: 1.2907 - val_accuracy: 0.6667\n",
      "Epoch 273/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0287 - accuracy: 0.7115 - val_loss: 1.4501 - val_accuracy: 0.6493\n",
      "Epoch 274/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9590 - accuracy: 0.7072 - val_loss: 1.8598 - val_accuracy: 0.6146\n",
      "Epoch 275/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0360 - accuracy: 0.6832 - val_loss: 1.3547 - val_accuracy: 0.6771\n",
      "Epoch 276/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0530 - accuracy: 0.6935 - val_loss: 1.2895 - val_accuracy: 0.6632\n",
      "Epoch 277/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0186 - accuracy: 0.6926 - val_loss: 1.3821 - val_accuracy: 0.6562\n",
      "Epoch 278/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0987 - accuracy: 0.6909 - val_loss: 1.8727 - val_accuracy: 0.6285\n",
      "Epoch 279/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.1406 - accuracy: 0.7029 - val_loss: 1.5305 - val_accuracy: 0.6701\n",
      "Epoch 280/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.8570 - accuracy: 0.7029 - val_loss: 1.3962 - val_accuracy: 0.6667\n",
      "Epoch 281/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9570 - accuracy: 0.7055 - val_loss: 1.5039 - val_accuracy: 0.6493\n",
      "Epoch 282/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9789 - accuracy: 0.7080 - val_loss: 1.6174 - val_accuracy: 0.6076\n",
      "Epoch 283/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9581 - accuracy: 0.7063 - val_loss: 1.5056 - val_accuracy: 0.6285\n",
      "Epoch 284/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9322 - accuracy: 0.7038 - val_loss: 1.4764 - val_accuracy: 0.6250\n",
      "Epoch 285/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8722 - accuracy: 0.7295 - val_loss: 1.3514 - val_accuracy: 0.6562\n",
      "Epoch 286/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9240 - accuracy: 0.7140 - val_loss: 1.7865 - val_accuracy: 0.6458\n",
      "Epoch 287/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0628 - accuracy: 0.6926 - val_loss: 1.4578 - val_accuracy: 0.6424\n",
      "Epoch 288/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0437 - accuracy: 0.6901 - val_loss: 1.4815 - val_accuracy: 0.6458\n",
      "Epoch 289/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9056 - accuracy: 0.7115 - val_loss: 1.4955 - val_accuracy: 0.6042\n",
      "Epoch 290/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0104 - accuracy: 0.7192 - val_loss: 1.8592 - val_accuracy: 0.6389\n",
      "Epoch 291/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8859 - accuracy: 0.7329 - val_loss: 1.4801 - val_accuracy: 0.6562\n",
      "Epoch 292/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0591 - accuracy: 0.6815 - val_loss: 1.6979 - val_accuracy: 0.6389\n",
      "Epoch 293/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 1.0480 - accuracy: 0.7156 - val_loss: 1.5016 - val_accuracy: 0.6458\n",
      "Epoch 294/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.8986 - accuracy: 0.7089 - val_loss: 1.3356 - val_accuracy: 0.6632\n",
      "Epoch 295/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0061 - accuracy: 0.7055 - val_loss: 1.3950 - val_accuracy: 0.6701\n",
      "Epoch 296/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 1.0840 - accuracy: 0.7029 - val_loss: 1.5475 - val_accuracy: 0.6632\n",
      "Epoch 297/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9571 - accuracy: 0.7149 - val_loss: 1.5597 - val_accuracy: 0.6389\n",
      "Epoch 298/300\n",
      "73/73 [==============================] - 0s 3ms/step - loss: 0.9887 - accuracy: 0.6866 - val_loss: 1.5422 - val_accuracy: 0.6285\n",
      "Epoch 299/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9899 - accuracy: 0.6969 - val_loss: 1.3994 - val_accuracy: 0.6667\n",
      "Epoch 300/300\n",
      "73/73 [==============================] - 0s 2ms/step - loss: 0.9262 - accuracy: 0.7175 - val_loss: 1.4455 - val_accuracy: 0.6632\n"
     ]
    }
   ],
   "source": [
    "train_summary = model3.fit(train_gen2, epochs = 300, verbose = 1, callbacks = None, validation_data = val_gen2, \n",
    "                              shuffle = True, steps_per_epoch = len(train_gen2)//batch_size, \n",
    "                              validation_steps = len(val_gen2)//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0a9ad08f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 2048)]            0         \n",
      "                                                                 \n",
      " intermediate (Dense)        (None, 85)                174165    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 174,165\n",
      "Trainable params: 174,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feat_model = Model(inputs = model3.input, outputs = model3.layers[-2].output)\n",
    "feat_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "da3a579e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n"
     ]
    }
   ],
   "source": [
    "weights_list3 = feat_model.get_weights()\n",
    "\n",
    "print(len(weights_list3[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "6a150d3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.2570282e-02  2.7582886e-02  3.5412494e-02 ...  4.1232813e-02\n",
      "  -8.1645876e-01  4.6295729e-02]\n",
      " [-6.6271067e-02 -6.0838886e-02 -5.9246797e-02 ...  2.5046097e-02\n",
      "   1.8070904e-03 -4.5600440e-02]\n",
      " [ 2.0238262e-02 -4.6132050e-02 -4.9232632e-02 ... -1.3403770e-01\n",
      "   1.3141199e+00  2.6507247e-02]\n",
      " ...\n",
      " [-5.8204886e-02 -4.7735837e-03 -3.1591924e-03 ...  1.2069412e-02\n",
      "   2.6402083e-01 -1.5647998e-01]\n",
      " [-6.1924208e-02 -2.8917195e-02  3.8849480e-02 ...  2.7971931e-03\n",
      "   3.9022020e-01 -7.0090391e-02]\n",
      " [ 2.0414205e-02 -3.2741504e-04 -2.6345322e-02 ...  3.6589526e-02\n",
      "  -9.7560957e-02  3.0911432e-03]] (2048, 85)\n"
     ]
    }
   ],
   "source": [
    "print(weights_list3[0], weights_list3[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "635e004e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 4.2570282e-02,  2.7582886e-02,  3.5412494e-02, ...,\n",
       "          4.1232813e-02, -8.1645876e-01,  4.6295729e-02],\n",
       "        [-6.6271067e-02, -6.0838886e-02, -5.9246797e-02, ...,\n",
       "          2.5046097e-02,  1.8070904e-03, -4.5600440e-02],\n",
       "        [ 2.0238262e-02, -4.6132050e-02, -4.9232632e-02, ...,\n",
       "         -1.3403770e-01,  1.3141199e+00,  2.6507247e-02],\n",
       "        ...,\n",
       "        [-5.8204886e-02, -4.7735837e-03, -3.1591924e-03, ...,\n",
       "          1.2069412e-02,  2.6402083e-01, -1.5647998e-01],\n",
       "        [-6.1924208e-02, -2.8917195e-02,  3.8849480e-02, ...,\n",
       "          2.7971931e-03,  3.9022020e-01, -7.0090391e-02],\n",
       "        [ 2.0414205e-02, -3.2741504e-04, -2.6345322e-02, ...,\n",
       "          3.6589526e-02, -9.7560957e-02,  3.0911432e-03]], dtype=float32),\n",
       " array([-0.03651396, -0.01135878, -0.03909372, -0.1555166 , -0.14149779,\n",
       "        -0.07470209, -0.02380687, -0.05713034, -0.15688655, -0.08627871,\n",
       "        -0.16019008, -0.04203104, -0.01275444, -0.09129269, -0.12100253,\n",
       "        -0.08774588, -0.13883682, -0.26916027, -0.07919597, -0.01113721,\n",
       "        -0.20530272, -0.04567936, -0.04810239, -0.11713473, -0.10369931,\n",
       "         0.15954524, -0.03420157, -0.03850812, -0.06256762, -0.06915671,\n",
       "        -0.15408655, -0.04438227, -0.09961966, -0.11528046, -0.11339387,\n",
       "        -0.04051552, -0.12300093, -0.11905853, -0.02965211, -0.02623696,\n",
       "        -0.10284457, -0.04375515, -0.08966553, -0.0823058 , -0.03326588,\n",
       "        -0.09406032, -0.06924681, -0.14506064, -0.07581647, -0.05578988,\n",
       "        -0.08730343, -0.06050096, -0.03199594, -0.09826547, -0.0501265 ,\n",
       "        -0.07418105, -0.02735343, -0.05062926, -0.16836536, -0.218709  ,\n",
       "         1.6460255 , -0.11352909, -0.01875713, -0.06375765, -0.12274334,\n",
       "        -0.01947342, -0.01644725, -0.03162671, -0.03083629, -0.16157047,\n",
       "        -0.04793261, -0.17802937, -0.08791988, -0.0183953 ,  0.87706375,\n",
       "        -0.17016606, -0.14430523, -0.13363652, -0.26985604, -0.04422854,\n",
       "        -0.06336808, -0.0685797 , -0.04725878, -0.12085553, -0.07815343],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat_model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2ed13b64",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 4.2570282e-02,  2.7582886e-02,  3.5412494e-02, ...,\n",
      "         4.1232813e-02, -4.3572113e-01,  4.6295729e-02],\n",
      "       [-6.6271067e-02, -6.0838886e-02, -5.9246797e-02, ...,\n",
      "         2.5046097e-02, -4.4697262e-02, -4.5600440e-02],\n",
      "       [ 2.0238262e-02, -4.6132050e-02, -4.9232632e-02, ...,\n",
      "        -1.3403770e-01,  8.9921498e-01,  2.6507247e-02],\n",
      "       ...,\n",
      "       [-5.8204886e-02, -4.7735837e-03, -3.1591924e-03, ...,\n",
      "         1.2069412e-02,  2.4534327e-01, -1.5647998e-01],\n",
      "       [-6.1924208e-02, -2.8917195e-02,  3.8849480e-02, ...,\n",
      "         2.7971931e-03,  1.9825137e-01, -7.0090391e-02],\n",
      "       [ 2.0414205e-02, -3.2741504e-04, -2.6345322e-02, ...,\n",
      "         3.6589526e-02, -1.8849771e-02,  3.0911432e-03]], dtype=float32), array([-0.03651396, -0.01135878, -0.03909372, -0.1555166 , -0.13045943,\n",
      "       -0.07470209, -0.02380687, -0.0570066 , -0.15688655, -0.08627871,\n",
      "       -0.16019008, -0.04203104, -0.01275444, -0.09129269, -0.12100253,\n",
      "       -0.08774588, -0.13883682, -0.26916027, -0.07919597, -0.01113721,\n",
      "       -0.20530272, -0.04567936, -0.04810239, -0.11713473, -0.10369931,\n",
      "        0.10238597, -0.03420157, -0.03850812, -0.06256762, -0.06038808,\n",
      "       -0.15408655, -0.04438227, -0.09961966, -0.10699334, -0.11339387,\n",
      "       -0.04051552, -0.12300093, -0.11905853, -0.02965211, -0.02623696,\n",
      "       -0.10284457, -0.04375515, -0.08966553, -0.0823058 , -0.03326588,\n",
      "       -0.09406032, -0.06924681, -0.14506064, -0.07581647, -0.05578988,\n",
      "       -0.08730343, -0.06050096, -0.03199594, -0.09826547, -0.0501265 ,\n",
      "       -0.07418105, -0.02735343, -0.05062926, -0.16836536, -0.218709  ,\n",
      "        1.3781679 , -0.02198003, -0.01875713, -0.06375765, -0.12274334,\n",
      "       -0.01947342, -0.01644725, -0.03162671, -0.03083629, -0.16195382,\n",
      "       -0.04793261, -0.17802937, -0.08791988, -0.0183953 ,  0.73541313,\n",
      "       -0.12621996, -0.13563834, -0.13363652, -0.26985604, -0.04422854,\n",
      "       -0.06336808, -0.0685797 , -0.04725878,  0.01368564, -0.07815343],\n",
      "      dtype=float32), array([[-2.6974251 , -0.27623567,  1.8423368 , ...,  2.791989  ,\n",
      "         1.7992651 , -2.9374685 ],\n",
      "       [-2.5549278 , -1.1409935 ,  1.8214685 , ...,  2.9134703 ,\n",
      "         1.7766362 , -0.06802152],\n",
      "       [-0.25196263, -0.01962969, -0.65597594, ..., -0.16878141,\n",
      "        -0.20581673, -0.27973074],\n",
      "       ...,\n",
      "       [-1.2960838 ,  1.5826073 , -0.31674778, ..., -1.0780495 ,\n",
      "         1.4656333 , -1.2007616 ],\n",
      "       [-0.07602122,  1.2992046 , -1.0830743 , ..., -0.00477982,\n",
      "        -0.9836214 ,  1.2920371 ],\n",
      "       [-0.62266946, -0.54580444, -0.19225898, ..., -1.2349248 ,\n",
      "         0.05332587, -1.3871676 ]], dtype=float32), array([  6.6409845 ,  -1.8473512 ,   2.7136805 ,  -0.1201532 ,\n",
      "         6.0567827 ,  -0.61573017,   4.978788  ,   2.9387326 ,\n",
      "         0.39576238,  -0.61341107,  -1.3218656 ,  -6.275859  ,\n",
      "         0.65735275,   4.093116  ,   0.908067  ,   3.808128  ,\n",
      "        -2.6443582 , -11.314949  ,   0.54799414,   2.2187076 ,\n",
      "        -4.067074  ,  -6.758697  ,  -7.6836486 ,  -0.02719587,\n",
      "        -0.85428363,   3.761162  ,   2.0930674 ,   0.6435193 ,\n",
      "        -4.2023926 ,  -6.1972723 ,  -2.0860295 ,  -2.0931256 ,\n",
      "         6.8589067 ,  -1.0406706 ,   6.562545  ,  -1.8030205 ,\n",
      "        -0.41283607,   3.2116127 ,  -1.0337194 ,   3.9246929 ],\n",
      "      dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "weights_list2 = model3.get_weights()\n",
    "print(weights_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "69d27841",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.set_weights(weights_list2[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "34447e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "outputs_1 = np.matmul(np.matmul(test_seen_vec, weights_list3[0]), test_seen_sig)\n",
    "preds_1 = np.array([np.argmax(output) for output in outputs_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "f3666964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37 37 35 ... 35  4 37]\n",
      "[[16]\n",
      " [31]\n",
      " [ 8]\n",
      " ...\n",
      " [17]\n",
      " [ 9]\n",
      " [19]]\n"
     ]
    }
   ],
   "source": [
    "print(preds_1)\n",
    "print(labels_test_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a6948f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0 ...   0  10 184]\n",
      " [  0   0   0 ...   0   0  60]\n",
      " [  0   0   0 ...   0   0  39]\n",
      " ...\n",
      " [  0   0   0 ...   0   3 104]\n",
      " [  0   0   0 ...   0   0   0]\n",
      " [  0   0   0 ...   0   0   0]]\n",
      "[[0.         0.         0.         ... 0.         0.02906977 0.53488372]\n",
      " [0.         0.         0.         ... 0.         0.         1.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.95121951]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.01515152 0.52525253]\n",
      " [       nan        nan        nan ...        nan        nan        nan]\n",
      " [       nan        nan        nan ...        nan        nan        nan]]\n",
      "nan\n",
      "The top 1% accuracy is: nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\AppData\\Local\\Temp\\ipykernel_14572\\4279645914.py:3: RuntimeWarning: invalid value encountered in divide\n",
      "  cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(labels_test_seen, preds_1)\n",
    "print(cm)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(cm)\n",
    "avg = sum(cm.diagonal())/len(test_labels_seen)\n",
    "print(avg)\n",
    "acc_seen = avg*100\n",
    "print(\"The top 1% accuracy is:\", acc_seen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "79d1c6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predictions\n",
    "outputs_2 = np.matmul(np.matmul(test_unseen_vec, out), test_unseen_sig)\n",
    "preds_2 = np.array([np.argmax(output) for output in outputs_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "e350ec10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The top 1% accuracy is: 10.0\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(labels_test_unseen, preds_2)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "avg = sum(cm.diagonal())/len(test_labels_unseen)\n",
    "acc_unseen = avg*100\n",
    "print(\"The top 1% accuracy is:\", acc_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51300963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
