{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d6e42e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "raw",
   "id": "efc9c457",
   "metadata": {},
   "source": [
    "GZSL_AWA2_3: Experiments with New attributes (New attribute length = 85*embedding length, then transform it to length 512)\n",
    "\tStep 1 - Class wise continous attributes are extracted\n",
    "\tStep 2 - Word vectors are extracted for each semantic attribute using pretrained w2v model \n",
    "                 New attributes are formed by aggregating the continous attribute values and word vectors\n",
    "\tStep 3 - Visual features are extracted from pre-trained ResNet101 (without finetuning)\n",
    "\tStep 4 - New attribute vectors are transformed into a lower dimensional space using 'model0'\n",
    "\tStep 5 - Define 'model2' for attribute to class label mapping\n",
    "\t\t Define 'model1' for visual feature to class label mapping\n",
    "\t\t Train 'model2' and 'model1' through the iterative process\n",
    "\tStep 6 - Evaluate for seen and unseen categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64bb0868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please add the folder name of the dataset to run it on different dataset.\n",
    "dataset = 'AWA2'\n",
    "path = 'E:/Sushree/Dataset/data/xlsa17/data/'\n",
    "\n",
    "res101 = scipy.io.loadmat(path + dataset + '/res101.mat')\n",
    "att_splits = scipy.io.loadmat(path + dataset + '/att_splits.mat')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b041c0fb",
   "metadata": {},
   "source": [
    "Step 1 - Class wise continous attributes are extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6082508e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85, 50)\n",
      "[[0.         0.         0.         ... 0.00882092 0.03640974 0.03145501]\n",
      " [0.12045618 0.00426584 0.         ... 0.17996306 0.0618086  0.03495531]\n",
      " [0.26584459 0.20652363 0.         ... 0.05026822 0.04274552 0.04915256]\n",
      " ...\n",
      " [0.22516498 0.15266022 0.         ... 0.12733492 0.10009694 0.01771   ]\n",
      " [0.19613947 0.1966714  0.         ... 0.01787277 0.06698743 0.25883601]\n",
      " [0.03819588 0.08046548 0.10363715 ... 0.01479997 0.05250999 0.14194515]] (50, 85)\n"
     ]
    }
   ],
   "source": [
    "signature = att_splits['att']\n",
    "#signature = att_splits['original_att']\n",
    "#signature = signature/100\n",
    "print(signature.shape) #(85, 50)\n",
    "\n",
    "attribute = signature.transpose()\n",
    "attribute[attribute<0] = 0\n",
    "print(attribute, attribute.shape)#(50, 85)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ee2eba39",
   "metadata": {},
   "source": [
    "Step 2 - Word vectors are extracted for each semantic attribute using pretrained w2v model \n",
    "                 New attributes are formed by aggregating the continous attribute values and word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ab0196a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrain w2v model\n",
      "Done replacing OOD words\n",
      "Done preprocessing attribute des\n",
      "black\n",
      "white\n",
      "blue\n",
      "brown\n",
      "gray\n",
      "orange\n",
      "red\n",
      "yellow\n",
      "patches\n",
      "spots\n",
      "stripes\n",
      "furry\n",
      "hairless\n",
      "tough skin\n",
      "big\n",
      "small\n",
      "bulbous\n",
      "lean\n",
      "flippers\n",
      "hands\n",
      "hooves\n",
      "pads\n",
      "paws\n",
      "long leg\n",
      "longneck\n",
      "tail\n",
      "chew teeth\n",
      "meat teeth\n",
      "buckteeth\n",
      "strain teeth\n",
      "horns\n",
      "claws\n",
      "tusks\n",
      "smelly\n",
      "flys\n",
      "hops\n",
      "swims\n",
      "tunnels\n",
      "walks\n",
      "fast\n",
      "slow\n",
      "strong\n",
      "weak\n",
      "muscle\n",
      "bipedal\n",
      "quadrupedal\n",
      "active\n",
      "inactive\n",
      "nocturnal\n",
      "hibernate\n",
      "agility\n",
      "fish\n",
      "meat\n",
      "plankton\n",
      "vegetation\n",
      "insects\n",
      "forager\n",
      "grazer\n",
      "hunter\n",
      "scavenger\n",
      "skimmer\n",
      "stalker\n",
      "new world\n",
      "old world\n",
      "arctic\n",
      "coastal\n",
      "desert\n",
      "bush\n",
      "plains\n",
      "forest\n",
      "fields\n",
      "jungle\n",
      "mountains\n",
      "ocean\n",
      "ground\n",
      "water\n",
      "tree\n",
      "cave\n",
      "fierce\n",
      "timid\n",
      "smart\n",
      "group\n",
      "solitary\n",
      "nest spot\n",
      "domestic\n",
      "counter_err  0\n",
      "[[ 0.10498047  0.01843262  0.00897217 ...  0.09228516  0.06103516\n",
      "  -0.1328125 ]\n",
      " [ 0.02697754  0.06933594  0.02416992 ...  0.06933594  0.06982422\n",
      "  -0.03369141]\n",
      " [ 0.0390625   0.08642578  0.22363281 ...  0.04663086  0.02258301\n",
      "  -0.15722656]\n",
      " ...\n",
      " [ 0.21289062  0.15039062 -0.14746094 ... -0.18652344 -0.10351562\n",
      "   0.24609375]\n",
      " [-0.02287292  0.18652344 -0.25854492 ... -0.13476562  0.03259277\n",
      "   0.19042969]\n",
      " [-0.29492188  0.15039062 -0.1484375  ...  0.11572266  0.07519531\n",
      "   0.00210571]] (85, 300)\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "import pandas as pd\n",
    "print('Load pretrain w2v model')\n",
    "\n",
    "model_name = 'word2vec-google-news-300'#best model\n",
    "#model_name = 'fasttext-wiki-news-subwords-300'\n",
    "\n",
    "model = api.load(model_name)\n",
    "\n",
    "dim_w2v = 300\n",
    "\n",
    "#%%\n",
    "replace_word = [('newworld','new world'),('oldworld','old world'),('nestspot','nest spot'),('toughskin','tough skin'),\n",
    "                ('longleg','long leg'),('chewteeth','chew teeth'),('meatteeth','meat teeth'),('strainteeth','strain teeth'),\n",
    "                ('quadrapedal','quadrupedal')]  # for AWA2\n",
    "\n",
    "\n",
    "#For AWA2\n",
    "path = 'E:/Sushree/Dataset/Animals_with_Attributes2/attribute/predicates.txt'\n",
    "df=pd.read_csv(path,sep='\\t',header = None, names = ['idx','des'])\n",
    "des = df['des'].values\n",
    "\n",
    "#%% replace out of dictionary (OOD) words\n",
    "for pair in replace_word:\n",
    "    for idx,s in enumerate(des):\n",
    "        des[idx] = s.replace(pair[0],pair[1])\n",
    "print('Done replacing OOD words')\n",
    "\n",
    "df['new_des'] = des\n",
    "df.to_csv('E:/Sushree/Dataset/Animals_with_Attributes2/attribute/new_des.csv')\n",
    "print('Done preprocessing attribute des')\n",
    "\n",
    "import pickle\n",
    "\n",
    "counter_err = 0\n",
    "\n",
    "all_w2v = []\n",
    "for s in des:\n",
    "    print(s)\n",
    "    words = s.split(' ')\n",
    "    if words[-1] == '':     #remove empty element\n",
    "        words = words[:-1]\n",
    "    w2v = np.zeros(dim_w2v)\n",
    "    for w in words:\n",
    "        try:\n",
    "            w2v += model[w]\n",
    "        except Exception as e:\n",
    "            print(e)\n",
    "            counter_err += 1\n",
    "    w2v = w2v / len(words)  \n",
    "    all_w2v.append(w2v[np.newaxis,:])\n",
    "    \n",
    "print('counter_err ',counter_err)\n",
    "\n",
    "#%%\n",
    "w2v_att = np.concatenate(all_w2v,axis=0)\n",
    "#pdb.set_trace()\n",
    "#%%\n",
    "print(w2v_att, w2v_att.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5facf5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 3.64005783e-03\n",
      "  2.36526964e-03 6.62352294e-05]\n",
      " [1.26455459e-02 2.22032260e-03 1.08075305e-03 ... 4.04512114e-03\n",
      "  2.62847534e-03 7.36058436e-05]\n",
      " [2.79084898e-02 4.90021159e-03 2.38520233e-03 ... 5.68806494e-03\n",
      "  3.69604220e-03 1.03501182e-04]\n",
      " ...\n",
      " [2.36379246e-02 4.15037979e-03 2.02021798e-03 ... 2.04944856e-03\n",
      "  1.33170919e-03 3.72921811e-05]\n",
      " [2.05908133e-02 3.61536373e-03 1.75979625e-03 ... 2.99531908e-02\n",
      "  1.94632548e-02 5.45034326e-04]\n",
      " [4.00982111e-03 7.04049985e-04 3.42699827e-04 ... 1.64262697e-02\n",
      "  1.06736098e-02 2.98895730e-04]] (50, 25500)\n"
     ]
    }
   ],
   "source": [
    "attribute_new = np.einsum('ij,jl->ijl', attribute, w2v_att)\n",
    "\n",
    "attribute_new = np.reshape(attribute_new, [attribute_new.shape[0], attribute_new.shape[1]* attribute_new.shape[2]])\n",
    "print(attribute_new, attribute_new.shape)\n",
    "\n",
    "#attribute_new[attribute_new<0] = 0\n",
    "#print(attribute_new, attribute_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "237b819e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    2     4     5 ... 37318 37320 37321] 37321\n",
      "[    0     1     3 ... 37306 37307 37319] 37319\n",
      "[ 1046  1047  1048 ... 35288 35289 35290] 35290\n"
     ]
    }
   ],
   "source": [
    "# total number of instances or images = 37322: ranges from 0 to 37321\n",
    "\n",
    "trainval_loc = np.squeeze(att_splits['trainval_loc']-1) # -1: to consider the overflow problem\n",
    "print(np.unique(trainval_loc), np.max(np.unique(trainval_loc))) # smallest location: 2, largest location 37321\n",
    "\n",
    "test_seen_loc = np.squeeze(att_splits['test_seen_loc']-1)\n",
    "print(np.unique(test_seen_loc), np.max(np.unique(test_seen_loc))) # smallest location: 0, largest location 37319\n",
    "\n",
    "test_unseen_loc = np.squeeze(att_splits['test_unseen_loc']-1)\n",
    "print(np.unique(test_unseen_loc), np.max(np.unique(test_unseen_loc))) # smallest location: 1046, largest location 35290\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c148c5e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels [[ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " ...\n",
      " [38]\n",
      " [38]\n",
      " [38]] (37322, 1)\n",
      "unique_labels [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50] (50,)\n",
      "labels_trainval [[43]\n",
      " [22]\n",
      " [43]\n",
      " ...\n",
      " [40]\n",
      " [19]\n",
      " [46]] (23527, 1)\n",
      "unique_labels_trainval [ 1  2  3  4  5  6  8 10 11 12 13 14 15 16 17 18 19 20 21 22 25 26 27 28\n",
      " 29 32 33 35 36 37 38 39 40 42 43 44 45 46 48 49] (40,)\n",
      "labels_test_seen [[22]\n",
      " [49]\n",
      " [14]\n",
      " ...\n",
      " [25]\n",
      " [15]\n",
      " [27]] (5882, 1)\n",
      "unique_labels_test_seen [ 1  2  3  4  5  6  8 10 11 12 13 14 15 16 17 18 19 20 21 22 25 26 27 28\n",
      " 29 32 33 35 36 37 38 39 40 42 43 44 45 46 48 49] (40,)\n",
      "labels_test_unseen [[30]\n",
      " [30]\n",
      " [30]\n",
      " ...\n",
      " [47]\n",
      " [47]\n",
      " [47]] (7913, 1)\n",
      "unique_labels_test_unseen [ 7  9 23 24 30 31 34 41 47 50] (10,)\n",
      "correct number of instances for training, test seen and test unseen categories\n",
      "Number of overlapping classes between trainval and test seen: 40\n",
      "Number of overlapping classes between trainval and test unseen: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels = res101['labels']# direct class labels\n",
    "print('labels', labels, labels.shape)# 37322 x 1\n",
    "\n",
    "print('unique_labels', np.unique(labels), np.unique(labels).shape)# class labels range from 1 to 50, 50 classes\n",
    "\n",
    "# get the labels for trainval, test seen and test unseen sets\n",
    "\n",
    "labels_trainval = labels[trainval_loc]\n",
    "print('labels_trainval', labels_trainval, labels_trainval.shape)\n",
    "\n",
    "unique_labels_trainval = np.unique(labels_trainval) # labels min:1 max:49\n",
    "print('unique_labels_trainval', unique_labels_trainval, unique_labels_trainval.shape)# 40 classes\n",
    "\n",
    "\n",
    "labels_test_seen = labels[test_seen_loc]\n",
    "print('labels_test_seen', labels_test_seen, labels_test_seen.shape)\n",
    "\n",
    "unique_labels_test_seen = np.unique(labels_test_seen) # labels min:1 max:49\n",
    "print('unique_labels_test_seen', unique_labels_test_seen, unique_labels_test_seen.shape)# 40 classes\n",
    "\n",
    "\n",
    "labels_test_unseen = labels[test_unseen_loc]\n",
    "print('labels_test_unseen', labels_test_unseen, labels_test_unseen.shape)\n",
    "\n",
    "unique_labels_test_unseen = np.unique(labels_test_unseen) # labels min:7 max:50\n",
    "print('unique_labels_test_unseen', unique_labels_test_unseen, unique_labels_test_unseen.shape)# 10 classes\n",
    "\n",
    "\n",
    "if len(labels) == len(labels_trainval) + len(labels_test_seen) + len(labels_test_unseen):\n",
    "    print('correct number of instances for training, test seen and test unseen categories')\n",
    "    \n",
    "print(\"Number of overlapping classes between trainval and test seen:\",len(set(unique_labels_trainval).intersection(set(unique_labels_test_seen))))\n",
    "\n",
    "print(\"Number of overlapping classes between trainval and test unseen:\",len(set(unique_labels_trainval).intersection(set(unique_labels_test_unseen))))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "48cddd3e",
   "metadata": {},
   "source": [
    "Step 3 - Visual features are extracted from pre-trained ResNet101 (without finetuning)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c88acec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for trainval: (23527, 2048)\n",
      "Features for test seen: (5882, 2048)\n",
      "Features for test unseen: (7913, 2048)\n"
     ]
    }
   ],
   "source": [
    "X_features = res101['features']\n",
    "\n",
    "# locations are already subtracted by 1, so they range from 0 to 37321\n",
    "trainval_vec = X_features[:, trainval_loc].transpose()\n",
    "test_seen_vec = X_features[:, test_seen_loc].transpose()\n",
    "test_unseen_vec = X_features[:, test_unseen_loc].transpose()\n",
    "\n",
    "print(\"Features for trainval:\", trainval_vec.shape) #(23527, 2048)\n",
    "print(\"Features for test seen:\", test_seen_vec.shape)# (5882, 2048)\n",
    "print(\"Features for test unseen:\", test_unseen_vec.shape) #(7913, 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e89686f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6.04562728e-04 1.06149967e-04 5.16690239e-05 ... 1.32930511e-03\n",
      "  8.63767876e-04 2.41883050e-05]\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 1.64911392e-03\n",
      "  1.07157614e-03 3.00076109e-05]\n",
      " [6.04562728e-04 1.06149967e-04 5.16690239e-05 ... 1.32930511e-03\n",
      "  8.63767876e-04 2.41883050e-05]\n",
      " ...\n",
      " [0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 3.84930615e-03\n",
      "  2.50123691e-03 7.00427543e-05]\n",
      " [8.83694338e-04 1.55160285e-04 7.55250393e-05 ... 2.68077514e-03\n",
      "  1.74193828e-03 4.87799274e-05]\n",
      " [4.07042949e-03 7.14691690e-04 3.47879730e-04 ... 3.50406426e-02\n",
      "  2.27690251e-02 6.37606629e-04]] (23527, 25500)\n",
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 ... 1.64911392e-03\n",
      "  1.07157614e-03 3.00076109e-05]\n",
      " [2.05908133e-02 3.61536373e-03 1.75979625e-03 ... 2.99531908e-02\n",
      "  1.94632548e-02 5.45034326e-04]\n",
      " [2.02414071e-03 3.55401451e-04 1.72993421e-04 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [1.40754209e-02 2.47138204e-03 1.20295749e-03 ... 1.19592677e-02\n",
      "  7.77100094e-03 2.17613257e-04]\n",
      " [1.22845937e-02 2.15694611e-03 1.04990423e-03 ... 2.07033114e-03\n",
      "  1.34527846e-03 3.76721647e-05]\n",
      " [3.76751163e-03 6.61504950e-04 3.21990820e-04 ... 5.80479554e-03\n",
      "  3.77189246e-03 1.05625235e-04]] (5882, 25500)\n",
      "[[2.90309359e-02 5.09729224e-03 2.48113231e-03 ... 1.94351262e-03\n",
      "  1.26287318e-03 3.53645493e-05]\n",
      " [2.90309359e-02 5.09729224e-03 2.48113231e-03 ... 1.94351262e-03\n",
      "  1.26287318e-03 3.53645493e-05]\n",
      " [2.90309359e-02 5.09729224e-03 2.48113231e-03 ... 1.94351262e-03\n",
      "  1.26287318e-03 3.53645493e-05]\n",
      " ...\n",
      " [6.52773571e-03 1.14614894e-03 5.57893692e-04 ... 7.16131575e-03\n",
      "  4.65334441e-03 1.30308752e-04]\n",
      " [6.52773571e-03 1.14614894e-03 5.57893692e-04 ... 7.16131575e-03\n",
      "  4.65334441e-03 1.30308752e-04]\n",
      " [6.52773571e-03 1.14614894e-03 5.57893692e-04 ... 7.16131575e-03\n",
      "  4.65334441e-03 1.30308752e-04]] (7913, 25500)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# attribute is defined for all 50 classes, so we cant use locations directly, instead we have to use labels \n",
    "# that range from 1 to 50, so we have to subtract 1\n",
    "\n",
    "train_attributes = np.zeros((len(trainval_loc), attribute_new.shape[1]))\n",
    "for i in range(len(trainval_loc)):\n",
    "    train_attributes[i] = attribute_new[int(labels_trainval[i])-1]\n",
    "\n",
    "print(train_attributes, train_attributes.shape)# (23527, 85)\n",
    "\n",
    "test_seen_attributes = np.zeros((len(test_seen_loc), attribute_new.shape[1]))\n",
    "for i in range(len(test_seen_loc)):\n",
    "    test_seen_attributes[i] = attribute_new[int(labels_test_seen[i])-1]\n",
    "\n",
    "print(test_seen_attributes, test_seen_attributes.shape)# (5882, 85)\n",
    "\n",
    "test_unseen_attributes = np.zeros((len(test_unseen_loc), attribute_new.shape[1]))\n",
    "for i in range(len(test_unseen_loc)):\n",
    "    test_unseen_attributes[i] = attribute_new[int(labels_test_unseen[i])-1]\n",
    "\n",
    "print(test_unseen_attributes, test_unseen_attributes.shape)# (7913, 85)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "79266bbb",
   "metadata": {},
   "source": [
    "\tStep 4 - New attribute vectors are transformed into a lower dimensional space using 'model0'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85741854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25500\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 25500)]           0         \n",
      "                                                                 \n",
      " layer1 (Dense)              (None, 2048)              52226048  \n",
      "                                                                 \n",
      " layer2 (Dense)              (None, 1024)              2098176   \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, 512)               524800    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 54,849,024\n",
      "Trainable params: 0\n",
      "Non-trainable params: 54,849,024\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "attribute_shape_new = attribute_new.shape[1]\n",
    "print(attribute_shape_new)\n",
    "\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from keras.optimizers import SGD, Adam, Adagrad\n",
    "import keras.backend as K\n",
    "\n",
    "# define model for attribute transformation\n",
    "\n",
    "inputt = Input(shape = attribute_shape_new)\n",
    "hidden = Dense(2048, name=\"layer1\", activation='linear')(inputt)\n",
    "#norm_layer = Lambda(lambda x: K.l2_normalize(x,axis=1))\n",
    "#batchnorm = BatchNormalization()(hidden)\n",
    "#batchnorm = norm_layer(hidden)\n",
    "hidden2 = Dense(1024, name=\"layer2\", activation='linear')(hidden)\n",
    "output = Dense(512, name=\"layer3\", activation='linear')(hidden2)\n",
    "\n",
    "model0 = Model(inputs = inputt, outputs = output)\n",
    "\n",
    "#sgd = SGD(learning_rate = 1e-2, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "opt = Adam(learning_rate = 1e-2, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0001)\n",
    "\n",
    "model0.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "for layer in model0.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "model0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d6ebf9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736/736 [==============================] - 2s 2ms/step\n",
      "[[-0.01613085  0.04699895 -0.07911047 ... -0.048988   -0.07092995\n",
      "   0.01688505]\n",
      " [-0.03439669  0.02339046 -0.06888594 ... -0.02540437 -0.04033518\n",
      "  -0.00347001]\n",
      " [-0.01613085  0.04699895 -0.07911047 ... -0.048988   -0.07092995\n",
      "   0.01688505]\n",
      " ...\n",
      " [ 0.02830535  0.00767346 -0.0814832  ... -0.01449266 -0.03441949\n",
      "   0.02702714]\n",
      " [ 0.02360165  0.02732371 -0.06990636 ...  0.00148146 -0.07558045\n",
      "   0.04686571]\n",
      " [-0.01684993  0.02050018 -0.09581041 ... -0.01330982 -0.03952045\n",
      "   0.02689633]] (23527, 512)\n",
      "184/184 [==============================] - 0s 2ms/step\n",
      "[[-0.03439669  0.02339046 -0.06888594 ... -0.02540437 -0.04033518\n",
      "  -0.00347001]\n",
      " [ 0.02516608 -0.00200605 -0.08214919 ... -0.01267577 -0.07438489\n",
      "   0.05249437]\n",
      " [-0.01636219  0.02860832 -0.06459633 ...  0.00162746 -0.08533247\n",
      "   0.0294285 ]\n",
      " ...\n",
      " [ 0.00595193  0.00904077 -0.04717364 ... -0.05065586 -0.06772685\n",
      "   0.04130901]\n",
      " [-0.02980464  0.04468604 -0.08603748 ... -0.0519068  -0.05965263\n",
      "   0.0112911 ]\n",
      " [-0.02875178  0.02241314 -0.05021622 ... -0.04393735 -0.0512049\n",
      "   0.03879152]] (5882, 512)\n",
      "248/248 [==============================] - 0s 2ms/step\n",
      "[[-0.01410007  0.05063264 -0.02117831 ... -0.01264011 -0.09523503\n",
      "   0.00427865]\n",
      " [-0.01410007  0.05063264 -0.02117831 ... -0.01264011 -0.09523503\n",
      "   0.00427865]\n",
      " [-0.01410007  0.05063264 -0.02117831 ... -0.01264011 -0.09523503\n",
      "   0.00427865]\n",
      " ...\n",
      " [ 0.00508688  0.04687088 -0.0544543  ...  0.00142347 -0.08027478\n",
      "   0.04780965]\n",
      " [ 0.00508688  0.04687088 -0.0544543  ...  0.00142347 -0.08027478\n",
      "   0.04780965]\n",
      " [ 0.00508688  0.04687088 -0.0544543  ...  0.00142347 -0.08027478\n",
      "   0.04780965]] (7913, 512)\n"
     ]
    }
   ],
   "source": [
    "train_attributes_2 = model0.predict(train_attributes)\n",
    "print(train_attributes_2, train_attributes_2.shape)\n",
    "\n",
    "test_seen_attributes_2 = model0.predict(test_seen_attributes)\n",
    "print(test_seen_attributes_2, test_seen_attributes_2.shape)\n",
    "\n",
    "test_unseen_attributes_2 = model0.predict(test_unseen_attributes)\n",
    "print(test_unseen_attributes_2, test_unseen_attributes_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1457e426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 2ms/step\n",
      "[[ 0.0130647   0.01747853 -0.06084995 ... -0.02515454 -0.06713821\n",
      "   0.03874364]\n",
      " [-0.02600192  0.03353297 -0.05538204 ... -0.00544162 -0.07287036\n",
      "   0.01002369]\n",
      " [-0.04828655  0.04934646 -0.03451646 ...  0.00868427 -0.09724176\n",
      "   0.04402236]\n",
      " ...\n",
      " [-0.04771004 -0.00987042 -0.03768729 ... -0.01553071 -0.08329649\n",
      "   0.05606448]\n",
      " [ 0.02516608 -0.00200605 -0.08214919 ... -0.01267577 -0.07438489\n",
      "   0.05249437]\n",
      " [-0.04149442  0.03858314 -0.03490333 ... -0.00849677 -0.07242228\n",
      "   0.02518131]] (50, 512)\n",
      "[[ 0.0130647  -0.02600192 -0.04828655 ... -0.04771004  0.02516608\n",
      "  -0.04149442]\n",
      " [ 0.01747853  0.03353297  0.04934646 ... -0.00987042 -0.00200605\n",
      "   0.03858314]\n",
      " [-0.06084995 -0.05538204 -0.03451646 ... -0.03768729 -0.08214919\n",
      "  -0.03490333]\n",
      " ...\n",
      " [-0.02515454 -0.00544162  0.00868427 ... -0.01553071 -0.01267577\n",
      "  -0.00849677]\n",
      " [-0.06713821 -0.07287036 -0.09724176 ... -0.08329649 -0.07438489\n",
      "  -0.07242228]\n",
      " [ 0.03874364  0.01002369  0.04402236 ...  0.05606448  0.05249437\n",
      "   0.02518131]] (512, 50)\n",
      "Signature for trainval: (512, 40)\n",
      "Signature for test seen: (512, 40)\n",
      "Signature for test unseen: (512, 10)\n"
     ]
    }
   ],
   "source": [
    "# as labels range from 1 to 50, we have subtract 1\n",
    "attribute_2 = model0.predict(attribute_new)\n",
    "print(attribute_2, attribute_2.shape)\n",
    "\n",
    "signature_2 = attribute_2.transpose()\n",
    "print(signature_2, signature_2.shape)#(50, 300)\n",
    "\n",
    "trainval_sig = signature_2[:, (unique_labels_trainval)-1]\n",
    "test_seen_sig = signature_2[:, (unique_labels_test_seen)-1]\n",
    "test_unseen_sig = signature_2[:, (unique_labels_test_unseen)-1]\n",
    "\n",
    "print(\"Signature for trainval:\", trainval_sig.shape)\n",
    "print(\"Signature for test seen:\", test_seen_sig.shape)\n",
    "print(\"Signature for test unseen:\", test_unseen_sig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "581a4c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34]\n",
      " [19]\n",
      " [34]\n",
      " ...\n",
      " [32]\n",
      " [16]\n",
      " [37]] (23527, 1)\n",
      "[[19]\n",
      " [39]\n",
      " [11]\n",
      " ...\n",
      " [20]\n",
      " [12]\n",
      " [22]] (5882, 1)\n",
      "[[4]\n",
      " [4]\n",
      " [4]\n",
      " ...\n",
      " [8]\n",
      " [8]\n",
      " [8]] (7913, 1)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] (40,)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] (40,)\n",
      "[0 1 2 3 4 5 6 7 8 9] (10,)\n"
     ]
    }
   ],
   "source": [
    "# by doing this modification, we are changing the range of trainval and test seen labels from 0 to 39 \n",
    "# and test unseen labels from 0 to 9\n",
    "\n",
    "k = 0\n",
    "new_labels_trainval = np.zeros((len(labels_trainval), 1), dtype = 'int')\n",
    "for labels in unique_labels_trainval:\n",
    "    new_labels_trainval[labels_trainval == labels] = k\n",
    "    k = k+1\n",
    "    \n",
    "print(new_labels_trainval, new_labels_trainval.shape)#(23527, 1)\n",
    "\n",
    "l = 0\n",
    "new_labels_test_seen = np.zeros((len(labels_test_seen), 1), dtype = 'int')\n",
    "for labels in unique_labels_test_seen:\n",
    "    new_labels_test_seen[labels_test_seen == labels] = l\n",
    "    l = l+1\n",
    "    \n",
    "print(new_labels_test_seen, new_labels_test_seen.shape)# (5882, 1)\n",
    "\n",
    "m = 0\n",
    "new_labels_test_unseen = np.zeros((len(labels_test_unseen), 1), dtype = 'int')\n",
    "for labels in unique_labels_test_unseen:\n",
    "    new_labels_test_unseen[labels_test_unseen == labels] = m\n",
    "    m = m+1  \n",
    "\n",
    "print(new_labels_test_unseen, new_labels_test_unseen.shape) #  (7913, 1)  \n",
    "\n",
    "\n",
    "print(np.unique(new_labels_trainval), np.unique(new_labels_trainval).shape)\n",
    "\n",
    "print(np.unique(new_labels_test_seen), np.unique(new_labels_test_seen).shape)\n",
    "\n",
    "print(np.unique(new_labels_test_unseen), np.unique(new_labels_test_unseen).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fee1341e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23527\n",
      "40\n",
      "5882\n",
      "40\n",
      "7913\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#params for trainval and test set\n",
    "m_trainval = new_labels_trainval.shape[0]# number of instances in training set: 23527\n",
    "print(m_trainval)\n",
    "\n",
    "z_trainval = len(unique_labels_trainval)# number of classes in training set: 40\n",
    "print(z_trainval)\n",
    "\n",
    "\n",
    "n_test_seen = new_labels_test_seen.shape[0]# 5882\n",
    "print(n_test_seen)\n",
    "\n",
    "z1_test_seen = len(unique_labels_test_seen)# 40\n",
    "print(z1_test_seen)\n",
    "\n",
    "\n",
    "n_test_unseen = new_labels_test_unseen.shape[0]# 7913\n",
    "print(n_test_unseen)\n",
    "\n",
    "z1_test_unseen = len(unique_labels_test_unseen)# 10\n",
    "print(z1_test_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "845b8e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]] (23527, 40)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "gt_trainval = to_categorical(new_labels_trainval, z_trainval)\n",
    "\n",
    "print(gt_trainval, gt_trainval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "08067319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n",
      "512\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "input1_shape = trainval_vec.shape[1]\n",
    "print(input1_shape)\n",
    "\n",
    "attribute_shape = trainval_sig.shape[0]\n",
    "print(attribute_shape)\n",
    "\n",
    "output_shape = z_trainval\n",
    "print(output_shape)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "90ffb297",
   "metadata": {},
   "source": [
    "\tStep 5 - Define 'model2' for attribute to class label mapping\n",
    "\t\t Define 'model1' for visual feature to class label mapping\n",
    "\t\t Train 'model2' and 'model1' through the iterative process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96792076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1, 1, 512)]       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 40)                20520     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,520\n",
      "Trainable params: 20,520\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from keras.optimizers import SGD, Adam, Adagrad\n",
    "\n",
    "# define model2 for attribute to class label mapping\n",
    "\n",
    "input2 = Input(shape = (1, 1, attribute_shape))\n",
    "flat = Flatten()(input2)\n",
    "output = Dense(output_shape, name=\"output\", activation='softmax')(flat)\n",
    "\n",
    "model2 = Model(inputs = input2, outputs = output)\n",
    "\n",
    "#sgd = SGD(learning_rate = 1e-2, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "opt = Adam(learning_rate = 1e-2, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0001)\n",
    "\n",
    "model2.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b285876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1, 1, 2048)]      0         \n",
      "                                                                 \n",
      " intermediate (Conv1D)       (None, 1, 1, 512)         1049088   \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 40)                20520     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069,608\n",
      "Trainable params: 1,069,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model1 for resnet feature to class label mapping\n",
    "\n",
    "input1 = Input(shape = (1,1, input1_shape))\n",
    "#inter_pre = Dense(512, name=\"intermediate_previous\", activation='relu')(input1)\n",
    "inter = Conv1D(attribute_shape, kernel_size = 1, name = \"intermediate\", activation = 'linear')(input1)\n",
    "flat = Flatten()(inter)\n",
    "output = Dense(output_shape, name=\"output\", activation='softmax')(flat)\n",
    "\n",
    "model1 = Model(inputs = input1, outputs = output)\n",
    "\n",
    "opt = Adam(learning_rate = 1e-2, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0001)\n",
    "\n",
    "model1.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9fd4ac3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23527, 1, 1, 2048)\n",
      "(23527, 1, 1, 512)\n",
      "(23527, 40)\n"
     ]
    }
   ],
   "source": [
    "trainval_input1 = np.reshape(trainval_vec, [trainval_vec.shape[0], 1, 1, trainval_vec.shape[1]])\n",
    "print(trainval_input1.shape)\n",
    "\n",
    "trainval_input2 = np.reshape(train_attributes_2, [train_attributes_2.shape[0], 1, 1, train_attributes_2.shape[1]])\n",
    "print(trainval_input2.shape)\n",
    "\n",
    "trainval_output = gt_trainval\n",
    "print(trainval_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cec915dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "batch_size = 16\n",
    "from sklearn.model_selection import train_test_split    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7be0da5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train1, X_val1, y_train1, y_val1 = train_test_split(trainval_input1, trainval_output, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#train_gen1 = DataGenerator(X_train1, y_train1, batch_size)   \n",
    "#val_gen1 = DataGenerator(X_val1, y_val1, batch_size)\n",
    "\n",
    "\n",
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(trainval_input2, trainval_output, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#train_gen2 = DataGenerator(X_train2, y_train2, batch_size)   \n",
    "#val_gen2 = DataGenerator(X_val2, y_val2, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f527990a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n",
      "model 2 is trained: training acc: 0.78125 , training loss: 1.9420372247695923 , validation acc: 0.625 , validation_loss: 2.0276763439178467\n",
      "model 1 is trained: training acc: 0.96875 , training loss: 2.11771297454834 , validation acc: 0.9375 , validation_loss: 8.198973655700684\n",
      "micro average\n",
      "seen accuracy: 72.5124664748783 unseen accuracy: 46.919979625341384 harmonic mean: 56.974190191659844\n",
      "macro average\n",
      "seen accuracy: 78.18769126147569 unseen accuracy: 36.64855301402755 harmonic mean: 49.905250146740805\n",
      "best accuracy micro seen accuracy: 72.5124664748783 unseen accuracy: 46.919979625341384 harmonic mean: 56.974190191659844\n",
      "best accuracy macro seen accuracy: 78.18769126147569 unseen accuracy: 36.64855301402755 harmonic mean: 49.905250146740805\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 1\n",
      "model 2 is trained: training acc: 0.8333333134651184 , training loss: 1.2243871688842773 , validation acc: 0.8125 , validation_loss: 1.4613722562789917\n",
      "model 1 is trained: training acc: 1.0 , training loss: 0.0 , validation acc: 0.8125 , validation_loss: 109.89424133300781\n",
      "micro average\n",
      "seen accuracy: 75.47210004732932 unseen accuracy: 48.15541687897782 harmonic mean: 58.79581715901454\n",
      "macro average\n",
      "seen accuracy: 80.80584835090106 unseen accuracy: 41.95627448502464 harmonic mean: 55.23385023142534\n",
      "best accuracy micro seen accuracy: 75.47210004732932 unseen accuracy: 48.15541687897782 harmonic mean: 58.79581715901454\n",
      "best accuracy macro seen accuracy: 80.80584835090106 unseen accuracy: 41.95627448502464 harmonic mean: 55.23385023142534\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 2\n",
      "model 2 is trained: training acc: 1.0 , training loss: 0.7068501114845276 , validation acc: 1.0 , validation_loss: 0.7589370012283325\n",
      "model 1 is trained: training acc: 0.96875 , training loss: 6.808990478515625 , validation acc: 0.875 , validation_loss: 17.302322387695312\n",
      "micro average\n",
      "seen accuracy: 78.35391183644379 unseen accuracy: 43.18535830928726 harmonic mean: 55.681455936568824\n",
      "macro average\n",
      "seen accuracy: 83.13498809928596 unseen accuracy: 36.95185138379881 harmonic mean: 51.162837464323694\n",
      "best accuracy micro seen accuracy: 75.47210004732932 unseen accuracy: 48.15541687897782 harmonic mean: 58.79581715901454\n",
      "best accuracy macro seen accuracy: 80.80584835090106 unseen accuracy: 41.95627448502464 harmonic mean: 55.23385023142534\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 3\n",
      "model 2 is trained: training acc: 0.96875 , training loss: 0.4942851662635803 , validation acc: 1.0 , validation_loss: 0.34460651874542236\n",
      "model 1 is trained: training acc: 0.953125 , training loss: 25.947528839111328 , validation acc: 0.9375 , validation_loss: 14.592788696289062\n",
      "micro average\n",
      "seen accuracy: 78.10898358973766 unseen accuracy: 48.21926116420521 harmonic mean: 59.628113828703\n",
      "macro average\n",
      "seen accuracy: 82.19993199591975 unseen accuracy: 46.429925439150765 harmonic mean: 59.341381383405796\n",
      "best accuracy micro seen accuracy: 78.10898358973766 unseen accuracy: 48.21926116420521 harmonic mean: 59.628113828703\n",
      "best accuracy macro seen accuracy: 82.19993199591975 unseen accuracy: 46.429925439150765 harmonic mean: 59.341381383405796\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 4\n",
      "model 2 is trained: training acc: 0.984375 , training loss: 0.37677037715911865 , validation acc: 1.0 , validation_loss: 0.3885567784309387\n",
      "model 1 is trained: training acc: 1.0 , training loss: 0.0 , validation acc: 0.9375 , validation_loss: 52.94340515136719\n",
      "micro average\n",
      "seen accuracy: 79.75861378668405 unseen accuracy: 56.39719479340932 harmonic mean: 66.07374485288871\n",
      "macro average\n",
      "seen accuracy: 84.47806868412104 unseen accuracy: 51.59863515733603 harmonic mean: 64.06611744368752\n",
      "best accuracy micro seen accuracy: 79.75861378668405 unseen accuracy: 56.39719479340932 harmonic mean: 66.07374485288871\n",
      "best accuracy macro seen accuracy: 84.47806868412104 unseen accuracy: 51.59863515733603 harmonic mean: 64.06611744368752\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 5\n",
      "model 2 is trained: training acc: 1.0 , training loss: 0.33718520402908325 , validation acc: 1.0 , validation_loss: 0.3150818943977356\n",
      "model 1 is trained: training acc: 0.984375 , training loss: 14.670753479003906 , validation acc: 0.875 , validation_loss: 50.234527587890625\n",
      "micro average\n",
      "seen accuracy: 82.80400771560397 unseen accuracy: 54.590065482455806 harmonic mean: 65.8001629646486\n",
      "macro average\n",
      "seen accuracy: 84.95409724583475 unseen accuracy: 46.07607734108429 harmonic mean: 59.747330223459144\n",
      "best accuracy micro seen accuracy: 79.75861378668405 unseen accuracy: 56.39719479340932 harmonic mean: 66.07374485288871\n",
      "best accuracy macro seen accuracy: 84.47806868412104 unseen accuracy: 51.59863515733603 harmonic mean: 64.06611744368752\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 6\n",
      "model 2 is trained: training acc: 0.96875 , training loss: 0.36612093448638916 , validation acc: 1.0 , validation_loss: 0.27056774497032166\n",
      "model 1 is trained: training acc: 1.0 , training loss: 0.0 , validation acc: 1.0 , validation_loss: 0.0\n",
      "micro average\n",
      "seen accuracy: 82.72086571733523 unseen accuracy: 48.86984930831271 harmonic mean: 61.44135992378218\n",
      "macro average\n",
      "seen accuracy: 87.0452227133628 unseen accuracy: 40.41450777202073 harmonic mean: 55.20001990385333\n",
      "best accuracy micro seen accuracy: 79.75861378668405 unseen accuracy: 56.39719479340932 harmonic mean: 66.07374485288871\n",
      "best accuracy macro seen accuracy: 84.47806868412104 unseen accuracy: 51.59863515733603 harmonic mean: 64.06611744368752\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 7\n",
      "model 2 is trained: training acc: 1.0 , training loss: 0.3290015161037445 , validation acc: 1.0 , validation_loss: 0.30782389640808105\n",
      "model 1 is trained: training acc: 0.953125 , training loss: 2.3026156425476074 , validation acc: 1.0 , validation_loss: 0.0\n",
      "micro average\n",
      "seen accuracy: 81.72364854837426 unseen accuracy: 49.22550995156375 harmonic mean: 61.44198742442473\n",
      "macro average\n",
      "seen accuracy: 85.14110846650799 unseen accuracy: 42.63869581700999 harmonic mean: 56.821276973809745\n",
      "best accuracy micro seen accuracy: 79.75861378668405 unseen accuracy: 56.39719479340932 harmonic mean: 66.07374485288871\n",
      "best accuracy macro seen accuracy: 84.47806868412104 unseen accuracy: 51.59863515733603 harmonic mean: 64.06611744368752\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 8\n",
      "model 2 is trained: training acc: 1.0 , training loss: 0.25208723545074463 , validation acc: 1.0 , validation_loss: 0.24957731366157532\n",
      "model 1 is trained: training acc: 0.96875 , training loss: 5.937103271484375 , validation acc: 0.9375 , validation_loss: 26.843780517578125\n",
      "micro average\n",
      "seen accuracy: 82.14704034623891 unseen accuracy: 50.16784285668528 harmonic mean: 62.29291386535149\n",
      "macro average\n",
      "seen accuracy: 86.33117987079225 unseen accuracy: 43.839251864021236 harmonic mean: 58.149831534461796\n",
      "best accuracy micro seen accuracy: 79.75861378668405 unseen accuracy: 56.39719479340932 harmonic mean: 66.07374485288871\n",
      "best accuracy macro seen accuracy: 84.47806868412104 unseen accuracy: 51.59863515733603 harmonic mean: 64.06611744368752\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 9\n",
      "model 2 is trained: training acc: 1.0 , training loss: 0.26108038425445557 , validation acc: 1.0 , validation_loss: 0.26524677872657776\n",
      "model 1 is trained: training acc: 0.953125 , training loss: 15.981498718261719 , validation acc: 1.0 , validation_loss: 0.0\n",
      "micro average\n",
      "seen accuracy: 81.50776453072994 unseen accuracy: 46.545492217351494 harmonic mean: 59.25376856415876\n",
      "macro average\n",
      "seen accuracy: 85.75314518871131 unseen accuracy: 43.46012890180715 harmonic mean: 57.68513753511102\n",
      "best accuracy micro seen accuracy: 79.75861378668405 unseen accuracy: 56.39719479340932 harmonic mean: 66.07374485288871\n",
      "best accuracy macro seen accuracy: 84.47806868412104 unseen accuracy: 51.59863515733603 harmonic mean: 64.06611744368752\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 10\n",
      "model 2 is trained: training acc: 1.0 , training loss: 0.23430000245571136 , validation acc: 1.0 , validation_loss: 0.2517252564430237\n",
      "model 1 is trained: training acc: 1.0 , training loss: 0.0 , validation acc: 0.9375 , validation_loss: 38.186431884765625\n",
      "micro average\n",
      "seen accuracy: 83.23567926272668 unseen accuracy: 48.756130576831936 harmonic mean: 61.492446413421725\n",
      "macro average\n",
      "seen accuracy: 87.0792247534852 unseen accuracy: 43.78870213572602 harmonic mean: 58.27380819088463\n",
      "best accuracy micro seen accuracy: 79.75861378668405 unseen accuracy: 56.39719479340932 harmonic mean: 66.07374485288871\n",
      "best accuracy macro seen accuracy: 84.47806868412104 unseen accuracy: 51.59863515733603 harmonic mean: 64.06611744368752\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 11\n",
      "model 2 is trained: training acc: 0.984375 , training loss: 0.25435951352119446 , validation acc: 1.0 , validation_loss: 0.219468355178833\n",
      "model 1 is trained: training acc: 0.984375 , training loss: 11.582260131835938 , validation acc: 0.875 , validation_loss: 123.67599487304688\n",
      "micro average\n",
      "seen accuracy: 85.62431631120975 unseen accuracy: 48.13597140234826 harmonic mean: 61.626805859273674\n",
      "macro average\n",
      "seen accuracy: 89.03434206052363 unseen accuracy: 45.92442815619866 harmonic mean: 60.59407978935923\n",
      "best accuracy micro seen accuracy: 79.75861378668405 unseen accuracy: 56.39719479340932 harmonic mean: 66.07374485288871\n",
      "best accuracy macro seen accuracy: 84.47806868412104 unseen accuracy: 51.59863515733603 harmonic mean: 64.06611744368752\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 12\n",
      "model 2 is trained: training acc: 1.0 , training loss: 0.24235908687114716 , validation acc: 1.0 , validation_loss: 0.15248316526412964\n",
      "model 1 is trained: training acc: 1.0 , training loss: 0.0 , validation acc: 0.9375 , validation_loss: 293.39361572265625\n",
      "micro average\n",
      "seen accuracy: 84.04290147787314 unseen accuracy: 43.82012343068033 harmonic mean: 57.60493025824773\n",
      "macro average\n",
      "seen accuracy: 87.98027881672901 unseen accuracy: 40.67989384557058 harmonic mean: 55.63537384894209\n",
      "best accuracy micro seen accuracy: 79.75861378668405 unseen accuracy: 56.39719479340932 harmonic mean: 66.07374485288871\n",
      "best accuracy macro seen accuracy: 84.47806868412104 unseen accuracy: 51.59863515733603 harmonic mean: 64.06611744368752\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 13\n",
      "model 2 is trained: training acc: 1.0 , training loss: 0.20788444578647614 , validation acc: 1.0 , validation_loss: 0.1772499978542328\n",
      "model 1 is trained: training acc: 0.984375 , training loss: 24.08831024169922 , validation acc: 0.8125 , validation_loss: 164.08834838867188\n",
      "micro average\n",
      "seen accuracy: 85.7045086446354 unseen accuracy: 54.56874059014706 harmonic mean: 66.6810974315901\n",
      "macro average\n",
      "seen accuracy: 88.94933696021762 unseen accuracy: 49.66510805004423 harmonic mean: 63.74052041664133\n",
      "best accuracy micro seen accuracy: 85.7045086446354 unseen accuracy: 54.56874059014706 harmonic mean: 66.6810974315901\n",
      "best accuracy macro seen accuracy: 84.47806868412104 unseen accuracy: 51.59863515733603 harmonic mean: 64.06611744368752\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 14\n",
      "model 2 is trained: training acc: 1.0 , training loss: 0.1720423698425293 , validation acc: 1.0 , validation_loss: 0.18093563616275787\n",
      "model 1 is trained: training acc: 1.0 , training loss: 0.0 , validation acc: 0.9375 , validation_loss: 54.032012939453125\n",
      "micro average\n",
      "seen accuracy: 83.92985822394068 unseen accuracy: 48.30382689114935 harmonic mean: 61.31770946441385\n",
      "macro average\n",
      "seen accuracy: 87.91227473648419 unseen accuracy: 45.70959181094402 harmonic mean: 60.146356239529716\n",
      "best accuracy micro seen accuracy: 85.7045086446354 unseen accuracy: 54.56874059014706 harmonic mean: 66.6810974315901\n",
      "best accuracy macro seen accuracy: 84.47806868412104 unseen accuracy: 51.59863515733603 harmonic mean: 64.06611744368752\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "iteration = 15\n",
    "epochs1 = 100\n",
    "epochs2 = 200\n",
    "\n",
    "best_performance_micro = [0, 0, 0]\n",
    "best_performance_macro = [0, 0, 0]\n",
    "\n",
    "save_path = 'C:/Users/Admin/Sushree_Codes/Sush_3/Results/'\n",
    "name = 'model1_conv_AWA2_NewattT_m3_512_lin_it15_100eph_adam_cce_16bch_1e-2lr_model2_adam_lr-2_200'\n",
    "\n",
    "for i in range(iteration):\n",
    "    X_train2_it = X_train2[(len(X_train2)//iteration)*i:(len(X_train2)//iteration)*(i+1)]\n",
    "    X_val2_it = X_val2[(len(X_val2)//iteration)*i:(len(X_val2)//iteration)*(i+1)]\n",
    "    y_train2_it = y_train2[(len(y_train2)//iteration)*i:(len(y_train2)//iteration)*(i+1)]\n",
    "    y_val2_it = y_val2[(len(y_val2)//iteration)*i:(len(y_val2)//iteration)*(i+1)]\n",
    "    \n",
    "    train_gen2 = DataGenerator(X_train2_it, y_train2_it, batch_size)   \n",
    "    val_gen2 = DataGenerator(X_val2_it, y_val2_it, batch_size)\n",
    "\n",
    "    train_summary2 = model2.fit(train_gen2, epochs = epochs2, verbose = 0, callbacks = None, validation_data = val_gen2, \n",
    "                              shuffle = True, steps_per_epoch = len(train_gen2)//batch_size, \n",
    "                              validation_steps = len(val_gen2)//batch_size)\n",
    "\n",
    "    print(\"iteration:\", i)\n",
    "    print('model 2 is trained:', 'training acc:', train_summary2.history['accuracy'][-1], ',',  \n",
    "          'training loss:', train_summary2.history['loss'][-1], ',', \n",
    "          'validation acc:', train_summary2.history['val_accuracy'][-1], ',',\n",
    "         'validation_loss:', train_summary2.history['val_loss'][-1])\n",
    "\n",
    "    weights_list2 = model2.get_weights()\n",
    "    #print(weights_list2)\n",
    "\n",
    "    model1.layers[-1].set_weights(weights_list2)\n",
    "\n",
    "    X_train1_it = X_train1[(len(X_train1)//iteration)*i:(len(X_train1)//iteration)*(i+1)]\n",
    "    X_val1_it = X_val1[(len(X_val1)//iteration)*i:(len(X_val1)//iteration)*(i+1)]\n",
    "    y_train1_it = y_train1[(len(y_train1)//iteration)*i:(len(y_train1)//iteration)*(i+1)]\n",
    "    y_val1_it = y_val1[(len(y_val1)//iteration)*i:(len(y_val1)//iteration)*(i+1)]\n",
    "    \n",
    "    train_gen1 = DataGenerator(X_train1_it, y_train1_it, batch_size)   \n",
    "    val_gen1 = DataGenerator(X_val1_it, y_val1_it, batch_size)\n",
    "    \n",
    "    for layer in model1.layers[2:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    train_summary1 = model1.fit(train_gen1, epochs = epochs1, verbose = 0, callbacks = None, validation_data = val_gen1, \n",
    "                              shuffle = True, steps_per_epoch = len(train_gen1)//batch_size, \n",
    "                              validation_steps = len(val_gen1)//batch_size)\n",
    "    \n",
    "    #print(\"iteration:\", i)\n",
    "    print('model 1 is trained:', 'training acc:', train_summary1.history['accuracy'][-1], ',',  \n",
    "          'training loss:', train_summary1.history['loss'][-1], ',', \n",
    "          'validation acc:', train_summary1.history['val_accuracy'][-1], ',',\n",
    "         'validation_loss:', train_summary1.history['val_loss'][-1])\n",
    "    \n",
    "    weights_list1 = Model(inputs = model1.input, outputs = model1.layers[-1].output).get_weights()\n",
    "    \n",
    "    #predictions\n",
    "    #outputs_seen = np.matmul(np.matmul(test_seen_vec, np.matmul(weights_list1[0], weights_list1[2])), test_seen_sig)\n",
    "    #outputs_seen = np.matmul(np.matmul(test_seen_vec, weights_list1[0]), test_seen_sig)\n",
    "    \n",
    "    outputs_seen = np.matmul(np.matmul(test_seen_vec, weights_list1[0][0]), test_seen_sig)\n",
    "    preds_seen = np.array([np.argmax(output) for output in outputs_seen])\n",
    "    \n",
    "    cm_seen = confusion_matrix(new_labels_test_seen, preds_seen)\n",
    "    #print(cm)\n",
    "    # Compute macro average (averaging performance metrics by first calculating the metric separately for each class and \n",
    "    # then averaging these class-specific metrics)\n",
    "    cm_seen_micro = cm_seen.astype('float') / cm_seen.sum(axis=1)[:, np.newaxis]\n",
    "    #print(cm)\n",
    "    avg_seen_micro = (sum(cm_seen_micro.diagonal())/len(unique_labels_test_seen))*100\n",
    "\n",
    "    avg_seen_macro = (sum(cm_seen.diagonal())/len(new_labels_test_seen))*100\n",
    "    \n",
    "    #predictions\n",
    "    #outputs_unseen = np.matmul(np.matmul(test_unseen_vec, weights_list1[0]), test_unseen_sig)\n",
    "    outputs_unseen = np.matmul(np.matmul(test_unseen_vec, weights_list1[0][0]), test_unseen_sig)\n",
    "    \n",
    "    preds_unseen = np.array([np.argmax(output) for output in outputs_unseen])\n",
    "    \n",
    "    cm_unseen = confusion_matrix(new_labels_test_unseen, preds_unseen)\n",
    "    # Compute macro average (averaging performance metrics by first calculating the metric separately for each class and \n",
    "    # then averaging these class-specific metrics)\n",
    "    cm_unseen_micro = cm_unseen.astype('float') / cm_unseen.sum(axis=1)[:, np.newaxis]\n",
    "    avg_unseen_micro = (sum(cm_unseen_micro.diagonal())/len(unique_labels_test_unseen))*100\n",
    "\n",
    "    avg_unseen_macro = (sum(cm_unseen.diagonal())/len(new_labels_test_unseen))*100\n",
    "    \n",
    "    harmonic_micro = (2*avg_seen_micro*avg_unseen_micro) / (avg_seen_micro + avg_unseen_micro)\n",
    "    harmonic_macro = (2*avg_seen_macro*avg_unseen_macro) / (avg_seen_macro + avg_unseen_macro)\n",
    "    \n",
    "    print('micro average')\n",
    "    print('seen accuracy:', avg_seen_micro, 'unseen accuracy:', avg_unseen_micro, 'harmonic mean:', harmonic_micro)\n",
    "    \n",
    "    print('macro average')\n",
    "    print('seen accuracy:', avg_seen_macro, 'unseen accuracy:', avg_unseen_macro, 'harmonic mean:', harmonic_macro)\n",
    "    \n",
    "    if harmonic_micro > best_performance_micro[2]:\n",
    "        best_performance_micro = [avg_seen_micro, avg_unseen_micro, harmonic_micro]\n",
    "        model1.save_weights(save_path + 'bw_micro_' + name + '.h5', overwrite=True)\n",
    "        \n",
    "    if harmonic_macro > best_performance_macro[2]:\n",
    "        best_performance_macro = [avg_seen_macro, avg_unseen_macro, harmonic_macro]\n",
    "        model1.save_weights(save_path + 'bw_macro_' + name + '.h5', overwrite=True)\n",
    "        \n",
    "    print('best accuracy micro','seen accuracy:', best_performance_micro[0], 'unseen accuracy:', best_performance_micro[1], 'harmonic mean:', best_performance_micro[2])\n",
    "    print('best accuracy macro', 'seen accuracy:', best_performance_macro[0], 'unseen accuracy:', best_performance_macro[1], 'harmonic mean:', best_performance_macro[2])\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    weights_list3 = model1.get_weights()\n",
    "    model2.set_weights(weights_list3[2:])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7160e6b1",
   "metadata": {},
   "source": [
    "\tStep 6 - Evaluate for seen and unseen categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "58bc47e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] (5882, 40)\n",
      "184/184 [==============================] - 0s 2ms/step - loss: 119.0042 - accuracy: 0.9097\n",
      "cce =  1.4455851\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 0.2254 - accuracy: 0.9866\n",
      "cce =  0.22538011\n"
     ]
    }
   ],
   "source": [
    "gt_test_seen = to_categorical(new_labels_test_seen, z1_test_seen)\n",
    "\n",
    "print(gt_test_seen, gt_test_seen.shape)\n",
    "\n",
    "test_seen_vec = np.reshape(test_seen_vec, [test_seen_vec.shape[0], 1, 1, test_seen_vec.shape[1]])\n",
    "res1 = model1.evaluate(test_seen_vec, gt_test_seen)\n",
    "\n",
    "p = model1.predict(test_seen_vec, verbose = 0)\n",
    "\n",
    "import tensorflow\n",
    "cce = tensorflow.keras.losses.CategoricalCrossentropy()\n",
    "print('cce = ', cce(gt_test_seen, p).numpy())\n",
    "\n",
    "\n",
    "test_seen_attributes_2 = np.reshape(test_seen_attributes_2, [test_seen_attributes_2.shape[0], 1, 1, test_seen_attributes_2.shape[1]])\n",
    "\n",
    "res2 = model2.evaluate(test_seen_attributes_2, gt_test_seen)\n",
    "\n",
    "p = model2.predict(test_seen_attributes_2, verbose = 0)\n",
    "\n",
    "import tensorflow\n",
    "cce = tensorflow.keras.losses.CategoricalCrossentropy()\n",
    "print('cce = ', cce(gt_test_seen, p).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe3280c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.21881570794042\n",
      "94.81468796730042\n",
      "69.27132349077378\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy_seen_updated = res1[1]*100\n",
    "unseen_accuracy = 54.57\n",
    "h = (2*accuracy_seen_updated*unseen_accuracy) / (accuracy_seen_updated + unseen_accuracy)\n",
    "print(h)\n",
    "\n",
    "\n",
    "accuracy_seen_updated2 = ((res1[1]*100)+(res2[1]*100))/2\n",
    "print(accuracy_seen_updated2)\n",
    "h = (2*accuracy_seen_updated2*unseen_accuracy) / (accuracy_seen_updated2 + unseen_accuracy)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a7e6f1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
