{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d6e42e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e42017e8",
   "metadata": {},
   "source": [
    "GZSL_AWA2_4: Experiments with New attributes, w2v is replaced by Bert (New attribute length = 85*embedding length, then transform it to length 512)\n",
    "\tStep 1 - Class wise continous attributes are extracted\n",
    "\tStep 2 - Word vectors are extracted for each semantic attribute using pretrained language models (Bert) \n",
    "                 New attributes are formed by aggregating the continous attribute values and word vectors\n",
    "\tStep 3 - Visual features are extracted from pre-trained ResNet101 (without finetuning)\n",
    "\tStep 4 - Visual features are transformed into lower dimensional space using 'model00' (optional)\n",
    "\tStep 5 - New attribute vectors are transformed into a lower dimensional space using 'model0'\n",
    "\tStep 6 - Define 'model2' for attribute to class label mapping\n",
    "\t\t Define 'model1' for visual feature to class label mapping\n",
    "\t\t Train 'model2' and 'model1' through the iterative process\n",
    "\tStep 7 - Evaluate for seen and unseen categories\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64bb0868",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please add the folder name of the dataset to run it on different dataset.\n",
    "dataset = 'AWA2'\n",
    "path = 'E:/Sushree/Dataset/data/xlsa17/data/'\n",
    "\n",
    "res101 = scipy.io.loadmat(path + dataset + '/res101.mat')\n",
    "att_splits = scipy.io.loadmat(path + dataset + '/att_splits.mat')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d850dce",
   "metadata": {},
   "source": [
    "Step 1 - Class wise continous attributes are extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6082508e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(85, 50)\n",
      "[[0.         0.         0.         ... 0.00882092 0.03640974 0.03145501]\n",
      " [0.12045618 0.00426584 0.         ... 0.17996306 0.0618086  0.03495531]\n",
      " [0.26584459 0.20652363 0.         ... 0.05026822 0.04274552 0.04915256]\n",
      " ...\n",
      " [0.22516498 0.15266022 0.         ... 0.12733492 0.10009694 0.01771   ]\n",
      " [0.19613947 0.1966714  0.         ... 0.01787277 0.06698743 0.25883601]\n",
      " [0.03819588 0.08046548 0.10363715 ... 0.01479997 0.05250999 0.14194515]] (50, 85)\n"
     ]
    }
   ],
   "source": [
    "signature = att_splits['att']\n",
    "#signature = att_splits['original_att']\n",
    "#signature = signature/100\n",
    "print(signature.shape) #(85, 50)\n",
    "\n",
    "attribute = signature.transpose()\n",
    "attribute[attribute<0] = 0\n",
    "print(attribute, attribute.shape)#(50, 85)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8090ce0e",
   "metadata": {},
   "source": [
    "Step 2 - Word vectors are extracted for each semantic attribute using pretrained language models (Bert) \n",
    "                 New attributes are formed by aggregating the continous attribute values and word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ab0196a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load pretrain w2v model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\en3\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the PyTorch model were not used when initializing the TF 2.0 model TFBertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight']\n",
      "- This IS expected if you are initializing TFBertModel from a PyTorch model trained on another task or with another architecture (e.g. initializing a TFBertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing TFBertModel from a PyTorch model that you expect to be exactly identical (e.g. initializing a TFBertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "All the weights of TFBertModel were initialized from the PyTorch model.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done replacing OOD words\n",
      "Done preprocessing attribute des\n",
      "black\n",
      "white\n",
      "blue\n",
      "brown\n",
      "gray\n",
      "orange\n",
      "red\n",
      "yellow\n",
      "patches\n",
      "spots\n",
      "stripes\n",
      "furry\n",
      "hairless\n",
      "tough skin\n",
      "big\n",
      "small\n",
      "bulbous\n",
      "lean\n",
      "flippers\n",
      "hands\n",
      "hooves\n",
      "pads\n",
      "paws\n",
      "long leg\n",
      "long neck\n",
      "tail\n",
      "chew teeth\n",
      "meat teeth\n",
      "buckteeth\n",
      "strain teeth\n",
      "horns\n",
      "claws\n",
      "tusks\n",
      "smelly\n",
      "flys\n",
      "hops\n",
      "swims\n",
      "tunnels\n",
      "walks\n",
      "fast\n",
      "slow\n",
      "strong\n",
      "weak\n",
      "muscle\n",
      "bipedal\n",
      "quadrupedal\n",
      "active\n",
      "inactive\n",
      "nocturnal\n",
      "hibernate\n",
      "agility\n",
      "fish\n",
      "meat\n",
      "plankton\n",
      "vegetation\n",
      "insects\n",
      "forager\n",
      "grazer\n",
      "hunter\n",
      "scavenger\n",
      "skimmer\n",
      "stalker\n",
      "new world\n",
      "old world\n",
      "arctic\n",
      "coastal\n",
      "desert\n",
      "bush\n",
      "plains\n",
      "forest\n",
      "fields\n",
      "jungle\n",
      "mountains\n",
      "ocean\n",
      "ground\n",
      "water\n",
      "tree\n",
      "cave\n",
      "fierce\n",
      "timid\n",
      "smart\n",
      "group\n",
      "solitary\n",
      "nest spot\n",
      "domestic\n",
      "counter  85\n",
      "[[ 0.15346664 -0.06185262 -0.61140162 ...  0.27451777  0.07035383\n",
      "  -0.21827152]\n",
      " [-0.12246033 -0.20419566 -0.71971899 ...  0.49881017 -0.01791931\n",
      "  -0.11089724]\n",
      " [-0.12060256 -0.24933095 -0.29174194 ...  0.22605884  0.26767644\n",
      "  -0.56125927]\n",
      " ...\n",
      " [-0.62034905 -0.26172695 -0.16961689 ...  0.25501505  0.34266904\n",
      "   0.25268397]\n",
      " [ 0.09704637  0.14363171 -0.80743253 ... -0.12237975 -0.21428932\n",
      "   0.33355671]\n",
      " [-0.91722775 -0.1039808  -0.60744339 ... -0.2960763  -0.02590791\n",
      "  -0.20444243]] (85, 768)\n"
     ]
    }
   ],
   "source": [
    "import gensim.downloader as api\n",
    "import pandas as pd\n",
    "print('Load pretrain w2v model')\n",
    "\n",
    "import transformers\n",
    "from transformers import BertTokenizer, TFBertModel\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#model = TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased')\n",
    "model = TFBertModel.from_pretrained(\"bert-large-uncased\")\n",
    "\n",
    "dim_w2v = 1024\n",
    "\n",
    "#%%\n",
    "replace_word = [('newworld','new world'),('oldworld','old world'),('nestspot','nest spot'),('toughskin','tough skin'),\n",
    "                ('longleg','long leg'), ('longneck', 'long neck'), ('chewteeth','chew teeth'),('meatteeth','meat teeth'),('strainteeth','strain teeth'),\n",
    "                ('quadrapedal','quadrupedal')]  # for AWA2\n",
    "\n",
    "\n",
    "#For AWA2\n",
    "path = 'E:/Sushree/Dataset/Animals_with_Attributes2/attribute/predicates.txt'\n",
    "df=pd.read_csv(path,sep='\\t',header = None, names = ['idx','des'])\n",
    "des = df['des'].values\n",
    "\n",
    "#%% replace out of dictionary (OOD) words\n",
    "for pair in replace_word:\n",
    "    for idx,s in enumerate(des):\n",
    "        des[idx] = s.replace(pair[0],pair[1])\n",
    "print('Done replacing OOD words')\n",
    "\n",
    "df['new_des'] = des\n",
    "df.to_csv('E:/Sushree/Dataset/Animals_with_Attributes2/attribute/new_des.csv')\n",
    "print('Done preprocessing attribute des')\n",
    "\n",
    "import pickle\n",
    "\n",
    "counter = 0\n",
    "\n",
    "w2v_att = np.zeros((signature.shape[0], dim_w2v))\n",
    "for s in des:\n",
    "    print(s)\n",
    "    w2v = np.zeros(dim_w2v)\n",
    "    encoded_input = tokenizer(s, return_tensors='tf')\n",
    "    length = encoded_input.input_ids.shape[1]\n",
    "    #print(length)\n",
    "    for i in range(length-2):\n",
    "        w2v = w2v + model(encoded_input).last_hidden_state[:, i+1, :]\n",
    "        #print(model(encoded_input).last_hidden_state[:, i+1, :][:,1:2])\n",
    "        #print(w2v[:, 1:2])\n",
    "        #print(w2v.shape)\n",
    "\n",
    "    w2v = w2v / (length - 2)\n",
    "    #print(w2v[:, 1:2])\n",
    "    w2v_att[counter] = w2v\n",
    "    counter = counter + 1\n",
    "\n",
    "print('counter ',counter)\n",
    "\n",
    "print(w2v_att, w2v_att.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5facf5d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.          0.          0.         ... -0.00931308 -0.00081493\n",
      "  -0.00643074]\n",
      " [ 0.018486   -0.00745053 -0.0736471  ... -0.01034944 -0.00090562\n",
      "  -0.00714635]\n",
      " [ 0.04079828 -0.01644319 -0.16253781 ... -0.01455291 -0.00127344\n",
      "  -0.01004887]\n",
      " ...\n",
      " [ 0.03455531 -0.01392704 -0.13766623 ... -0.00524351 -0.00045883\n",
      "  -0.00362068]\n",
      " [ 0.03010087 -0.01213174 -0.11991999 ... -0.07663521 -0.0067059\n",
      "  -0.05291706]\n",
      " [ 0.00586179 -0.00236252 -0.02335302 ... -0.04202659 -0.0036775\n",
      "  -0.02901961]] (50, 65280)\n"
     ]
    }
   ],
   "source": [
    "attribute_new = np.einsum('ij,jl->ijl', attribute, w2v_att)\n",
    "\n",
    "attribute_new = np.reshape(attribute_new, [attribute_new.shape[0], attribute_new.shape[1]* attribute_new.shape[2]])\n",
    "print(attribute_new, attribute_new.shape)\n",
    "\n",
    "#attribute_new[attribute_new<0] = 0\n",
    "#print(attribute_new, attribute_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "237b819e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    2     4     5 ... 37318 37320 37321] 37321\n",
      "[    0     1     3 ... 37306 37307 37319] 37319\n",
      "[ 1046  1047  1048 ... 35288 35289 35290] 35290\n"
     ]
    }
   ],
   "source": [
    "# total number of instances or images = 37322: ranges from 0 to 37321\n",
    "\n",
    "trainval_loc = np.squeeze(att_splits['trainval_loc']-1) # -1: to consider the overflow problem\n",
    "print(np.unique(trainval_loc), np.max(np.unique(trainval_loc))) # smallest location: 2, largest location 37321\n",
    "\n",
    "test_seen_loc = np.squeeze(att_splits['test_seen_loc']-1)\n",
    "print(np.unique(test_seen_loc), np.max(np.unique(test_seen_loc))) # smallest location: 0, largest location 37319\n",
    "\n",
    "test_unseen_loc = np.squeeze(att_splits['test_unseen_loc']-1)\n",
    "print(np.unique(test_unseen_loc), np.max(np.unique(test_unseen_loc))) # smallest location: 1046, largest location 35290\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c148c5e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels [[ 1]\n",
      " [ 1]\n",
      " [ 1]\n",
      " ...\n",
      " [38]\n",
      " [38]\n",
      " [38]] (37322, 1)\n",
      "unique_labels [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24\n",
      " 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48\n",
      " 49 50] (50,)\n",
      "labels_trainval [[43]\n",
      " [22]\n",
      " [43]\n",
      " ...\n",
      " [40]\n",
      " [19]\n",
      " [46]] (23527, 1)\n",
      "unique_labels_trainval [ 1  2  3  4  5  6  8 10 11 12 13 14 15 16 17 18 19 20 21 22 25 26 27 28\n",
      " 29 32 33 35 36 37 38 39 40 42 43 44 45 46 48 49] (40,)\n",
      "labels_test_seen [[22]\n",
      " [49]\n",
      " [14]\n",
      " ...\n",
      " [25]\n",
      " [15]\n",
      " [27]] (5882, 1)\n",
      "unique_labels_test_seen [ 1  2  3  4  5  6  8 10 11 12 13 14 15 16 17 18 19 20 21 22 25 26 27 28\n",
      " 29 32 33 35 36 37 38 39 40 42 43 44 45 46 48 49] (40,)\n",
      "labels_test_unseen [[30]\n",
      " [30]\n",
      " [30]\n",
      " ...\n",
      " [47]\n",
      " [47]\n",
      " [47]] (7913, 1)\n",
      "unique_labels_test_unseen [ 7  9 23 24 30 31 34 41 47 50] (10,)\n",
      "correct number of instances for training, test seen and test unseen categories\n",
      "Number of overlapping classes between trainval and test seen: 40\n",
      "Number of overlapping classes between trainval and test unseen: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels = res101['labels']# direct class labels\n",
    "print('labels', labels, labels.shape)# 37322 x 1\n",
    "\n",
    "print('unique_labels', np.unique(labels), np.unique(labels).shape)# class labels range from 1 to 50, 50 classes\n",
    "\n",
    "# get the labels for trainval, test seen and test unseen sets\n",
    "\n",
    "labels_trainval = labels[trainval_loc]\n",
    "print('labels_trainval', labels_trainval, labels_trainval.shape)\n",
    "\n",
    "unique_labels_trainval = np.unique(labels_trainval) # labels min:1 max:49\n",
    "print('unique_labels_trainval', unique_labels_trainval, unique_labels_trainval.shape)# 40 classes\n",
    "\n",
    "\n",
    "labels_test_seen = labels[test_seen_loc]\n",
    "print('labels_test_seen', labels_test_seen, labels_test_seen.shape)\n",
    "\n",
    "unique_labels_test_seen = np.unique(labels_test_seen) # labels min:1 max:49\n",
    "print('unique_labels_test_seen', unique_labels_test_seen, unique_labels_test_seen.shape)# 40 classes\n",
    "\n",
    "\n",
    "labels_test_unseen = labels[test_unseen_loc]\n",
    "print('labels_test_unseen', labels_test_unseen, labels_test_unseen.shape)\n",
    "\n",
    "unique_labels_test_unseen = np.unique(labels_test_unseen) # labels min:7 max:50\n",
    "print('unique_labels_test_unseen', unique_labels_test_unseen, unique_labels_test_unseen.shape)# 10 classes\n",
    "\n",
    "\n",
    "if len(labels) == len(labels_trainval) + len(labels_test_seen) + len(labels_test_unseen):\n",
    "    print('correct number of instances for training, test seen and test unseen categories')\n",
    "    \n",
    "print(\"Number of overlapping classes between trainval and test seen:\",len(set(unique_labels_trainval).intersection(set(unique_labels_test_seen))))\n",
    "\n",
    "print(\"Number of overlapping classes between trainval and test unseen:\",len(set(unique_labels_trainval).intersection(set(unique_labels_test_unseen))))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ca83ed30",
   "metadata": {},
   "source": [
    "# Step 3 - Visual features are extracted from pre-trained ResNet101 (without finetuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c88acec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for trainval: (23527, 2048)\n",
      "Features for test seen: (5882, 2048)\n",
      "Features for test unseen: (7913, 2048)\n"
     ]
    }
   ],
   "source": [
    "X_features = res101['features']\n",
    "\n",
    "# locations are already subtracted by 1, so they range from 0 to 37321\n",
    "trainval_vec = X_features[:, trainval_loc].transpose()\n",
    "test_seen_vec = X_features[:, test_seen_loc].transpose()\n",
    "test_unseen_vec = X_features[:, test_unseen_loc].transpose()\n",
    "\n",
    "print(\"Features for trainval:\", trainval_vec.shape) #(23527, 2048)\n",
    "print(\"Features for test seen:\", test_seen_vec.shape)# (5882, 2048)\n",
    "print(\"Features for test unseen:\", test_unseen_vec.shape) #(7913, 2048)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a651a471",
   "metadata": {},
   "source": [
    "Step 4 - Visual features are transformed into lower dimensional space using 'model00' (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c87a4f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from tensorflow.keras.models import Model\n",
    "#from tensorflow.keras.layers import *\n",
    "#from keras.optimizers import SGD, Adam, Adagrad\n",
    "#import keras.backend as K\n",
    "\n",
    "#inputt = Input(shape = trainval_vec.shape[1])\n",
    "#hidden = Dense(2048, name=\"layer1\", activation='linear')(inputt)\n",
    "#output = Dense(1024, name=\"layer3\", activation='linear')(hidden)\n",
    "\n",
    "#model00 = Model(inputs = inputt, outputs = output)\n",
    "\n",
    "#sgd = SGD(learning_rate = 1e-2, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "#opt = Adam(learning_rate = 1e-2, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0001)\n",
    "\n",
    "#model00.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#for layer in model00.layers:\n",
    " #       layer.trainable = False\n",
    "        \n",
    "#model00.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38c1b7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainval_vec = model00.predict(trainval_vec)\n",
    "#print(trainval_vec, trainval_vec.shape)\n",
    "\n",
    "#test_seen_vec = model00.predict(test_seen_vec)\n",
    "#print(test_seen_vec, test_seen_vec.shape)\n",
    "\n",
    "#test_unseen_vec = model00.predict(test_unseen_vec)\n",
    "#print(test_unseen_vec, test_unseen_vec.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e89686f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.00088379 -0.0003562  -0.00352095 ... -0.00340103 -0.0002976\n",
      "  -0.00234843]\n",
      " [ 0.          0.          0.         ... -0.00421926 -0.0003692\n",
      "  -0.00291342]\n",
      " [ 0.00088379 -0.0003562  -0.00352095 ... -0.00340103 -0.0002976\n",
      "  -0.00234843]\n",
      " ...\n",
      " [ 0.          0.          0.         ... -0.00984845 -0.00086178\n",
      "  -0.00680041]\n",
      " [ 0.00129184 -0.00052066 -0.0051466  ... -0.00685876 -0.00060017\n",
      "  -0.00473601]\n",
      " [ 0.00595039 -0.00239822 -0.023706   ... -0.08965145 -0.00784488\n",
      "  -0.06190485]] (23527, 65280)\n",
      "[[ 0.          0.          0.         ... -0.00421926 -0.0003692\n",
      "  -0.00291342]\n",
      " [ 0.03010087 -0.01213174 -0.11991999 ... -0.07663521 -0.0067059\n",
      "  -0.05291706]\n",
      " [ 0.00295901 -0.00119259 -0.01178851 ...  0.          0.\n",
      "   0.        ]\n",
      " ...\n",
      " [ 0.02057628 -0.00829299 -0.08197463 ... -0.03059777 -0.00267743\n",
      "  -0.02112794]\n",
      " [ 0.01795834 -0.00723786 -0.07154493 ... -0.00529694 -0.0004635\n",
      "  -0.00365757]\n",
      " [ 0.00550757 -0.00221975 -0.02194182 ... -0.01485156 -0.00129957\n",
      "  -0.01025509]] (5882, 65280)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# attribute is defined for all 50 classes, so we cant use locations directly, instead we have to use labels \n",
    "# that range from 1 to 50, so we have to subtract 1\n",
    "\n",
    "train_attributes = np.zeros((len(trainval_loc), attribute_new.shape[1]))\n",
    "for i in range(len(trainval_loc)):\n",
    "    train_attributes[i] = attribute_new[int(labels_trainval[i])-1]\n",
    "\n",
    "print(train_attributes, train_attributes.shape)# (23527, 85)\n",
    "\n",
    "test_seen_attributes = np.zeros((len(test_seen_loc), attribute_new.shape[1]))\n",
    "for i in range(len(test_seen_loc)):\n",
    "    test_seen_attributes[i] = attribute_new[int(labels_test_seen[i])-1]\n",
    "\n",
    "print(test_seen_attributes, test_seen_attributes.shape)# (5882, 85)\n",
    "\n",
    "#test_unseen_attributes = np.zeros((len(test_unseen_loc), attribute_new.shape[1]))\n",
    "#for i in range(len(test_unseen_loc)):\n",
    "#    test_unseen_attributes[i] = attribute_new[int(labels_test_unseen[i])-1]\n",
    "\n",
    "#print(test_unseen_attributes, test_unseen_attributes.shape)# (7913, 85)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e974ea3e",
   "metadata": {},
   "source": [
    "Step 5 - New attribute vectors are transformed into a lower dimensional space using 'model0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85741854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65280\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 65280)]           0         \n",
      "                                                                 \n",
      " layer1 (Dense)              (None, 2048)              133695488 \n",
      "                                                                 \n",
      " layer3 (Dense)              (None, 512)               1049088   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,744,576\n",
      "Trainable params: 0\n",
      "Non-trainable params: 134,744,576\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from keras.optimizers import SGD, Adam, Adagrad\n",
    "import keras.backend as K\n",
    "\n",
    "attribute_shape_new = attribute_new.shape[1]\n",
    "print(attribute_shape_new)\n",
    "\n",
    "# define model for attribute transformation\n",
    "\n",
    "inputt = Input(shape = attribute_shape_new)\n",
    "hidden = Dense(2048, name=\"layer1\", activation='linear')(inputt)\n",
    "#norm_layer = Lambda(lambda x: K.l2_normalize(x,axis=1))\n",
    "#batchnorm = BatchNormalization()(hidden)\n",
    "#batchnorm = norm_layer(hidden)\n",
    "#hidden2 = Dense(1024, name=\"layer2\", activation='linear')(hidden)\n",
    "output = Dense(512, name=\"layer3\", activation='linear')(hidden)\n",
    "\n",
    "model0 = Model(inputs = inputt, outputs = output)\n",
    "\n",
    "#sgd = SGD(learning_rate = 1e-2, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "opt = Adam(learning_rate = 1e-2, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0001)\n",
    "\n",
    "model0.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "for layer in model0.layers:\n",
    "        layer.trainable = False\n",
    "        \n",
    "model0.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8d6ebf9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "736/736 [==============================] - 3s 4ms/step\n",
      "[[-0.09079248 -0.15513441  0.03450223 ...  0.07863947  0.05400824\n",
      "   0.19759056]\n",
      " [-0.02591212 -0.08569978  0.05164524 ... -0.00724208  0.08779809\n",
      "   0.1599655 ]\n",
      " [-0.09079248 -0.15513441  0.03450223 ...  0.07863947  0.05400824\n",
      "   0.19759056]\n",
      " ...\n",
      " [-0.06239893 -0.17224857  0.02817143 ... -0.05956789  0.10969195\n",
      "   0.05822079]\n",
      " [-0.02612286 -0.11323641  0.0363593  ...  0.07818766  0.00906518\n",
      "   0.10914487]\n",
      " [ 0.03701828 -0.19909267  0.20381573 ... -0.15653741  0.08541014\n",
      "   0.0844107 ]] (23527, 512)\n",
      "184/184 [==============================] - 1s 4ms/step\n",
      "[[-0.02591212 -0.08569978  0.05164524 ... -0.00724208  0.08779809\n",
      "   0.1599655 ]\n",
      " [-0.02663787 -0.21656027  0.05196369 ... -0.11733016  0.06081239\n",
      "   0.07741418]\n",
      " [ 0.04574097 -0.14345555 -0.02098396 ...  0.10292707 -0.00216211\n",
      "   0.07635386]\n",
      " ...\n",
      " [-0.07753605 -0.14462332  0.10455911 ... -0.05544434  0.102138\n",
      "   0.09501376]\n",
      " [-0.0596295  -0.09572737  0.0177859  ...  0.08558711  0.00865394\n",
      "   0.17574747]\n",
      " [-0.05430871 -0.06671895  0.08591001 ... -0.05986893  0.1344863\n",
      "   0.03340217]] (5882, 512)\n"
     ]
    }
   ],
   "source": [
    "train_attributes_2 = model0.predict(train_attributes)\n",
    "print(train_attributes_2, train_attributes_2.shape)\n",
    "\n",
    "test_seen_attributes_2 = model0.predict(test_seen_attributes)\n",
    "print(test_seen_attributes_2, test_seen_attributes_2.shape)\n",
    "\n",
    "#test_unseen_attributes_2 = model0.predict(test_unseen_attributes)\n",
    "#print(test_unseen_attributes_2, test_unseen_attributes_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1457e426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "[[-0.04632114 -0.16317618  0.01918893 ... -0.0118344   0.09675445\n",
      "   0.1050285 ]\n",
      " [-0.01274851 -0.11601336  0.04131824 ...  0.11491158  0.04615615\n",
      "   0.20498416]\n",
      " [-0.03061893 -0.04868404 -0.06235023 ...  0.00595602 -0.01076042\n",
      "   0.15913182]\n",
      " ...\n",
      " [ 0.01021317 -0.05698518  0.06949456 ... -0.05546188  0.04739615\n",
      "   0.14959104]\n",
      " [-0.02663786 -0.21656057  0.05196367 ... -0.11733024  0.06081242\n",
      "   0.07741417]\n",
      " [-0.04167401 -0.05273971  0.03453676 ... -0.02451247  0.06393757\n",
      "   0.07381221]] (50, 512)\n",
      "[[-0.04632114 -0.01274851 -0.03061893 ...  0.01021317 -0.02663786\n",
      "  -0.04167401]\n",
      " [-0.16317618 -0.11601336 -0.04868404 ... -0.05698518 -0.21656057\n",
      "  -0.05273971]\n",
      " [ 0.01918893  0.04131824 -0.06235023 ...  0.06949456  0.05196367\n",
      "   0.03453676]\n",
      " ...\n",
      " [-0.0118344   0.11491158  0.00595602 ... -0.05546188 -0.11733024\n",
      "  -0.02451247]\n",
      " [ 0.09675445  0.04615615 -0.01076042 ...  0.04739615  0.06081242\n",
      "   0.06393757]\n",
      " [ 0.1050285   0.20498416  0.15913182 ...  0.14959104  0.07741417\n",
      "   0.07381221]] (512, 50)\n",
      "Signature for trainval: (512, 40)\n",
      "Signature for test seen: (512, 40)\n",
      "Signature for test unseen: (512, 10)\n"
     ]
    }
   ],
   "source": [
    "# as labels range from 1 to 50, we have subtract 1\n",
    "attribute_2 = model0.predict(attribute_new)\n",
    "print(attribute_2, attribute_2.shape)\n",
    "\n",
    "signature_2 = attribute_2.transpose()\n",
    "print(signature_2, signature_2.shape)#(50, 300)\n",
    "\n",
    "trainval_sig = signature_2[:, (unique_labels_trainval)-1]\n",
    "test_seen_sig = signature_2[:, (unique_labels_test_seen)-1]\n",
    "test_unseen_sig = signature_2[:, (unique_labels_test_unseen)-1]\n",
    "\n",
    "print(\"Signature for trainval:\", trainval_sig.shape)\n",
    "print(\"Signature for test seen:\", test_seen_sig.shape)\n",
    "print(\"Signature for test unseen:\", test_unseen_sig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "581a4c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34]\n",
      " [19]\n",
      " [34]\n",
      " ...\n",
      " [32]\n",
      " [16]\n",
      " [37]] (23527, 1)\n",
      "[[19]\n",
      " [39]\n",
      " [11]\n",
      " ...\n",
      " [20]\n",
      " [12]\n",
      " [22]] (5882, 1)\n",
      "[[4]\n",
      " [4]\n",
      " [4]\n",
      " ...\n",
      " [8]\n",
      " [8]\n",
      " [8]] (7913, 1)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] (40,)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39] (40,)\n",
      "[0 1 2 3 4 5 6 7 8 9] (10,)\n"
     ]
    }
   ],
   "source": [
    "# by doing this modification, we are changing the range of trainval and test seen labels from 0 to 39 \n",
    "# and test unseen labels from 0 to 9\n",
    "\n",
    "k = 0\n",
    "new_labels_trainval = np.zeros((len(labels_trainval), 1), dtype = 'int')\n",
    "for labels in unique_labels_trainval:\n",
    "    new_labels_trainval[labels_trainval == labels] = k\n",
    "    k = k+1\n",
    "    \n",
    "print(new_labels_trainval, new_labels_trainval.shape)#(23527, 1)\n",
    "\n",
    "l = 0\n",
    "new_labels_test_seen = np.zeros((len(labels_test_seen), 1), dtype = 'int')\n",
    "for labels in unique_labels_test_seen:\n",
    "    new_labels_test_seen[labels_test_seen == labels] = l\n",
    "    l = l+1\n",
    "    \n",
    "print(new_labels_test_seen, new_labels_test_seen.shape)# (5882, 1)\n",
    "\n",
    "m = 0\n",
    "new_labels_test_unseen = np.zeros((len(labels_test_unseen), 1), dtype = 'int')\n",
    "for labels in unique_labels_test_unseen:\n",
    "    new_labels_test_unseen[labels_test_unseen == labels] = m\n",
    "    m = m+1  \n",
    "\n",
    "print(new_labels_test_unseen, new_labels_test_unseen.shape) #  (7913, 1)  \n",
    "\n",
    "\n",
    "print(np.unique(new_labels_trainval), np.unique(new_labels_trainval).shape)\n",
    "\n",
    "print(np.unique(new_labels_test_seen), np.unique(new_labels_test_seen).shape)\n",
    "\n",
    "print(np.unique(new_labels_test_unseen), np.unique(new_labels_test_unseen).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fee1341e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23527\n",
      "40\n",
      "5882\n",
      "40\n",
      "7913\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "#params for trainval and test set\n",
    "m_trainval = new_labels_trainval.shape[0]# number of instances in training set: 23527\n",
    "print(m_trainval)\n",
    "\n",
    "z_trainval = len(unique_labels_trainval)# number of classes in training set: 40\n",
    "print(z_trainval)\n",
    "\n",
    "\n",
    "n_test_seen = new_labels_test_seen.shape[0]# 5882\n",
    "print(n_test_seen)\n",
    "\n",
    "z1_test_seen = len(unique_labels_test_seen)# 40\n",
    "print(z1_test_seen)\n",
    "\n",
    "\n",
    "n_test_unseen = new_labels_test_unseen.shape[0]# 7913\n",
    "print(n_test_unseen)\n",
    "\n",
    "z1_test_unseen = len(unique_labels_test_unseen)# 10\n",
    "print(z1_test_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "845b8e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 1. 0. 0.]] (23527, 40)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "gt_trainval = to_categorical(new_labels_trainval, z_trainval)\n",
    "\n",
    "print(gt_trainval, gt_trainval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08067319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n",
      "512\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "input1_shape = trainval_vec.shape[1]\n",
    "print(input1_shape)\n",
    "\n",
    "attribute_shape = trainval_sig.shape[0]\n",
    "print(attribute_shape)\n",
    "\n",
    "output_shape = z_trainval\n",
    "print(output_shape)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fb9d2473",
   "metadata": {},
   "source": [
    "Step 6 - Define 'model2' for attribute to class label mapping\n",
    "\t\t Define 'model1' for visual feature to class label mapping\n",
    "\t\t Train 'model2' and 'model1' through the iterative process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96792076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 1, 1, 512)]       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 512)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 40)                20520     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 20,520\n",
      "Trainable params: 20,520\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from keras.optimizers import SGD, Adam, Adagrad\n",
    "\n",
    "# define model2 for attribute to class label mapping\n",
    "\n",
    "input2 = Input(shape = (1, 1, attribute_shape))\n",
    "flat = Flatten()(input2)\n",
    "output = Dense(output_shape, name=\"output\", activation='softmax')(flat)\n",
    "\n",
    "model2 = Model(inputs = input2, outputs = output)\n",
    "\n",
    "#sgd = SGD(learning_rate = 1e-2, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "opt = Adam(learning_rate = 1e-2, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0001)\n",
    "\n",
    "model2.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2b285876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 1, 1, 2048)]      0         \n",
      "                                                                 \n",
      " intermediate (Conv1D)       (None, 1, 1, 512)         1049088   \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 512)               0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 40)                20520     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,069,608\n",
      "Trainable params: 1,069,608\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model1 for resnet feature to class label mapping\n",
    "\n",
    "input1 = Input(shape = (1, 1, input1_shape))\n",
    "#inter_pre = Dense(512, name=\"intermediate_previous\", activation='relu')(input1)\n",
    "inter = Conv1D(attribute_shape, kernel_size = 1, name = \"intermediate\", activation = 'linear')(input1)\n",
    "flat = Flatten()(inter)\n",
    "output = Dense(output_shape, name=\"output\", activation='softmax')(flat)\n",
    "\n",
    "model1 = Model(inputs = input1, outputs = output)\n",
    "\n",
    "opt = Adam(learning_rate = 1e-2, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0001)\n",
    "\n",
    "model1.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9fd4ac3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23527, 1, 1, 2048)\n",
      "(23527, 1, 1, 512)\n",
      "(23527, 40)\n"
     ]
    }
   ],
   "source": [
    "trainval_input1 = np.reshape(trainval_vec, [trainval_vec.shape[0], 1, 1, trainval_vec.shape[1]])\n",
    "print(trainval_input1.shape)\n",
    "\n",
    "trainval_input2 = np.reshape(train_attributes_2, [train_attributes_2.shape[0], 1, 1, train_attributes_2.shape[1]])\n",
    "print(trainval_input2.shape)\n",
    "\n",
    "trainval_output = gt_trainval\n",
    "print(trainval_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cec915dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "batch_size = 16\n",
    "from sklearn.model_selection import train_test_split    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7be0da5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train1, X_val1, y_train1, y_val1 = train_test_split(trainval_input1, trainval_output, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#train_gen1 = DataGenerator(X_train1, y_train1, batch_size)   \n",
    "#val_gen1 = DataGenerator(X_val1, y_val1, batch_size)\n",
    "\n",
    "\n",
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(trainval_input2, trainval_output, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#train_gen2 = DataGenerator(X_train2, y_train2, batch_size)   \n",
    "#val_gen2 = DataGenerator(X_val2, y_val2, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f527990a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n",
      "model 2 is trained: training acc: 1.0 , training loss: 0.00857263058423996 , validation acc: 1.0 , validation_loss: 0.00870188232511282\n",
      "model 1 is trained: training acc: 0.9563356041908264 , training loss: 10.088253021240234 , validation acc: 0.9097222089767456 , validation_loss: 34.14784240722656\n",
      "micro average\n",
      "seen accuracy: 86.5677390222425 unseen accuracy: 47.51927212061777 harmonic mean: 61.357709630529\n",
      "macro average\n",
      "seen accuracy: 89.01734104046243 unseen accuracy: 41.678250979400985 harmonic mean: 56.77447913988496\n",
      "best accuracy micro seen accuracy: 86.5677390222425 unseen accuracy: 47.51927212061777 harmonic mean: 61.357709630529\n",
      "best accuracy macro seen accuracy: 89.01734104046243 unseen accuracy: 41.678250979400985 harmonic mean: 56.77447913988496\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "iteration = 15\n",
    "epochs1 = 100\n",
    "epochs2 = 200\n",
    "\n",
    "best_performance_micro = [0, 0, 0]\n",
    "best_performance_macro = [0, 0, 0]\n",
    "\n",
    "save_path = 'C:/Users/Admin/Sushree_Codes/Sush_3/Results/'\n",
    "name = 'model1_conv_AWA2_Bert2attT_1024_lin_it15_100eph_adam_cce_16bch_1e-2lr_model2_adam_lr-2_200'\n",
    "\n",
    "for i in range(iteration):\n",
    "    X_train2_it = X_train2[(len(X_train2)//iteration)*i:(len(X_train2)//iteration)*(i+1)]\n",
    "    X_val2_it = X_val2[(len(X_val2)//iteration)*i:(len(X_val2)//iteration)*(i+1)]\n",
    "    y_train2_it = y_train2[(len(y_train2)//iteration)*i:(len(y_train2)//iteration)*(i+1)]\n",
    "    y_val2_it = y_val2[(len(y_val2)//iteration)*i:(len(y_val2)//iteration)*(i+1)]\n",
    "    \n",
    "    train_gen2 = DataGenerator(X_train2_it, y_train2_it, batch_size)   \n",
    "    val_gen2 = DataGenerator(X_val2_it, y_val2_it, batch_size)\n",
    "\n",
    "    train_summary2 = model2.fit(train_gen2, epochs = epochs2, verbose = 0, callbacks = None, validation_data = val_gen2, \n",
    "                              shuffle = True, steps_per_epoch = len(train_gen2)//batch_size, \n",
    "                              validation_steps = len(val_gen2)//batch_size)\n",
    "\n",
    "    print(\"iteration:\", i)\n",
    "    print('model 2 is trained:', 'training acc:', train_summary2.history['accuracy'][-1], ',',  \n",
    "          'training loss:', train_summary2.history['loss'][-1], ',', \n",
    "          'validation acc:', train_summary2.history['val_accuracy'][-1], ',',\n",
    "         'validation_loss:', train_summary2.history['val_loss'][-1])\n",
    "\n",
    "    weights_list2 = model2.get_weights()\n",
    "    #print(weights_list2)\n",
    "\n",
    "    model1.layers[-1].set_weights(weights_list2)\n",
    "\n",
    "    X_train1_it = X_train1[(len(X_train1)//iteration)*i:(len(X_train1)//iteration)*(i+1)]\n",
    "    X_val1_it = X_val1[(len(X_val1)//iteration)*i:(len(X_val1)//iteration)*(i+1)]\n",
    "    y_train1_it = y_train1[(len(y_train1)//iteration)*i:(len(y_train1)//iteration)*(i+1)]\n",
    "    y_val1_it = y_val1[(len(y_val1)//iteration)*i:(len(y_val1)//iteration)*(i+1)]\n",
    "    \n",
    "    train_gen1 = DataGenerator(X_train1_it, y_train1_it, batch_size)   \n",
    "    val_gen1 = DataGenerator(X_val1_it, y_val1_it, batch_size)\n",
    "    \n",
    "    for layer in model1.layers[2:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    train_summary1 = model1.fit(train_gen1, epochs = epochs1, verbose = 0, callbacks = None, validation_data = val_gen1, \n",
    "                              shuffle = True, steps_per_epoch = len(train_gen1)//batch_size, \n",
    "                              validation_steps = len(val_gen1)//batch_size)\n",
    "    \n",
    "    #print(\"iteration:\", i)\n",
    "    print('model 1 is trained:', 'training acc:', train_summary1.history['accuracy'][-1], ',',  \n",
    "          'training loss:', train_summary1.history['loss'][-1], ',', \n",
    "          'validation acc:', train_summary1.history['val_accuracy'][-1], ',',\n",
    "         'validation_loss:', train_summary1.history['val_loss'][-1])\n",
    "    \n",
    "    weights_list1 = Model(inputs = model1.input, outputs = model1.layers[-1].output).get_weights()\n",
    "    \n",
    "    #predictions\n",
    "    #outputs_seen = np.matmul(np.matmul(test_seen_vec, np.matmul(weights_list1[0], weights_list1[2])), test_seen_sig)\n",
    "    #outputs_seen = np.matmul(np.matmul(test_seen_vec, weights_list1[0]), test_seen_sig)\n",
    "    \n",
    "    outputs_seen = np.matmul(np.matmul(test_seen_vec, weights_list1[0][0]), test_seen_sig)\n",
    "    preds_seen = np.array([np.argmax(output) for output in outputs_seen])\n",
    "    \n",
    "    cm_seen = confusion_matrix(new_labels_test_seen, preds_seen)\n",
    "    #print(cm)\n",
    "    # Compute macro average (averaging performance metrics by first calculating the metric separately for each class and \n",
    "    # then averaging these class-specific metrics)\n",
    "    cm_seen_micro = cm_seen.astype('float') / cm_seen.sum(axis=1)[:, np.newaxis]\n",
    "    #print(cm)\n",
    "    avg_seen_micro = (sum(cm_seen_micro.diagonal())/len(unique_labels_test_seen))*100\n",
    "\n",
    "    avg_seen_macro = (sum(cm_seen.diagonal())/len(new_labels_test_seen))*100\n",
    "    \n",
    "    #predictions\n",
    "    #outputs_unseen = np.matmul(np.matmul(test_unseen_vec, weights_list1[0]), test_unseen_sig)\n",
    "    outputs_unseen = np.matmul(np.matmul(test_unseen_vec, weights_list1[0][0]), test_unseen_sig)\n",
    "    \n",
    "    preds_unseen = np.array([np.argmax(output) for output in outputs_unseen])\n",
    "    \n",
    "    cm_unseen = confusion_matrix(new_labels_test_unseen, preds_unseen)\n",
    "    # Compute macro average (averaging performance metrics by first calculating the metric separately for each class and \n",
    "    # then averaging these class-specific metrics)\n",
    "    cm_unseen_micro = cm_unseen.astype('float') / cm_unseen.sum(axis=1)[:, np.newaxis]\n",
    "    avg_unseen_micro = (sum(cm_unseen_micro.diagonal())/len(unique_labels_test_unseen))*100\n",
    "\n",
    "    avg_unseen_macro = (sum(cm_unseen.diagonal())/len(new_labels_test_unseen))*100\n",
    "    \n",
    "    harmonic_micro = (2*avg_seen_micro*avg_unseen_micro) / (avg_seen_micro + avg_unseen_micro)\n",
    "    harmonic_macro = (2*avg_seen_macro*avg_unseen_macro) / (avg_seen_macro + avg_unseen_macro)\n",
    "    \n",
    "    print('micro average')\n",
    "    print('seen accuracy:', avg_seen_micro, 'unseen accuracy:', avg_unseen_micro, 'harmonic mean:', harmonic_micro)\n",
    "    \n",
    "    print('macro average')\n",
    "    print('seen accuracy:', avg_seen_macro, 'unseen accuracy:', avg_unseen_macro, 'harmonic mean:', harmonic_macro)\n",
    "    \n",
    "    if harmonic_micro > best_performance_micro[2]:\n",
    "        best_performance_micro = [avg_seen_micro, avg_unseen_micro, harmonic_micro]\n",
    "        model1.save_weights(save_path + 'bw_micro_' + name + '.h5', overwrite=True)\n",
    "        \n",
    "    if harmonic_macro > best_performance_macro[2]:\n",
    "        best_performance_macro = [avg_seen_macro, avg_unseen_macro, harmonic_macro]\n",
    "        model1.save_weights(save_path + 'bw_macro_' + name + '.h5', overwrite=True)\n",
    "        \n",
    "    print('best accuracy micro','seen accuracy:', best_performance_micro[0], 'unseen accuracy:', best_performance_micro[1], 'harmonic mean:', best_performance_micro[2])\n",
    "    print('best accuracy macro', 'seen accuracy:', best_performance_macro[0], 'unseen accuracy:', best_performance_macro[1], 'harmonic mean:', best_performance_macro[2])\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    weights_list3 = model1.get_weights()\n",
    "    model2.set_weights(weights_list3[2:])"
   ]
  },
  {
   "cell_type": "raw",
   "id": "da36182a",
   "metadata": {},
   "source": [
    "Step 7 - Evaluate for seen and unseen categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58bc47e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] (5882, 40)\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 29.0337 - accuracy: 0.9126\n",
      "cce =  1.3645023\n",
      "184/184 [==============================] - 0s 1ms/step - loss: 0.2884 - accuracy: 1.0000\n",
      "cce =  0.28839198\n"
     ]
    }
   ],
   "source": [
    "gt_test_seen = to_categorical(new_labels_test_seen, z1_test_seen)\n",
    "\n",
    "print(gt_test_seen, gt_test_seen.shape)\n",
    "\n",
    "test_seen_vec = np.reshape(test_seen_vec, [test_seen_vec.shape[0], 1, 1, test_seen_vec.shape[1]])\n",
    "res1 = model1.evaluate(test_seen_vec, gt_test_seen)\n",
    "\n",
    "p1 = model1.predict(test_seen_vec, verbose = 0)\n",
    "\n",
    "import tensorflow\n",
    "cce = tensorflow.keras.losses.CategoricalCrossentropy()\n",
    "print('cce = ', cce(gt_test_seen, p1).numpy())\n",
    "\n",
    "\n",
    "test_seen_attributes_2 = np.reshape(test_seen_attributes_2, [test_seen_attributes_2.shape[0], 1, 1, test_seen_attributes_2.shape[1]])\n",
    "\n",
    "res2 = model2.evaluate(test_seen_attributes_2, gt_test_seen)\n",
    "\n",
    "p2 = model2.predict(test_seen_attributes_2, verbose = 0)\n",
    "\n",
    "import tensorflow\n",
    "cce = tensorflow.keras.losses.CategoricalCrossentropy()\n",
    "print('cce = ', cce(gt_test_seen, p2).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fe3280c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.497466795184906\n",
      "95.63073813915253\n",
      "63.49073341075028\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy_seen_updated = res1[1]*100\n",
    "unseen_accuracy = 47.52\n",
    "h = (2*accuracy_seen_updated*unseen_accuracy) / (accuracy_seen_updated + unseen_accuracy)\n",
    "print(h)\n",
    "\n",
    "\n",
    "accuracy_seen_updated2 = ((res1[1]*100)+(res2[1]*100))/2\n",
    "print(accuracy_seen_updated2)\n",
    "h = (2*accuracy_seen_updated2*unseen_accuracy) / (accuracy_seen_updated2 + unseen_accuracy)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67a434d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_seen_macro 0.951417001590959 recall_seen_macro 0.9444416393642484 f1_seen_macro 0.9463362823978898\n",
      "precision_seen_micro 0.9563073784427065 recall_seen_micro 0.9563073784427065 f1_seen_micro 0.9563073784427065\n",
      "precision_unseen_macro 0.46097194096560656 recall_unseen_macro 0.4751927212061777 f1_unseen_macro 0.3855672966969162\n",
      "precision_unseen_micro 0.4167825097940099 recall_unseen_micro 0.4167825097940099 f1_unseen_micro 0.4167825097940099\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "pp1 = np.array([np.argmax(output) for output in p1])\n",
    "pp2 = np.array([np.argmax(output) for output in p2])\n",
    "\n",
    "seen_macro1 = precision_recall_fscore_support(new_labels_test_seen, pp1, average = 'macro')\n",
    "seen_macro2 = precision_recall_fscore_support(new_labels_test_seen, pp2, average = 'macro')\n",
    "print('precision_seen_macro', (seen_macro1[0] + seen_macro2[0])/2, 'recall_seen_macro', (seen_macro1[1] + seen_macro2[1])/2, 'f1_seen_macro', (seen_macro1[2] + seen_macro2[2])/2)\n",
    "\n",
    "\n",
    "seen_micro1 = precision_recall_fscore_support(new_labels_test_seen, pp1, average = 'micro')\n",
    "seen_micro2 = precision_recall_fscore_support(new_labels_test_seen, pp2, average = 'micro')\n",
    "print('precision_seen_micro', (seen_micro1[0] + seen_micro2[0])/2, 'recall_seen_micro', (seen_micro1[1] + seen_micro2[1])/2, 'f1_seen_micro', (seen_micro1[2] + seen_micro2[2])/2)\n",
    "\n",
    "unseen_macro = precision_recall_fscore_support(new_labels_test_unseen, preds_unseen, average = 'macro')\n",
    "unseen_micro = precision_recall_fscore_support(new_labels_test_unseen, preds_unseen, average = 'micro')\n",
    "\n",
    "print('precision_unseen_macro', unseen_macro[0], 'recall_unseen_macro', unseen_macro[1], 'f1_unseen_macro', unseen_macro[2])\n",
    "print('precision_unseen_micro', unseen_micro[0], 'recall_unseen_micro', unseen_micro[1], 'f1_unseen_micro', unseen_micro[2])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
