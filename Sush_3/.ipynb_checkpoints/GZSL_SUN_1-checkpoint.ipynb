{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "254eac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import scipy.io\n",
    "from sklearn.metrics import classification_report,confusion_matrix"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b409cf05",
   "metadata": {},
   "source": [
    "GZSL_SUN_1: Experiments with direct 102 length attributes\n",
    "Step 1 - Visual features are extracted from pre-trained ResNet101 (without finetuning)\n",
    "Step 2 - Class wise continuous attributes are extracted (for SUN: 717 categories, and each category has attribute vectors of length 102) \n",
    "Step 3 - Define 'model2' for attribute to class label mapping.\n",
    "                                     Define 'model1' for visual feature to class label mapping.\n",
    "                                     Train 'model2' and 'model1' through the iterative process\n",
    "Step 4 - Evaluate for seen and unseen categories.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9174f315",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Please add the folder name of the dataset to run it on different dataset.\n",
    "dataset = 'SUN'\n",
    "path = 'E:/Sushree/Dataset/data/xlsa17/data/'\n",
    "\n",
    "res101 = scipy.io.loadmat(path + dataset + '/res101.mat')\n",
    "att_splits = scipy.io.loadmat(path + dataset + '/att_splits.mat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17ca09e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[    1     2     4 ... 14337 14338 14339] 14339\n",
      "[    0     3    14 ... 14322 14331 14335] 14335\n",
      "[   60    61    62 ... 14317 14318 14319] 14319\n"
     ]
    }
   ],
   "source": [
    "# total number of instances or images = 11788: ranges from 0 to 11787\n",
    "\n",
    "trainval_loc = np.squeeze(att_splits['trainval_loc']-1) # -1: to consider the overflow problem\n",
    "print(np.unique(trainval_loc), np.max(np.unique(trainval_loc))) # smallest location: 1, largest location 11726\n",
    "\n",
    "test_seen_loc = np.squeeze(att_splits['test_seen_loc']-1)\n",
    "print(np.unique(test_seen_loc), np.max(np.unique(test_seen_loc))) # smallest location: 0, largest location 11727\n",
    "\n",
    "test_unseen_loc = np.squeeze(att_splits['test_unseen_loc']-1)\n",
    "print(np.unique(test_unseen_loc), np.max(np.unique(test_unseen_loc))) # smallest location: 178, largest location 11787\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85fdebcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels [[  1]\n",
      " [  1]\n",
      " [  1]\n",
      " ...\n",
      " [717]\n",
      " [717]\n",
      " [717]] (14340, 1)\n",
      "unique_labels [  1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17  18\n",
      "  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35  36\n",
      "  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53  54\n",
      "  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71  72\n",
      "  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89  90\n",
      "  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107 108\n",
      " 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126\n",
      " 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144\n",
      " 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162\n",
      " 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180\n",
      " 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198\n",
      " 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216\n",
      " 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234\n",
      " 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252\n",
      " 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270\n",
      " 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288\n",
      " 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305 306\n",
      " 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323 324\n",
      " 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341 342\n",
      " 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359 360\n",
      " 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377 378\n",
      " 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395 396\n",
      " 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413 414\n",
      " 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431 432\n",
      " 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449 450\n",
      " 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467 468\n",
      " 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485 486\n",
      " 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503 504\n",
      " 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521 522\n",
      " 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539 540\n",
      " 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558\n",
      " 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576\n",
      " 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593 594\n",
      " 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612\n",
      " 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629 630\n",
      " 631 632 633 634 635 636 637 638 639 640 641 642 643 644 645 646 647 648\n",
      " 649 650 651 652 653 654 655 656 657 658 659 660 661 662 663 664 665 666\n",
      " 667 668 669 670 671 672 673 674 675 676 677 678 679 680 681 682 683 684\n",
      " 685 686 687 688 689 690 691 692 693 694 695 696 697 698 699 700 701 702\n",
      " 703 704 705 706 707 708 709 710 711 712 713 714 715 716 717] (717,)\n",
      "labels_trainval [[50]\n",
      " [50]\n",
      " [50]\n",
      " ...\n",
      " [70]\n",
      " [70]\n",
      " [70]] (10320, 1)\n",
      "unique_labels_trainval [  1   2   3   5   6   7   8   9  10  12  13  14  15  16  17  18  19  20\n",
      "  21  22  23  26  27  28  29  30  31  32  34  35  36  37  38  40  41  42\n",
      "  43  44  45  46  47  48  49  50  51  52  53  55  56  57  59  60  61  62\n",
      "  63  64  65  66  67  68  69  70  71  72  74  77  78  79  80  81  82  83\n",
      "  84  85  87  88  89  90  91  92  93  94  95  97  98  99 101 102 103 105\n",
      " 106 107 108 109 110 111 112 114 115 116 117 118 119 120 121 122 123 124\n",
      " 126 127 128 129 130 132 133 134 135 136 137 138 140 141 142 143 144 145\n",
      " 147 148 149 150 151 152 154 155 156 157 158 160 161 162 163 164 165 166\n",
      " 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184\n",
      " 186 187 188 189 190 191 192 193 194 195 196 198 199 200 201 202 203 204\n",
      " 205 206 207 208 209 210 211 212 213 214 215 216 218 219 220 221 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 239 240 241 242 243\n",
      " 244 245 248 249 250 251 252 253 254 256 257 258 259 261 262 264 265 266\n",
      " 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284\n",
      " 285 286 288 289 290 291 292 293 294 295 296 297 298 300 301 302 303 304\n",
      " 305 306 307 308 309 310 311 312 313 314 315 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 330 331 332 333 334 335 336 338 339 340 341 342 344\n",
      " 345 346 347 348 349 350 351 352 353 355 356 357 358 360 361 362 363 364\n",
      " 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 381 383 384\n",
      " 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402\n",
      " 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420\n",
      " 422 423 425 427 428 429 430 431 432 433 434 435 436 437 438 439 440 442\n",
      " 443 444 445 446 447 448 450 451 452 453 454 455 456 457 458 459 460 461\n",
      " 462 463 464 465 466 467 468 469 470 471 473 474 475 476 477 478 479 480\n",
      " 481 482 484 485 486 487 488 489 490 491 492 493 495 496 497 498 499 500\n",
      " 501 502 503 504 505 506 507 508 511 512 513 514 515 516 517 519 520 521\n",
      " 522 523 524 525 526 527 528 529 531 532 533 534 535 536 537 538 539 540\n",
      " 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558\n",
      " 560 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578\n",
      " 579 580 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597\n",
      " 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615\n",
      " 616 617 618 619 620 621 622 624 625 626 627 628 629 630 631 633 634 635\n",
      " 637 638 639 640 641 642 643 644 645 647 648 649 650 652 653 654 655 656\n",
      " 658 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 676 677\n",
      " 678 679 681 683 684 685 686 687 688 689 690 691 692 693 694 695 697 698\n",
      " 699 700 701 702 703 704 705 706 707 708 709 710 714 715 717] (645,)\n",
      "labels_test_seen [[50]\n",
      " [50]\n",
      " [50]\n",
      " ...\n",
      " [70]\n",
      " [70]\n",
      " [70]] (2580, 1)\n",
      "unique_labels_test_seen [  1   2   3   5   6   7   8   9  10  12  13  14  15  16  17  18  19  20\n",
      "  21  22  23  26  27  28  29  30  31  32  34  35  36  37  38  40  41  42\n",
      "  43  44  45  46  47  48  49  50  51  52  53  55  56  57  59  60  61  62\n",
      "  63  64  65  66  67  68  69  70  71  72  74  77  78  79  80  81  82  83\n",
      "  84  85  87  88  89  90  91  92  93  94  95  97  98  99 101 102 103 105\n",
      " 106 107 108 109 110 111 112 114 115 116 117 118 119 120 121 122 123 124\n",
      " 126 127 128 129 130 132 133 134 135 136 137 138 140 141 142 143 144 145\n",
      " 147 148 149 150 151 152 154 155 156 157 158 160 161 162 163 164 165 166\n",
      " 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184\n",
      " 186 187 188 189 190 191 192 193 194 195 196 198 199 200 201 202 203 204\n",
      " 205 206 207 208 209 210 211 212 213 214 215 216 218 219 220 221 223 224\n",
      " 225 226 227 228 229 230 231 232 233 234 235 236 237 239 240 241 242 243\n",
      " 244 245 248 249 250 251 252 253 254 256 257 258 259 261 262 264 265 266\n",
      " 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284\n",
      " 285 286 288 289 290 291 292 293 294 295 296 297 298 300 301 302 303 304\n",
      " 305 306 307 308 309 310 311 312 313 314 315 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 330 331 332 333 334 335 336 338 339 340 341 342 344\n",
      " 345 346 347 348 349 350 351 352 353 355 356 357 358 360 361 362 363 364\n",
      " 365 366 367 368 369 370 371 372 373 374 375 376 377 378 379 381 383 384\n",
      " 385 386 387 388 389 390 391 392 393 394 395 396 397 398 399 400 401 402\n",
      " 403 404 405 406 407 408 409 410 411 412 413 414 415 416 417 418 419 420\n",
      " 422 423 425 427 428 429 430 431 432 433 434 435 436 437 438 439 440 442\n",
      " 443 444 445 446 447 448 450 451 452 453 454 455 456 457 458 459 460 461\n",
      " 462 463 464 465 466 467 468 469 470 471 473 474 475 476 477 478 479 480\n",
      " 481 482 484 485 486 487 488 489 490 491 492 493 495 496 497 498 499 500\n",
      " 501 502 503 504 505 506 507 508 511 512 513 514 515 516 517 519 520 521\n",
      " 522 523 524 525 526 527 528 529 531 532 533 534 535 536 537 538 539 540\n",
      " 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557 558\n",
      " 560 562 563 564 565 566 567 568 569 570 571 572 573 574 575 576 577 578\n",
      " 579 580 582 583 584 585 586 587 588 589 590 591 592 593 594 595 596 597\n",
      " 598 599 600 601 602 603 604 605 606 607 608 609 610 611 612 613 614 615\n",
      " 616 617 618 619 620 621 622 624 625 626 627 628 629 630 631 633 634 635\n",
      " 637 638 639 640 641 642 643 644 645 647 648 649 650 652 653 654 655 656\n",
      " 658 660 661 662 663 664 665 666 667 668 669 670 671 672 673 674 676 677\n",
      " 678 679 681 683 684 685 686 687 688 689 690 691 692 693 694 695 697 698\n",
      " 699 700 701 702 703 704 705 706 707 708 709 710 714 715 717] (645,)\n",
      "labels_test_unseen [[  4]\n",
      " [  4]\n",
      " [  4]\n",
      " ...\n",
      " [716]\n",
      " [716]\n",
      " [716]] (1440, 1)\n",
      "unique_labels_test_unseen [  4  11  24  25  33  39  54  58  73  75  76  86  96 100 104 113 125 131\n",
      " 139 146 153 159 185 197 217 222 238 246 247 255 260 263 287 299 316 329\n",
      " 337 343 354 359 380 382 421 424 426 441 449 472 483 494 509 510 518 530\n",
      " 559 561 581 623 632 636 646 651 657 659 675 680 682 696 711 712 713 716] (72,)\n",
      "correct number of instances for training, test seen and test unseen categories\n",
      "Number of overlapping classes between trainval and test seen: 645\n",
      "Number of overlapping classes between trainval and test unseen: 0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "labels = res101['labels']# direct class labels\n",
    "print('labels', labels, labels.shape)# 11788 x 1\n",
    "\n",
    "print('unique_labels', np.unique(labels), np.unique(labels).shape)# class labels range from 1 to 200, 200 classes\n",
    "\n",
    "# get the labels for trainval, test seen and test unseen sets\n",
    "\n",
    "labels_trainval = labels[trainval_loc]\n",
    "print('labels_trainval', labels_trainval, labels_trainval.shape)\n",
    "\n",
    "unique_labels_trainval = np.unique(labels_trainval) # labels min:1 max:200\n",
    "print('unique_labels_trainval', unique_labels_trainval, unique_labels_trainval.shape)# 150 classes\n",
    "\n",
    "\n",
    "labels_test_seen = labels[test_seen_loc]\n",
    "print('labels_test_seen', labels_test_seen, labels_test_seen.shape)\n",
    "\n",
    "unique_labels_test_seen = np.unique(labels_test_seen) # labels min:1 max:200\n",
    "print('unique_labels_test_seen', unique_labels_test_seen, unique_labels_test_seen.shape)# 150 classes\n",
    "\n",
    "\n",
    "labels_test_unseen = labels[test_unseen_loc]\n",
    "print('labels_test_unseen', labels_test_unseen, labels_test_unseen.shape)\n",
    "\n",
    "unique_labels_test_unseen = np.unique(labels_test_unseen) # labels min:7 max:195\n",
    "print('unique_labels_test_unseen', unique_labels_test_unseen, unique_labels_test_unseen.shape)# 50 classes\n",
    "\n",
    "\n",
    "if len(labels) == len(labels_trainval) + len(labels_test_seen) + len(labels_test_unseen):\n",
    "    print('correct number of instances for training, test seen and test unseen categories')\n",
    "    \n",
    "print(\"Number of overlapping classes between trainval and test seen:\",len(set(unique_labels_trainval).intersection(set(unique_labels_test_seen))))\n",
    "\n",
    "print(\"Number of overlapping classes between trainval and test unseen:\",len(set(unique_labels_trainval).intersection(set(unique_labels_test_unseen))))\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "94fa36b6",
   "metadata": {},
   "source": [
    "Step 1 - Visual features are extracted from pre-trained ResNet101 (without finetuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "43955a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for trainval: (10320, 2048)\n",
      "Features for test seen: (2580, 2048)\n",
      "Features for test unseen: (1440, 2048)\n"
     ]
    }
   ],
   "source": [
    "X_features = res101['features']\n",
    "\n",
    "# locations are already subtracted by 1, so they range from 0 to 11787\n",
    "trainval_vec = X_features[:, trainval_loc].transpose()\n",
    "test_seen_vec = X_features[:, test_seen_loc].transpose()\n",
    "test_unseen_vec = X_features[:, test_unseen_loc].transpose()\n",
    "\n",
    "print(\"Features for trainval:\", trainval_vec.shape) #(7057, 2048)\n",
    "print(\"Features for test seen:\", test_seen_vec.shape)# (1764, 2048)\n",
    "print(\"Features for test unseen:\", test_unseen_vec.shape) #(2967, 2048)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6ff2a5e9",
   "metadata": {},
   "source": [
    "Step 2 - Class wise continuous attributes are extracted (for SUN: 717 categories, and each category has attribute vectors of length 102) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48707767",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 717)\n",
      "[[0.         0.04386302 0.04386302 ... 0.0087726  0.02631781 0.0087726 ]\n",
      " [0.00725916 0.3411804  0.31214377 ... 0.00725916 0.02903663 0.00725916]\n",
      " [0.         0.03359921 0.09239783 ... 0.0083998  0.04199902 0.04199902]\n",
      " ...\n",
      " [0.         0.04857575 0.04857575 ... 0.00971515 0.194303   0.00971515]\n",
      " [0.         0.08417375 0.04208687 ... 0.01402896 0.03507239 0.02805792]\n",
      " [0.03236677 0.         0.01078892 ... 0.03236677 0.07552247 0.        ]] (717, 102)\n",
      "[[0.         0.         0.         ... 0.         0.         0.0231295 ]\n",
      " [0.         0.         0.         ... 0.         0.         0.0231295 ]\n",
      " [0.         0.         0.         ... 0.         0.         0.0231295 ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.0651789  0.01086315]\n",
      " [0.         0.         0.         ... 0.         0.0651789  0.01086315]\n",
      " [0.         0.         0.         ... 0.         0.0651789  0.01086315]] (10320, 102)\n",
      "[[0.         0.         0.         ... 0.         0.         0.0231295 ]\n",
      " [0.         0.         0.         ... 0.         0.         0.0231295 ]\n",
      " [0.         0.         0.         ... 0.         0.         0.0231295 ]\n",
      " ...\n",
      " [0.         0.         0.         ... 0.         0.0651789  0.01086315]\n",
      " [0.         0.         0.         ... 0.         0.0651789  0.01086315]\n",
      " [0.         0.         0.         ... 0.         0.0651789  0.01086315]] (2580, 102)\n",
      "[[0.         0.         0.         ... 0.09640654 0.         0.09640654]\n",
      " [0.         0.         0.         ... 0.09640654 0.         0.09640654]\n",
      " [0.         0.         0.         ... 0.09640654 0.         0.09640654]\n",
      " ...\n",
      " [0.         0.08417375 0.04208687 ... 0.01402896 0.03507239 0.02805792]\n",
      " [0.         0.08417375 0.04208687 ... 0.01402896 0.03507239 0.02805792]\n",
      " [0.         0.08417375 0.04208687 ... 0.01402896 0.03507239 0.02805792]] (1440, 102)\n"
     ]
    }
   ],
   "source": [
    "signature = att_splits['att']\n",
    "print(signature.shape) #(312, 200)\n",
    "\n",
    "attribute = signature.transpose()\n",
    "print(attribute, attribute.shape)#(200, 312)\n",
    "\n",
    "attribute[attribute<0]=0\n",
    "print(attribute, attribute.shape)#(200, 312)\n",
    "\n",
    "# attribute is defined for all 50 classes, so we cant use locations directly, instead we have to use labels \n",
    "# that range from 1 to 50, so we have to subtract 1\n",
    "\n",
    "train_attributes = np.zeros((len(trainval_loc), signature.shape[0]))\n",
    "for i in range(len(trainval_loc)):\n",
    "    train_attributes[i] = attribute[int(labels_trainval[i])-1]\n",
    "\n",
    "print(train_attributes, train_attributes.shape)# (7057, 312)\n",
    "\n",
    "test_seen_attributes = np.zeros((len(test_seen_loc), signature.shape[0]))\n",
    "for i in range(len(test_seen_loc)):\n",
    "    test_seen_attributes[i] = attribute[int(labels_test_seen[i])-1]\n",
    "\n",
    "print(test_seen_attributes, test_seen_attributes.shape)# (1764, 312)\n",
    "\n",
    "test_unseen_attributes = np.zeros((len(test_unseen_loc), signature.shape[0]))\n",
    "for i in range(len(test_unseen_loc)):\n",
    "    test_unseen_attributes[i] = attribute[int(labels_test_unseen[i])-1]\n",
    "\n",
    "print(test_unseen_attributes, test_unseen_attributes.shape)# (2967, 312)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd86867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Signature for trainval: (102, 645)\n",
      "Signature for test seen: (102, 645)\n",
      "Signature for test unseen: (102, 72)\n"
     ]
    }
   ],
   "source": [
    "# as labels range from 1 to 312, we have subtract 1\n",
    "\n",
    "trainval_sig = signature[:, (unique_labels_trainval)-1]\n",
    "test_seen_sig = signature[:, (unique_labels_test_seen)-1]\n",
    "test_unseen_sig = signature[:, (unique_labels_test_unseen)-1]\n",
    "\n",
    "print(\"Signature for trainval:\", trainval_sig.shape)\n",
    "print(\"Signature for test seen:\", test_seen_sig.shape)\n",
    "print(\"Signature for test unseen:\", test_unseen_sig.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74ca9ca5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[43]\n",
      " [43]\n",
      " [43]\n",
      " ...\n",
      " [61]\n",
      " [61]\n",
      " [61]] (10320, 1)\n",
      "[[43]\n",
      " [43]\n",
      " [43]\n",
      " ...\n",
      " [61]\n",
      " [61]\n",
      " [61]] (2580, 1)\n",
      "[[ 0]\n",
      " [ 0]\n",
      " [ 0]\n",
      " ...\n",
      " [71]\n",
      " [71]\n",
      " [71]] (1440, 1)\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
      " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
      " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
      " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
      " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
      " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
      " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
      " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644] (645,)\n",
      "[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161\n",
      " 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179\n",
      " 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197\n",
      " 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215\n",
      " 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233\n",
      " 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251\n",
      " 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269\n",
      " 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287\n",
      " 288 289 290 291 292 293 294 295 296 297 298 299 300 301 302 303 304 305\n",
      " 306 307 308 309 310 311 312 313 314 315 316 317 318 319 320 321 322 323\n",
      " 324 325 326 327 328 329 330 331 332 333 334 335 336 337 338 339 340 341\n",
      " 342 343 344 345 346 347 348 349 350 351 352 353 354 355 356 357 358 359\n",
      " 360 361 362 363 364 365 366 367 368 369 370 371 372 373 374 375 376 377\n",
      " 378 379 380 381 382 383 384 385 386 387 388 389 390 391 392 393 394 395\n",
      " 396 397 398 399 400 401 402 403 404 405 406 407 408 409 410 411 412 413\n",
      " 414 415 416 417 418 419 420 421 422 423 424 425 426 427 428 429 430 431\n",
      " 432 433 434 435 436 437 438 439 440 441 442 443 444 445 446 447 448 449\n",
      " 450 451 452 453 454 455 456 457 458 459 460 461 462 463 464 465 466 467\n",
      " 468 469 470 471 472 473 474 475 476 477 478 479 480 481 482 483 484 485\n",
      " 486 487 488 489 490 491 492 493 494 495 496 497 498 499 500 501 502 503\n",
      " 504 505 506 507 508 509 510 511 512 513 514 515 516 517 518 519 520 521\n",
      " 522 523 524 525 526 527 528 529 530 531 532 533 534 535 536 537 538 539\n",
      " 540 541 542 543 544 545 546 547 548 549 550 551 552 553 554 555 556 557\n",
      " 558 559 560 561 562 563 564 565 566 567 568 569 570 571 572 573 574 575\n",
      " 576 577 578 579 580 581 582 583 584 585 586 587 588 589 590 591 592 593\n",
      " 594 595 596 597 598 599 600 601 602 603 604 605 606 607 608 609 610 611\n",
      " 612 613 614 615 616 617 618 619 620 621 622 623 624 625 626 627 628 629\n",
      " 630 631 632 633 634 635 636 637 638 639 640 641 642 643 644] (645,)\n",
      "[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
      " 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47\n",
      " 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71] (72,)\n"
     ]
    }
   ],
   "source": [
    "# by doing this modification, we are changing the range of trainval and test seen labels from 0 to 149 \n",
    "# and test unseen labels from 0 to 49\n",
    "\n",
    "k = 0\n",
    "new_labels_trainval = np.zeros((len(labels_trainval), 1), dtype = 'int')\n",
    "for labels in unique_labels_trainval:\n",
    "    new_labels_trainval[labels_trainval == labels] = k\n",
    "    k = k+1\n",
    "    \n",
    "print(new_labels_trainval, new_labels_trainval.shape)#(7057, 1)\n",
    "\n",
    "l = 0\n",
    "new_labels_test_seen = np.zeros((len(labels_test_seen), 1), dtype = 'int')\n",
    "for labels in unique_labels_test_seen:\n",
    "    new_labels_test_seen[labels_test_seen == labels] = l\n",
    "    l = l+1\n",
    "    \n",
    "print(new_labels_test_seen, new_labels_test_seen.shape)# (1764, 1)\n",
    "\n",
    "m = 0\n",
    "new_labels_test_unseen = np.zeros((len(labels_test_unseen), 1), dtype = 'int')\n",
    "for labels in unique_labels_test_unseen:\n",
    "    new_labels_test_unseen[labels_test_unseen == labels] = m\n",
    "    m = m+1  \n",
    "\n",
    "print(new_labels_test_unseen, new_labels_test_unseen.shape) #  (2967, 1)  \n",
    "\n",
    "\n",
    "print(np.unique(new_labels_trainval), np.unique(new_labels_trainval).shape)\n",
    "\n",
    "print(np.unique(new_labels_test_seen), np.unique(new_labels_test_seen).shape)\n",
    "\n",
    "print(np.unique(new_labels_test_unseen), np.unique(new_labels_test_unseen).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c560b958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10320\n",
      "645\n",
      "2580\n",
      "645\n",
      "1440\n",
      "72\n"
     ]
    }
   ],
   "source": [
    "#params for trainval and test set\n",
    "m_trainval = new_labels_trainval.shape[0]# number of instances in training set: 7057\n",
    "print(m_trainval)\n",
    "\n",
    "z_trainval = len(unique_labels_trainval)# number of classes in training set: 150\n",
    "print(z_trainval)\n",
    "\n",
    "\n",
    "n_test_seen = new_labels_test_seen.shape[0]# 1764\n",
    "print(n_test_seen)\n",
    "\n",
    "z1_test_seen = len(unique_labels_test_seen)# 150\n",
    "print(z1_test_seen)\n",
    "\n",
    "\n",
    "n_test_unseen = new_labels_test_unseen.shape[0]# 2967\n",
    "print(n_test_unseen)\n",
    "\n",
    "z1_test_unseen = len(unique_labels_test_unseen)# 50\n",
    "print(z1_test_unseen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "37635eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] (10320, 645)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "gt_trainval = to_categorical(new_labels_trainval, z_trainval)\n",
    "\n",
    "print(gt_trainval, gt_trainval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9b7c79ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#grountruth for trainval and test set\n",
    "#gt_trainval = 0*np.ones((m_trainval, z_trainval))# 23527, 40\n",
    "#gt_trainval[np.arange(m_trainval), np.squeeze(new_labels_trainval)] = 1\n",
    "\n",
    "#print(gt_trainval, gt_trainval.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99410b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048\n",
      "102\n",
      "645\n"
     ]
    }
   ],
   "source": [
    "input1_shape = trainval_vec.shape[1]\n",
    "print(input1_shape)\n",
    "\n",
    "attribute_shape = trainval_sig.shape[0]\n",
    "print(attribute_shape)\n",
    "\n",
    "output_shape = z_trainval\n",
    "print(output_shape)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "692678fd",
   "metadata": {},
   "source": [
    "Step 3 - Define 'model2' for attribute to class label mapping.\n",
    "                                     Define 'model1' for visual feature to class label mapping.\n",
    "                                     Train 'model2' and 'model1' through the iterative process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3eecfe31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 102)]             0         \n",
      "                                                                 \n",
      " output (Dense)              (None, 645)               66435     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 66,435\n",
      "Trainable params: 66,435\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import *\n",
    "from keras.optimizers import SGD, Adam, Adagrad\n",
    "\n",
    "# define model2 for attribute to class label mapping\n",
    "\n",
    "input2 = Input(shape = attribute_shape)\n",
    "output = Dense(output_shape, name=\"output\", activation='softmax')(input2)\n",
    "\n",
    "model2 = Model(inputs = input2, outputs = output)\n",
    "\n",
    "#opt = SGD(learning_rate = 1e-2, decay = 1e-6, momentum = 0.9, nesterov = True)\n",
    "opt = Adam(learning_rate = 1e-2, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0001)\n",
    "model2.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bde8378e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 2048)]            0         \n",
      "                                                                 \n",
      " intermediate (Dense)        (None, 102)               208998    \n",
      "                                                                 \n",
      " output (Dense)              (None, 645)               66435     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 275,433\n",
      "Trainable params: 275,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define model1 for resnet feature to class label mapping\n",
    "\n",
    "input1 = Input(shape = input1_shape)\n",
    "#inter_pre = Dense(512, name=\"intermediate_previous\", activation='relu')(input1)\n",
    "inter = Dense(attribute_shape, name = \"intermediate\", activation = 'linear')(input1)\n",
    "output = Dense(output_shape, name=\"output\", activation='softmax')(inter)\n",
    "\n",
    "model1 = Model(inputs = input1, outputs = output)\n",
    "\n",
    "opt = Adam(learning_rate = 1e-2, beta_1=0.9, beta_2=0.999, epsilon=0.01, decay=0.0001)\n",
    "\n",
    "model1.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9566a2e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10320, 2048)\n",
      "(10320, 102)\n",
      "(10320, 645)\n"
     ]
    }
   ],
   "source": [
    "trainval_input1 = trainval_vec\n",
    "print(trainval_input1.shape)\n",
    "\n",
    "trainval_input2 = train_attributes\n",
    "print(trainval_input2.shape)\n",
    "\n",
    "trainval_output = gt_trainval\n",
    "print(trainval_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c995f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, x_set, y_set, batch_size):\n",
    "        self.x, self.y = x_set, y_set\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.x) / float(self.batch_size)))\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        return batch_x, batch_y\n",
    "    \n",
    "batch_size = 8\n",
    "from sklearn.model_selection import train_test_split    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6928ad80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train1, X_val1, y_train1, y_val1 = train_test_split(trainval_input1, trainval_output, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#train_gen1 = DataGenerator(X_train1, y_train1, batch_size)   \n",
    "#val_gen1 = DataGenerator(X_val1, y_val1, batch_size)\n",
    "\n",
    "\n",
    "X_train2, X_val2, y_train2, y_val2 = train_test_split(trainval_input2, trainval_output, test_size = 0.2, random_state = 42)\n",
    "\n",
    "#train_gen2 = DataGenerator(X_train2, y_train2, batch_size)   \n",
    "#val_gen2 = DataGenerator(X_val2, y_val2, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "22218dbd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 0\n",
      "model 2 is trained: training acc: 0.125 , training loss: 5.124402046203613 , validation acc: 0.125 , validation_loss: 6.748011589050293\n",
      "model 1 is trained: training acc: 0.890625 , training loss: 1.7687256336212158 , validation acc: 0.0625 , validation_loss: 115.02653503417969\n",
      "micro average\n",
      "seen accuracy: 8.527131782945736 unseen accuracy: 30.34722222222222 harmonic mean: 13.31339232548156\n",
      "macro average\n",
      "seen accuracy: 8.527131782945736 unseen accuracy: 30.34722222222222 harmonic mean: 13.31339232548156\n",
      "best accuracy micro seen accuracy: 8.527131782945736 unseen accuracy: 30.34722222222222 harmonic mean: 13.31339232548156\n",
      "best accuracy macro seen accuracy: 8.527131782945736 unseen accuracy: 30.34722222222222 harmonic mean: 13.31339232548156\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 1\n",
      "model 2 is trained: training acc: 0.296875 , training loss: 4.249504089355469 , validation acc: 0.0625 , validation_loss: 6.310480117797852\n",
      "model 1 is trained: training acc: 0.984375 , training loss: 0.07133378088474274 , validation acc: 0.0 , validation_loss: 252.70814514160156\n",
      "micro average\n",
      "seen accuracy: 12.790697674418606 unseen accuracy: 37.91666666666667 harmonic mean: 19.128606917638066\n",
      "macro average\n",
      "seen accuracy: 12.790697674418606 unseen accuracy: 37.916666666666664 harmonic mean: 19.128606917638066\n",
      "best accuracy micro seen accuracy: 12.790697674418606 unseen accuracy: 37.91666666666667 harmonic mean: 19.128606917638066\n",
      "best accuracy macro seen accuracy: 12.790697674418606 unseen accuracy: 37.916666666666664 harmonic mean: 19.128606917638066\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 2\n",
      "model 2 is trained: training acc: 0.421875 , training loss: 4.059391975402832 , validation acc: 0.0625 , validation_loss: 5.440949440002441\n",
      "model 1 is trained: training acc: 0.96875 , training loss: 0.8887360095977783 , validation acc: 0.125 , validation_loss: 252.49319458007812\n",
      "micro average\n",
      "seen accuracy: 14.34108527131783 unseen accuracy: 39.23611111111111 harmonic mean: 21.00477267018337\n",
      "macro average\n",
      "seen accuracy: 14.34108527131783 unseen accuracy: 39.23611111111111 harmonic mean: 21.00477267018337\n",
      "best accuracy micro seen accuracy: 14.34108527131783 unseen accuracy: 39.23611111111111 harmonic mean: 21.00477267018337\n",
      "best accuracy macro seen accuracy: 14.34108527131783 unseen accuracy: 39.23611111111111 harmonic mean: 21.00477267018337\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 3\n",
      "model 2 is trained: training acc: 0.375 , training loss: 3.9480066299438477 , validation acc: 0.125 , validation_loss: 5.024857521057129\n",
      "model 1 is trained: training acc: 0.984375 , training loss: 1.210611343383789 , validation acc: 0.0625 , validation_loss: 177.2958984375\n",
      "micro average\n",
      "seen accuracy: 15.658914728682172 unseen accuracy: 39.930555555555564 harmonic mean: 22.495956925520275\n",
      "macro average\n",
      "seen accuracy: 15.658914728682172 unseen accuracy: 39.93055555555556 harmonic mean: 22.49595692552028\n",
      "best accuracy micro seen accuracy: 15.658914728682172 unseen accuracy: 39.930555555555564 harmonic mean: 22.495956925520275\n",
      "best accuracy macro seen accuracy: 15.658914728682172 unseen accuracy: 39.93055555555556 harmonic mean: 22.49595692552028\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 4\n",
      "model 2 is trained: training acc: 0.5 , training loss: 3.662968873977661 , validation acc: 0.0 , validation_loss: 4.882430076599121\n",
      "model 1 is trained: training acc: 0.96875 , training loss: 1.1486209630966187 , validation acc: 0.125 , validation_loss: 223.45150756835938\n",
      "micro average\n",
      "seen accuracy: 16.899224806201552 unseen accuracy: 40.69444444444445 harmonic mean: 23.881255491372706\n",
      "macro average\n",
      "seen accuracy: 16.899224806201552 unseen accuracy: 40.69444444444444 harmonic mean: 23.881255491372706\n",
      "best accuracy micro seen accuracy: 16.899224806201552 unseen accuracy: 40.69444444444445 harmonic mean: 23.881255491372706\n",
      "best accuracy macro seen accuracy: 16.899224806201552 unseen accuracy: 40.69444444444444 harmonic mean: 23.881255491372706\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 5\n",
      "model 2 is trained: training acc: 0.40625 , training loss: 3.5727884769439697 , validation acc: 0.125 , validation_loss: 4.583160877227783\n",
      "model 1 is trained: training acc: 0.984375 , training loss: 0.03107406385242939 , validation acc: 0.25 , validation_loss: 238.93740844726562\n",
      "micro average\n",
      "seen accuracy: 18.100775193798448 unseen accuracy: 43.19444444444444 harmonic mean: 25.511057244734854\n",
      "macro average\n",
      "seen accuracy: 18.100775193798448 unseen accuracy: 43.19444444444444 harmonic mean: 25.511057244734854\n",
      "best accuracy micro seen accuracy: 18.100775193798448 unseen accuracy: 43.19444444444444 harmonic mean: 25.511057244734854\n",
      "best accuracy macro seen accuracy: 18.100775193798448 unseen accuracy: 43.19444444444444 harmonic mean: 25.511057244734854\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 6\n",
      "model 2 is trained: training acc: 0.453125 , training loss: 3.5535573959350586 , validation acc: 0.25 , validation_loss: 4.4531474113464355\n",
      "model 1 is trained: training acc: 0.984375 , training loss: 1.7873201370239258 , validation acc: 0.25 , validation_loss: 214.55853271484375\n",
      "micro average\n",
      "seen accuracy: 17.751937984496124 unseen accuracy: 42.222222222222214 harmonic mean: 24.99497343099239\n",
      "macro average\n",
      "seen accuracy: 17.751937984496124 unseen accuracy: 42.22222222222222 harmonic mean: 24.99497343099239\n",
      "best accuracy micro seen accuracy: 18.100775193798448 unseen accuracy: 43.19444444444444 harmonic mean: 25.511057244734854\n",
      "best accuracy macro seen accuracy: 18.100775193798448 unseen accuracy: 43.19444444444444 harmonic mean: 25.511057244734854\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 7\n",
      "model 2 is trained: training acc: 0.5967742204666138 , training loss: 3.09975266456604 , validation acc: 0.1875 , validation_loss: 3.9640700817108154\n",
      "model 1 is trained: training acc: 0.984375 , training loss: 1.2168102264404297 , validation acc: 0.3125 , validation_loss: 166.11337280273438\n",
      "micro average\n",
      "seen accuracy: 19.883720930232556 unseen accuracy: 41.94444444444445 harmonic mean: 26.978372165917875\n",
      "macro average\n",
      "seen accuracy: 19.883720930232556 unseen accuracy: 41.94444444444444 harmonic mean: 26.978372165917875\n",
      "best accuracy micro seen accuracy: 19.883720930232556 unseen accuracy: 41.94444444444445 harmonic mean: 26.978372165917875\n",
      "best accuracy macro seen accuracy: 19.883720930232556 unseen accuracy: 41.94444444444444 harmonic mean: 26.978372165917875\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 8\n",
      "model 2 is trained: training acc: 0.5 , training loss: 3.474104642868042 , validation acc: 0.375 , validation_loss: 4.024659156799316\n",
      "model 1 is trained: training acc: 1.0 , training loss: 0.0026284109335392714 , validation acc: 0.25 , validation_loss: 273.8343200683594\n",
      "micro average\n",
      "seen accuracy: 19.883720930232556 unseen accuracy: 46.180555555555564 harmonic mean: 27.798420808174637\n",
      "macro average\n",
      "seen accuracy: 19.883720930232556 unseen accuracy: 46.18055555555556 harmonic mean: 27.79842080817464\n",
      "best accuracy micro seen accuracy: 19.883720930232556 unseen accuracy: 46.180555555555564 harmonic mean: 27.798420808174637\n",
      "best accuracy macro seen accuracy: 19.883720930232556 unseen accuracy: 46.18055555555556 harmonic mean: 27.79842080817464\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 9\n",
      "model 2 is trained: training acc: 0.6875 , training loss: 2.9920060634613037 , validation acc: 0.125 , validation_loss: 4.002153396606445\n",
      "model 1 is trained: training acc: 0.984375 , training loss: 0.3229592740535736 , validation acc: 0.125 , validation_loss: 210.95626831054688\n",
      "micro average\n",
      "seen accuracy: 20.503875968992247 unseen accuracy: 43.750000000000014 harmonic mean: 27.921882069069525\n",
      "macro average\n",
      "seen accuracy: 20.503875968992247 unseen accuracy: 43.75 harmonic mean: 27.92188206906952\n",
      "best accuracy micro seen accuracy: 20.503875968992247 unseen accuracy: 43.750000000000014 harmonic mean: 27.921882069069525\n",
      "best accuracy macro seen accuracy: 20.503875968992247 unseen accuracy: 43.75 harmonic mean: 27.92188206906952\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 10\n",
      "model 2 is trained: training acc: 0.59375 , training loss: 3.1406517028808594 , validation acc: 0.375 , validation_loss: 3.808312177658081\n",
      "model 1 is trained: training acc: 1.0 , training loss: 0.0 , validation acc: 0.4375 , validation_loss: 183.14234924316406\n",
      "micro average\n",
      "seen accuracy: 20.852713178294575 unseen accuracy: 45.62500000000001 harmonic mean: 28.623278186721087\n",
      "macro average\n",
      "seen accuracy: 20.852713178294575 unseen accuracy: 45.625 harmonic mean: 28.623278186721084\n",
      "best accuracy micro seen accuracy: 20.852713178294575 unseen accuracy: 45.62500000000001 harmonic mean: 28.623278186721087\n",
      "best accuracy macro seen accuracy: 20.852713178294575 unseen accuracy: 45.625 harmonic mean: 28.623278186721084\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 11\n",
      "model 2 is trained: training acc: 0.59375 , training loss: 3.0420618057250977 , validation acc: 0.3125 , validation_loss: 3.878009796142578\n",
      "model 1 is trained: training acc: 1.0 , training loss: 1.806755278721539e-07 , validation acc: 0.25 , validation_loss: 159.4765167236328\n",
      "micro average\n",
      "seen accuracy: 21.93798449612403 unseen accuracy: 46.458333333333336 harmonic mean: 29.802838185639068\n",
      "macro average\n",
      "seen accuracy: 21.93798449612403 unseen accuracy: 46.458333333333336 harmonic mean: 29.802838185639068\n",
      "best accuracy micro seen accuracy: 21.93798449612403 unseen accuracy: 46.458333333333336 harmonic mean: 29.802838185639068\n",
      "best accuracy macro seen accuracy: 21.93798449612403 unseen accuracy: 46.458333333333336 harmonic mean: 29.802838185639068\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 12\n",
      "model 2 is trained: training acc: 0.71875 , training loss: 2.681645393371582 , validation acc: 0.375 , validation_loss: 3.8747100830078125\n",
      "model 1 is trained: training acc: 1.0 , training loss: 0.0 , validation acc: 0.25 , validation_loss: 143.58566284179688\n",
      "micro average\n",
      "seen accuracy: 21.821705426356587 unseen accuracy: 43.88888888888887 harmonic mean: 29.149954122427573\n",
      "macro average\n",
      "seen accuracy: 21.821705426356587 unseen accuracy: 43.888888888888886 harmonic mean: 29.149954122427577\n",
      "best accuracy micro seen accuracy: 21.93798449612403 unseen accuracy: 46.458333333333336 harmonic mean: 29.802838185639068\n",
      "best accuracy macro seen accuracy: 21.93798449612403 unseen accuracy: 46.458333333333336 harmonic mean: 29.802838185639068\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 13\n",
      "model 2 is trained: training acc: 0.796875 , training loss: 2.810483455657959 , validation acc: 0.5 , validation_loss: 3.1305198669433594\n",
      "model 1 is trained: training acc: 0.984375 , training loss: 0.2710520923137665 , validation acc: 0.375 , validation_loss: 240.70364379882812\n",
      "micro average\n",
      "seen accuracy: 22.05426356589147 unseen accuracy: 47.500000000000014 harmonic mean: 30.12259682362775\n",
      "macro average\n",
      "seen accuracy: 22.05426356589147 unseen accuracy: 47.5 harmonic mean: 30.12259682362775\n",
      "best accuracy micro seen accuracy: 22.05426356589147 unseen accuracy: 47.500000000000014 harmonic mean: 30.12259682362775\n",
      "best accuracy macro seen accuracy: 22.05426356589147 unseen accuracy: 47.5 harmonic mean: 30.12259682362775\n",
      "-----------------------------------------------------------------------------------------------------------\n",
      "iteration: 14\n",
      "model 2 is trained: training acc: 0.734375 , training loss: 2.657081127166748 , validation acc: 0.375 , validation_loss: 3.591301441192627\n",
      "model 1 is trained: training acc: 1.0 , training loss: 0.0 , validation acc: 0.4375 , validation_loss: 207.5684356689453\n",
      "micro average\n",
      "seen accuracy: 24.108527131782946 unseen accuracy: 49.65277777777779 harmonic mean: 32.457542384632795\n",
      "macro average\n",
      "seen accuracy: 24.108527131782946 unseen accuracy: 49.65277777777778 harmonic mean: 32.457542384632795\n",
      "best accuracy micro seen accuracy: 24.108527131782946 unseen accuracy: 49.65277777777779 harmonic mean: 32.457542384632795\n",
      "best accuracy macro seen accuracy: 24.108527131782946 unseen accuracy: 49.65277777777778 harmonic mean: 32.457542384632795\n",
      "-----------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "iteration = 5\n",
    "epochs1 = 200\n",
    "epochs2 = 200\n",
    "\n",
    "best_performance_micro = [0, 0, 0]\n",
    "best_performance_macro = [0, 0, 0]\n",
    "\n",
    "save_path = 'C:/Users/Admin/Sushree_Codes/Sush_3/Results/'\n",
    "name = 'model1_SUN_Tatt_it5_200eph_adam_cce_16bch_1e-2lr_model2_adam_200'\n",
    "       \n",
    "for i in range(iteration):\n",
    "    X_train2_it = X_train2[(len(X_train2)//iteration)*i:(len(X_train2)//iteration)*(i+1)]\n",
    "    X_val2_it = X_val2[(len(X_val2)//iteration)*i:(len(X_val2)//iteration)*(i+1)]\n",
    "    y_train2_it = y_train2[(len(y_train2)//iteration)*i:(len(y_train2)//iteration)*(i+1)]\n",
    "    y_val2_it = y_val2[(len(y_val2)//iteration)*i:(len(y_val2)//iteration)*(i+1)]\n",
    "    \n",
    "    train_gen2 = DataGenerator(X_train2_it, y_train2_it, batch_size)   \n",
    "    val_gen2 = DataGenerator(X_val2_it, y_val2_it, batch_size)\n",
    "\n",
    "    train_summary2 = model2.fit(train_gen2, epochs = epochs2, verbose = 0, callbacks = None, validation_data = val_gen2, \n",
    "                              shuffle = True, steps_per_epoch = len(train_gen2)//batch_size, \n",
    "                              validation_steps = len(val_gen2)//batch_size)\n",
    "\n",
    "    print(\"iteration:\", i)\n",
    "    print('model 2 is trained:', 'training acc:', train_summary2.history['accuracy'][-1], ',',  \n",
    "          'training loss:', train_summary2.history['loss'][-1], ',', \n",
    "          'validation acc:', train_summary2.history['val_accuracy'][-1], ',',\n",
    "         'validation_loss:', train_summary2.history['val_loss'][-1])\n",
    "\n",
    "    weights_list2 = model2.get_weights()\n",
    "    #print(weights_list2)\n",
    "\n",
    "    model1.layers[-1].set_weights(weights_list2)\n",
    "\n",
    "    X_train1_it = X_train1[(len(X_train1)//iteration)*i:(len(X_train1)//iteration)*(i+1)]\n",
    "    X_val1_it = X_val1[(len(X_val1)//iteration)*i:(len(X_val1)//iteration)*(i+1)]\n",
    "    y_train1_it = y_train1[(len(y_train1)//iteration)*i:(len(y_train1)//iteration)*(i+1)]\n",
    "    y_val1_it = y_val1[(len(y_val1)//iteration)*i:(len(y_val1)//iteration)*(i+1)]\n",
    "    \n",
    "    train_gen1 = DataGenerator(X_train1_it, y_train1_it, batch_size)   \n",
    "    val_gen1 = DataGenerator(X_val1_it, y_val1_it, batch_size)\n",
    "    \n",
    "    for layer in model1.layers[2:]:\n",
    "        layer.trainable = True\n",
    "\n",
    "    train_summary1 = model1.fit(train_gen1, epochs = epochs1, verbose = 0, callbacks = None, validation_data = val_gen1, \n",
    "                              shuffle = True, steps_per_epoch = len(train_gen1)//batch_size, \n",
    "                              validation_steps = len(val_gen1)//batch_size)\n",
    "    \n",
    "    #print(\"iteration:\", i)\n",
    "    print('model 1 is trained:', 'training acc:', train_summary1.history['accuracy'][-1], ',',  \n",
    "          'training loss:', train_summary1.history['loss'][-1], ',', \n",
    "          'validation acc:', train_summary1.history['val_accuracy'][-1], ',',\n",
    "         'validation_loss:', train_summary1.history['val_loss'][-1])\n",
    "    \n",
    "    weights_list1 = Model(inputs = model1.input, outputs = model1.layers[-1].output).get_weights()\n",
    "    \n",
    "    #predictions\n",
    "    #outputs_seen = np.matmul(np.matmul(test_seen_vec, np.matmul(weights_list1[0], weights_list1[2])), test_seen_sig)\n",
    "    outputs_seen = np.matmul(np.matmul(test_seen_vec, weights_list1[0]), test_seen_sig)\n",
    "    \n",
    "    preds_seen = np.array([np.argmax(output) for output in outputs_seen])\n",
    "    \n",
    "    cm_seen = confusion_matrix(new_labels_test_seen, preds_seen)\n",
    "    #print(cm)\n",
    "    # Compute macro average (averaging performance metrics by first calculating the metric separately for each class and \n",
    "    # then averaging these class-specific metrics)\n",
    "    cm_seen_micro = cm_seen.astype('float') / cm_seen.sum(axis=1)[:, np.newaxis]\n",
    "    #print(cm)\n",
    "    avg_seen_micro = (sum(cm_seen_micro.diagonal())/len(unique_labels_test_seen))*100\n",
    "\n",
    "    avg_seen_macro = (sum(cm_seen.diagonal())/len(new_labels_test_seen))*100\n",
    "    \n",
    "    #predictions\n",
    "    outputs_unseen = np.matmul(np.matmul(test_unseen_vec, weights_list1[0]), test_unseen_sig)\n",
    "    \n",
    "    preds_unseen = np.array([np.argmax(output) for output in outputs_unseen])\n",
    "    \n",
    "    cm_unseen = confusion_matrix(new_labels_test_unseen, preds_unseen)\n",
    "    # Compute macro average (averaging performance metrics by first calculating the metric separately for each class and \n",
    "    # then averaging these class-specific metrics)\n",
    "    cm_unseen_micro = cm_unseen.astype('float') / cm_unseen.sum(axis=1)[:, np.newaxis]\n",
    "    avg_unseen_micro = (sum(cm_unseen_micro.diagonal())/len(unique_labels_test_unseen))*100\n",
    "\n",
    "    avg_unseen_macro = (sum(cm_unseen.diagonal())/len(new_labels_test_unseen))*100\n",
    "    \n",
    "    harmonic_micro = (2*avg_seen_micro*avg_unseen_micro) / (avg_seen_micro + avg_unseen_micro)\n",
    "    harmonic_macro = (2*avg_seen_macro*avg_unseen_macro) / (avg_seen_macro + avg_unseen_macro)\n",
    "    \n",
    "    print('micro average')\n",
    "    print('seen accuracy:', avg_seen_micro, 'unseen accuracy:', avg_unseen_micro, 'harmonic mean:', harmonic_micro)\n",
    "    \n",
    "    print('macro average')\n",
    "    print('seen accuracy:', avg_seen_macro, 'unseen accuracy:', avg_unseen_macro, 'harmonic mean:', harmonic_macro)\n",
    "    \n",
    "    if harmonic_micro > best_performance_micro[2]:\n",
    "        best_performance_micro = [avg_seen_micro, avg_unseen_micro, harmonic_micro]\n",
    "        model1.save_weights(save_path + 'bw_micro_' + name + '.h5', overwrite=True)\n",
    "        \n",
    "    if harmonic_macro > best_performance_macro[2]:\n",
    "        best_performance_macro = [avg_seen_macro, avg_unseen_macro, harmonic_macro]\n",
    "        model1.save_weights(save_path + 'bw_macro_' + name + '.h5', overwrite=True)\n",
    "        \n",
    "    print('best accuracy micro','seen accuracy:', best_performance_micro[0], 'unseen accuracy:', best_performance_micro[1], 'harmonic mean:', best_performance_micro[2])\n",
    "    print('best accuracy macro', 'seen accuracy:', best_performance_macro[0], 'unseen accuracy:', best_performance_macro[1], 'harmonic mean:', best_performance_macro[2])\n",
    "    \n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "    weights_list3 = model1.get_weights()\n",
    "    model2.set_weights(weights_list3[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92c61599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] (2580, 645)\n",
      "81/81 [==============================] - 0s 3ms/step - loss: 214.9025 - accuracy: 0.2891\n",
      "cce =  11.27264\n",
      "81/81 [==============================] - 0s 2ms/step - loss: 3.2620 - accuracy: 0.4279\n",
      "cce =  3.2620137\n"
     ]
    }
   ],
   "source": [
    "gt_test_seen = to_categorical(new_labels_test_seen, z1_test_seen)\n",
    "\n",
    "print(gt_test_seen, gt_test_seen.shape)\n",
    "\n",
    "#test_seen_vec = np.reshape(test_seen_vec, [test_seen_vec.shape[0], 1, 1, test_seen_vec.shape[1]])\n",
    "res1 = model1.evaluate(test_seen_vec, gt_test_seen)\n",
    "\n",
    "p1 = model1.predict(test_seen_vec, verbose = 0)\n",
    "\n",
    "import tensorflow\n",
    "cce = tensorflow.keras.losses.CategoricalCrossentropy()\n",
    "print('cce = ', cce(gt_test_seen, p1).numpy())\n",
    "\n",
    "#test_seen_attributes = np.reshape(train_attributes, [test_seen_attributes.shape[0], 1, train_attributes.shape[1]])\n",
    "#test_seen_attributes = np.reshape(test_seen_attributes, [test_seen_attributes.shape[0], 1, 1, test_seen_attributes.shape[1]])\n",
    "\n",
    "res2 = model2.evaluate(test_seen_attributes, gt_test_seen)\n",
    "\n",
    "p2 = model2.predict(test_seen_attributes, verbose = 0)\n",
    "\n",
    "import tensorflow\n",
    "cce = tensorflow.keras.losses.CategoricalCrossentropy()\n",
    "print('cce = ', cce(gt_test_seen, p2).numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b965eee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.54607622568388\n",
      "35.852713882923126\n",
      "41.638146052874184\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy_seen_updated = res1[1]*100\n",
    "unseen_accuracy = 49.65\n",
    "h = (2*accuracy_seen_updated*unseen_accuracy) / (accuracy_seen_updated + unseen_accuracy)\n",
    "print(h)\n",
    "\n",
    "\n",
    "accuracy_seen_updated2 = ((res1[1]*100)+(res2[1]*100))/2\n",
    "print(accuracy_seen_updated2)\n",
    "h = (2*accuracy_seen_updated2*unseen_accuracy) / (accuracy_seen_updated2 + unseen_accuracy)\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9d5745b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_seen_macro 0.31079446199812316 recall_seen_macro 0.3585271317829457 f1_seen_macro 0.2974102830353097\n",
      "precision_seen_micro 0.3585271317829457 recall_seen_micro 0.3585271317829457 f1_seen_micro 0.3585271317829457\n",
      "precision_unseen_macro 0.5293554858042557 recall_unseen_macro 0.4965277777777778 f1_unseen_macro 0.47642198451002127\n",
      "precision_unseen_micro 0.4965277777777778 recall_unseen_micro 0.4965277777777778 f1_unseen_micro 0.4965277777777778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\en3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\en3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\Admin\\anaconda3\\envs\\en3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "\n",
    "pp1 = np.array([np.argmax(output) for output in p1])\n",
    "pp2 = np.array([np.argmax(output) for output in p2])\n",
    "\n",
    "seen_macro1 = precision_recall_fscore_support(new_labels_test_seen, pp1, average = 'macro')\n",
    "seen_macro2 = precision_recall_fscore_support(new_labels_test_seen, pp2, average = 'macro')\n",
    "print('precision_seen_macro', (seen_macro1[0] + seen_macro2[0])/2, 'recall_seen_macro', (seen_macro1[1] + seen_macro2[1])/2, 'f1_seen_macro', (seen_macro1[2] + seen_macro2[2])/2)\n",
    "\n",
    "\n",
    "seen_micro1 = precision_recall_fscore_support(new_labels_test_seen, pp1, average = 'micro')\n",
    "seen_micro2 = precision_recall_fscore_support(new_labels_test_seen, pp2, average = 'micro')\n",
    "print('precision_seen_micro', (seen_micro1[0] + seen_micro2[0])/2, 'recall_seen_micro', (seen_micro1[1] + seen_micro2[1])/2, 'f1_seen_micro', (seen_micro1[2] + seen_micro2[2])/2)\n",
    "\n",
    "unseen_macro = precision_recall_fscore_support(new_labels_test_unseen, preds_unseen, average = 'macro')\n",
    "unseen_micro = precision_recall_fscore_support(new_labels_test_unseen, preds_unseen, average = 'micro')\n",
    "\n",
    "print('precision_unseen_macro', unseen_macro[0], 'recall_unseen_macro', unseen_macro[1], 'f1_unseen_macro', unseen_macro[2])\n",
    "print('precision_unseen_micro', unseen_micro[0], 'recall_unseen_micro', unseen_micro[1], 'f1_unseen_micro', unseen_micro[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0480d9e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
